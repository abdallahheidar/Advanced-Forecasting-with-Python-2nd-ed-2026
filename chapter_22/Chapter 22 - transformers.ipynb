{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2eeb30a5-cf9a-43e8-8e0f-040e708c3287",
   "metadata": {},
   "source": [
    "# Chapter 22 - The Transformer Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b129a252-d4bc-4ecb-b3de-6eaddc2676fe",
   "metadata": {},
   "source": [
    "## Listing 22-1. Import the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ceed840f-60a2-44c9-90b4-0da9b6090c1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5z/nxlf2r4n5yx6qy1wbzvkr3xr0000gn/T/ipykernel_74850/896776394.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_sum['SALES'] = df[[x for x in df.columns if x.startswith('QTY')]].sum(axis=1)\n",
      "/var/folders/5z/nxlf2r4n5yx6qy1wbzvkr3xr0000gn/T/ipykernel_74850/896776394.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_sum['PROMO'] = df[[x for x in df.columns if x.startswith('PROMO')]].sum(axis=1)\n",
      "/var/folders/5z/nxlf2r4n5yx6qy1wbzvkr3xr0000gn/T/ipykernel_74850/896776394.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_sum['YEAR_MONTH'] = df_sum['DATE'].apply(lambda x: x[:7])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SALES</th>\n",
       "      <th>PROMO</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YEAR_MONTH</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2014-01</th>\n",
       "      <td>12819</td>\n",
       "      <td>990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-02</th>\n",
       "      <td>17906</td>\n",
       "      <td>1329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-03</th>\n",
       "      <td>12047</td>\n",
       "      <td>896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-04</th>\n",
       "      <td>15998</td>\n",
       "      <td>1235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-05</th>\n",
       "      <td>17453</td>\n",
       "      <td>1354</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            SALES  PROMO\n",
       "YEAR_MONTH              \n",
       "2014-01     12819    990\n",
       "2014-02     17906   1329\n",
       "2014-03     12047    896\n",
       "2014-04     15998   1235\n",
       "2014-05     17453   1354"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Read the data\n",
    "df = pd.read_csv('hierarchical_sales_data.csv')\n",
    "\n",
    "df_sum = df[['DATE']]\n",
    "\n",
    "# Sum the sales and promos of the different products\n",
    "df_sum['SALES'] = df[[x for x in df.columns if x.startswith('QTY')]].sum(axis=1)\n",
    "df_sum['PROMO'] = df[[x for x in df.columns if x.startswith('PROMO')]].sum(axis=1)\n",
    "\n",
    "# Create sum of sales and promos per month\n",
    "df_sum['YEAR_MONTH'] = df_sum['DATE'].apply(lambda x: x[:7])\n",
    "df_sum = df_sum[['SALES', 'PROMO', 'YEAR_MONTH']].groupby('YEAR_MONTH').sum()\n",
    "df_sum.head()\n",
    "\n",
    "# Preview the data\n",
    "df_sum.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74c6b5c7-573b-499c-904c-4c7967310b1a",
   "metadata": {},
   "source": [
    "## Listing 22-2. Prepare for Darts and create univariate train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f955fde7-fd55-442f-9944-2df9afe8b14e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><svg style=\"position: absolute; width: 0; height: 0; overflow: hidden\">\n",
       "<defs>\n",
       "<symbol id=\"icon-database\" viewBox=\"0 0 32 32\">\n",
       "<path d=\"M16 0c-8.837 0-16 2.239-16 5v4c0 2.761 7.163 5 16 5s16-2.239 16-5v-4c0-2.761-7.163-5-16-5z\"></path>\n",
       "<path d=\"M16 17c-8.837 0-16-2.239-16-5v6c0 2.761 7.163 5 16 5s16-2.239 16-5v-6c0 2.761-7.163 5-16 5z\"></path>\n",
       "<path d=\"M16 26c-8.837 0-16-2.239-16-5v6c0 2.761 7.163 5 16 5s16-2.239 16-5v-6c0 2.761-7.163 5-16 5z\"></path>\n",
       "</symbol>\n",
       "<symbol id=\"icon-file-text2\" viewBox=\"0 0 32 32\">\n",
       "<path d=\"M28.681 7.159c-0.694-0.947-1.662-2.053-2.724-3.116s-2.169-2.030-3.116-2.724c-1.612-1.182-2.393-1.319-2.841-1.319h-15.5c-1.378 0-2.5 1.121-2.5 2.5v27c0 1.378 1.122 2.5 2.5 2.5h23c1.378 0 2.5-1.122 2.5-2.5v-19.5c0-0.448-0.137-1.23-1.319-2.841zM24.543 5.457c0.959 0.959 1.712 1.825 2.268 2.543h-4.811v-4.811c0.718 0.556 1.584 1.309 2.543 2.268zM28 29.5c0 0.271-0.229 0.5-0.5 0.5h-23c-0.271 0-0.5-0.229-0.5-0.5v-27c0-0.271 0.229-0.5 0.5-0.5 0 0 15.499-0 15.5 0v7c0 0.552 0.448 1 1 1h7v19.5z\"></path>\n",
       "<path d=\"M23 26h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "<path d=\"M23 22h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "<path d=\"M23 18h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "</symbol>\n",
       "</defs>\n",
       "</svg>\n",
       "<style>/* CSS stylesheet for displaying xarray objects in jupyterlab.\n",
       " *\n",
       " */\n",
       "\n",
       ":root {\n",
       "  --xr-font-color0: var(--jp-content-font-color0, rgba(0, 0, 0, 1));\n",
       "  --xr-font-color2: var(--jp-content-font-color2, rgba(0, 0, 0, 0.54));\n",
       "  --xr-font-color3: var(--jp-content-font-color3, rgba(0, 0, 0, 0.38));\n",
       "  --xr-border-color: var(--jp-border-color2, #e0e0e0);\n",
       "  --xr-disabled-color: var(--jp-layout-color3, #bdbdbd);\n",
       "  --xr-background-color: var(--jp-layout-color0, white);\n",
       "  --xr-background-color-row-even: var(--jp-layout-color1, white);\n",
       "  --xr-background-color-row-odd: var(--jp-layout-color2, #eeeeee);\n",
       "}\n",
       "\n",
       "html[theme=dark],\n",
       "html[data-theme=dark],\n",
       "body[data-theme=dark],\n",
       "body.vscode-dark {\n",
       "  --xr-font-color0: rgba(255, 255, 255, 1);\n",
       "  --xr-font-color2: rgba(255, 255, 255, 0.54);\n",
       "  --xr-font-color3: rgba(255, 255, 255, 0.38);\n",
       "  --xr-border-color: #1F1F1F;\n",
       "  --xr-disabled-color: #515151;\n",
       "  --xr-background-color: #111111;\n",
       "  --xr-background-color-row-even: #111111;\n",
       "  --xr-background-color-row-odd: #313131;\n",
       "}\n",
       "\n",
       ".xr-wrap {\n",
       "  display: block !important;\n",
       "  min-width: 300px;\n",
       "  max-width: 700px;\n",
       "}\n",
       "\n",
       ".xr-text-repr-fallback {\n",
       "  /* fallback to plain text repr when CSS is not injected (untrusted notebook) */\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-header {\n",
       "  padding-top: 6px;\n",
       "  padding-bottom: 6px;\n",
       "  margin-bottom: 4px;\n",
       "  border-bottom: solid 1px var(--xr-border-color);\n",
       "}\n",
       "\n",
       ".xr-header > div,\n",
       ".xr-header > ul {\n",
       "  display: inline;\n",
       "  margin-top: 0;\n",
       "  margin-bottom: 0;\n",
       "}\n",
       "\n",
       ".xr-obj-type,\n",
       ".xr-array-name {\n",
       "  margin-left: 2px;\n",
       "  margin-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-obj-type {\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-sections {\n",
       "  padding-left: 0 !important;\n",
       "  display: grid;\n",
       "  grid-template-columns: 150px auto auto 1fr 20px 20px;\n",
       "}\n",
       "\n",
       ".xr-section-item {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-section-item input {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-section-item input + label {\n",
       "  color: var(--xr-disabled-color);\n",
       "}\n",
       "\n",
       ".xr-section-item input:enabled + label {\n",
       "  cursor: pointer;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-section-item input:enabled + label:hover {\n",
       "  color: var(--xr-font-color0);\n",
       "}\n",
       "\n",
       ".xr-section-summary {\n",
       "  grid-column: 1;\n",
       "  color: var(--xr-font-color2);\n",
       "  font-weight: 500;\n",
       "}\n",
       "\n",
       ".xr-section-summary > span {\n",
       "  display: inline-block;\n",
       "  padding-left: 0.5em;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:disabled + label {\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-section-summary-in + label:before {\n",
       "  display: inline-block;\n",
       "  content: '►';\n",
       "  font-size: 11px;\n",
       "  width: 15px;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:disabled + label:before {\n",
       "  color: var(--xr-disabled-color);\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked + label:before {\n",
       "  content: '▼';\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked + label > span {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-section-summary,\n",
       ".xr-section-inline-details {\n",
       "  padding-top: 4px;\n",
       "  padding-bottom: 4px;\n",
       "}\n",
       "\n",
       ".xr-section-inline-details {\n",
       "  grid-column: 2 / -1;\n",
       "}\n",
       "\n",
       ".xr-section-details {\n",
       "  display: none;\n",
       "  grid-column: 1 / -1;\n",
       "  margin-bottom: 5px;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked ~ .xr-section-details {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-array-wrap {\n",
       "  grid-column: 1 / -1;\n",
       "  display: grid;\n",
       "  grid-template-columns: 20px auto;\n",
       "}\n",
       "\n",
       ".xr-array-wrap > label {\n",
       "  grid-column: 1;\n",
       "  vertical-align: top;\n",
       "}\n",
       "\n",
       ".xr-preview {\n",
       "  color: var(--xr-font-color3);\n",
       "}\n",
       "\n",
       ".xr-array-preview,\n",
       ".xr-array-data {\n",
       "  padding: 0 5px !important;\n",
       "  grid-column: 2;\n",
       "}\n",
       "\n",
       ".xr-array-data,\n",
       ".xr-array-in:checked ~ .xr-array-preview {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-array-in:checked ~ .xr-array-data,\n",
       ".xr-array-preview {\n",
       "  display: inline-block;\n",
       "}\n",
       "\n",
       ".xr-dim-list {\n",
       "  display: inline-block !important;\n",
       "  list-style: none;\n",
       "  padding: 0 !important;\n",
       "  margin: 0;\n",
       "}\n",
       "\n",
       ".xr-dim-list li {\n",
       "  display: inline-block;\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "}\n",
       "\n",
       ".xr-dim-list:before {\n",
       "  content: '(';\n",
       "}\n",
       "\n",
       ".xr-dim-list:after {\n",
       "  content: ')';\n",
       "}\n",
       "\n",
       ".xr-dim-list li:not(:last-child):after {\n",
       "  content: ',';\n",
       "  padding-right: 5px;\n",
       "}\n",
       "\n",
       ".xr-has-index {\n",
       "  font-weight: bold;\n",
       "}\n",
       "\n",
       ".xr-var-list,\n",
       ".xr-var-item {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-var-item > div,\n",
       ".xr-var-item label,\n",
       ".xr-var-item > .xr-var-name span {\n",
       "  background-color: var(--xr-background-color-row-even);\n",
       "  margin-bottom: 0;\n",
       "}\n",
       "\n",
       ".xr-var-item > .xr-var-name:hover span {\n",
       "  padding-right: 5px;\n",
       "}\n",
       "\n",
       ".xr-var-list > li:nth-child(odd) > div,\n",
       ".xr-var-list > li:nth-child(odd) > label,\n",
       ".xr-var-list > li:nth-child(odd) > .xr-var-name span {\n",
       "  background-color: var(--xr-background-color-row-odd);\n",
       "}\n",
       "\n",
       ".xr-var-name {\n",
       "  grid-column: 1;\n",
       "}\n",
       "\n",
       ".xr-var-dims {\n",
       "  grid-column: 2;\n",
       "}\n",
       "\n",
       ".xr-var-dtype {\n",
       "  grid-column: 3;\n",
       "  text-align: right;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-var-preview {\n",
       "  grid-column: 4;\n",
       "}\n",
       "\n",
       ".xr-index-preview {\n",
       "  grid-column: 2 / 5;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-var-name,\n",
       ".xr-var-dims,\n",
       ".xr-var-dtype,\n",
       ".xr-preview,\n",
       ".xr-attrs dt {\n",
       "  white-space: nowrap;\n",
       "  overflow: hidden;\n",
       "  text-overflow: ellipsis;\n",
       "  padding-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-var-name:hover,\n",
       ".xr-var-dims:hover,\n",
       ".xr-var-dtype:hover,\n",
       ".xr-attrs dt:hover {\n",
       "  overflow: visible;\n",
       "  width: auto;\n",
       "  z-index: 1;\n",
       "}\n",
       "\n",
       ".xr-var-attrs,\n",
       ".xr-var-data,\n",
       ".xr-index-data {\n",
       "  display: none;\n",
       "  background-color: var(--xr-background-color) !important;\n",
       "  padding-bottom: 5px !important;\n",
       "}\n",
       "\n",
       ".xr-var-attrs-in:checked ~ .xr-var-attrs,\n",
       ".xr-var-data-in:checked ~ .xr-var-data,\n",
       ".xr-index-data-in:checked ~ .xr-index-data {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       ".xr-var-data > table {\n",
       "  float: right;\n",
       "}\n",
       "\n",
       ".xr-var-name span,\n",
       ".xr-var-data,\n",
       ".xr-index-name div,\n",
       ".xr-index-data,\n",
       ".xr-attrs {\n",
       "  padding-left: 25px !important;\n",
       "}\n",
       "\n",
       ".xr-attrs,\n",
       ".xr-var-attrs,\n",
       ".xr-var-data,\n",
       ".xr-index-data {\n",
       "  grid-column: 1 / -1;\n",
       "}\n",
       "\n",
       "dl.xr-attrs {\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "  display: grid;\n",
       "  grid-template-columns: 125px auto;\n",
       "}\n",
       "\n",
       ".xr-attrs dt,\n",
       ".xr-attrs dd {\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "  float: left;\n",
       "  padding-right: 10px;\n",
       "  width: auto;\n",
       "}\n",
       "\n",
       ".xr-attrs dt {\n",
       "  font-weight: normal;\n",
       "  grid-column: 1;\n",
       "}\n",
       "\n",
       ".xr-attrs dt:hover span {\n",
       "  display: inline-block;\n",
       "  background: var(--xr-background-color);\n",
       "  padding-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-attrs dd {\n",
       "  grid-column: 2;\n",
       "  white-space: pre-wrap;\n",
       "  word-break: break-all;\n",
       "}\n",
       "\n",
       ".xr-icon-database,\n",
       ".xr-icon-file-text2,\n",
       ".xr-no-icon {\n",
       "  display: inline-block;\n",
       "  vertical-align: middle;\n",
       "  width: 1em;\n",
       "  height: 1.5em !important;\n",
       "  stroke-width: 0;\n",
       "  stroke: currentColor;\n",
       "  fill: currentColor;\n",
       "}\n",
       "</style><pre class='xr-text-repr-fallback'>&lt;TimeSeries (DataArray) (YEAR_MONTH: 48, component: 1, sample: 1)&gt; Size: 192B\n",
       "array([[[12819.]],\n",
       "\n",
       "       [[17906.]],\n",
       "\n",
       "       [[12047.]],\n",
       "\n",
       "       [[15998.]],\n",
       "\n",
       "       [[17453.]],\n",
       "\n",
       "       [[17310.]],\n",
       "\n",
       "       [[13523.]],\n",
       "\n",
       "       [[13279.]],\n",
       "\n",
       "       [[11887.]],\n",
       "\n",
       "       [[18202.]],\n",
       "\n",
       "...\n",
       "\n",
       "       [[15957.]],\n",
       "\n",
       "       [[13524.]],\n",
       "\n",
       "       [[12601.]],\n",
       "\n",
       "       [[13516.]],\n",
       "\n",
       "       [[11642.]],\n",
       "\n",
       "       [[ 8858.]],\n",
       "\n",
       "       [[14215.]],\n",
       "\n",
       "       [[11029.]],\n",
       "\n",
       "       [[16095.]],\n",
       "\n",
       "       [[13111.]]], dtype=float32)\n",
       "Coordinates:\n",
       "  * YEAR_MONTH  (YEAR_MONTH) datetime64[ns] 384B 2014-01-01 ... 2017-12-01\n",
       "  * component   (component) &lt;U5 20B &#x27;SALES&#x27;\n",
       "Dimensions without coordinates: sample\n",
       "Attributes:\n",
       "    static_covariates:  None\n",
       "    hierarchy:          None\n",
       "    metadata:           None</pre><div class='xr-wrap' style='display:none'><div class='xr-header'><div class='xr-obj-type'>TimeSeries (DataArray)</div><div class='xr-array-name'></div><ul class='xr-dim-list'><li><span class='xr-has-index'>YEAR_MONTH</span>: 48</li><li><span class='xr-has-index'>component</span>: 1</li><li><span>sample</span>: 1</li></ul></div><ul class='xr-sections'><li class='xr-section-item'><div class='xr-array-wrap'><input id='section-7887ca34-581f-45c5-88d2-cc4e3dea66ac' class='xr-array-in' type='checkbox' checked><label for='section-7887ca34-581f-45c5-88d2-cc4e3dea66ac' title='Show/hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-array-preview xr-preview'><span>1.282e+04 1.791e+04 1.205e+04 1.6e+04 ... 1.103e+04 1.61e+04 1.311e+04</span></div><div class='xr-array-data'><pre>array([[[12819.]],\n",
       "\n",
       "       [[17906.]],\n",
       "\n",
       "       [[12047.]],\n",
       "\n",
       "       [[15998.]],\n",
       "\n",
       "       [[17453.]],\n",
       "\n",
       "       [[17310.]],\n",
       "\n",
       "       [[13523.]],\n",
       "\n",
       "       [[13279.]],\n",
       "\n",
       "       [[11887.]],\n",
       "\n",
       "       [[18202.]],\n",
       "\n",
       "...\n",
       "\n",
       "       [[15957.]],\n",
       "\n",
       "       [[13524.]],\n",
       "\n",
       "       [[12601.]],\n",
       "\n",
       "       [[13516.]],\n",
       "\n",
       "       [[11642.]],\n",
       "\n",
       "       [[ 8858.]],\n",
       "\n",
       "       [[14215.]],\n",
       "\n",
       "       [[11029.]],\n",
       "\n",
       "       [[16095.]],\n",
       "\n",
       "       [[13111.]]], dtype=float32)</pre></div></div></li><li class='xr-section-item'><input id='section-b81977b1-b640-43ca-b88f-59a7837a287e' class='xr-section-summary-in' type='checkbox'  checked><label for='section-b81977b1-b640-43ca-b88f-59a7837a287e' class='xr-section-summary' >Coordinates: <span>(2)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>YEAR_MONTH</span></div><div class='xr-var-dims'>(YEAR_MONTH)</div><div class='xr-var-dtype'>datetime64[ns]</div><div class='xr-var-preview xr-preview'>2014-01-01 ... 2017-12-01</div><input id='attrs-89916b9b-2aec-4441-b22d-cc4bd0e19eb9' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-89916b9b-2aec-4441-b22d-cc4bd0e19eb9' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-a8f3f302-cf41-42b4-a3d9-43839333d792' class='xr-var-data-in' type='checkbox'><label for='data-a8f3f302-cf41-42b4-a3d9-43839333d792' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([&#x27;2014-01-01T00:00:00.000000000&#x27;, &#x27;2014-02-01T00:00:00.000000000&#x27;,\n",
       "       &#x27;2014-03-01T00:00:00.000000000&#x27;, &#x27;2014-04-01T00:00:00.000000000&#x27;,\n",
       "       &#x27;2014-05-01T00:00:00.000000000&#x27;, &#x27;2014-06-01T00:00:00.000000000&#x27;,\n",
       "       &#x27;2014-07-01T00:00:00.000000000&#x27;, &#x27;2014-08-01T00:00:00.000000000&#x27;,\n",
       "       &#x27;2014-09-01T00:00:00.000000000&#x27;, &#x27;2014-10-01T00:00:00.000000000&#x27;,\n",
       "       &#x27;2014-11-01T00:00:00.000000000&#x27;, &#x27;2014-12-01T00:00:00.000000000&#x27;,\n",
       "       &#x27;2015-01-01T00:00:00.000000000&#x27;, &#x27;2015-02-01T00:00:00.000000000&#x27;,\n",
       "       &#x27;2015-03-01T00:00:00.000000000&#x27;, &#x27;2015-04-01T00:00:00.000000000&#x27;,\n",
       "       &#x27;2015-05-01T00:00:00.000000000&#x27;, &#x27;2015-06-01T00:00:00.000000000&#x27;,\n",
       "       &#x27;2015-07-01T00:00:00.000000000&#x27;, &#x27;2015-08-01T00:00:00.000000000&#x27;,\n",
       "       &#x27;2015-09-01T00:00:00.000000000&#x27;, &#x27;2015-10-01T00:00:00.000000000&#x27;,\n",
       "       &#x27;2015-11-01T00:00:00.000000000&#x27;, &#x27;2015-12-01T00:00:00.000000000&#x27;,\n",
       "       &#x27;2016-01-01T00:00:00.000000000&#x27;, &#x27;2016-02-01T00:00:00.000000000&#x27;,\n",
       "       &#x27;2016-03-01T00:00:00.000000000&#x27;, &#x27;2016-04-01T00:00:00.000000000&#x27;,\n",
       "       &#x27;2016-05-01T00:00:00.000000000&#x27;, &#x27;2016-06-01T00:00:00.000000000&#x27;,\n",
       "       &#x27;2016-07-01T00:00:00.000000000&#x27;, &#x27;2016-08-01T00:00:00.000000000&#x27;,\n",
       "       &#x27;2016-09-01T00:00:00.000000000&#x27;, &#x27;2016-10-01T00:00:00.000000000&#x27;,\n",
       "       &#x27;2016-11-01T00:00:00.000000000&#x27;, &#x27;2016-12-01T00:00:00.000000000&#x27;,\n",
       "       &#x27;2017-01-01T00:00:00.000000000&#x27;, &#x27;2017-02-01T00:00:00.000000000&#x27;,\n",
       "       &#x27;2017-03-01T00:00:00.000000000&#x27;, &#x27;2017-04-01T00:00:00.000000000&#x27;,\n",
       "       &#x27;2017-05-01T00:00:00.000000000&#x27;, &#x27;2017-06-01T00:00:00.000000000&#x27;,\n",
       "       &#x27;2017-07-01T00:00:00.000000000&#x27;, &#x27;2017-08-01T00:00:00.000000000&#x27;,\n",
       "       &#x27;2017-09-01T00:00:00.000000000&#x27;, &#x27;2017-10-01T00:00:00.000000000&#x27;,\n",
       "       &#x27;2017-11-01T00:00:00.000000000&#x27;, &#x27;2017-12-01T00:00:00.000000000&#x27;],\n",
       "      dtype=&#x27;datetime64[ns]&#x27;)</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>component</span></div><div class='xr-var-dims'>(component)</div><div class='xr-var-dtype'>&lt;U5</div><div class='xr-var-preview xr-preview'>&#x27;SALES&#x27;</div><input id='attrs-ade27f99-d513-4b3a-96e3-f35906fec747' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-ade27f99-d513-4b3a-96e3-f35906fec747' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-027ab1a8-d5e1-40a2-840c-f5ae260aa70e' class='xr-var-data-in' type='checkbox'><label for='data-027ab1a8-d5e1-40a2-840c-f5ae260aa70e' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([&#x27;SALES&#x27;], dtype=&#x27;&lt;U5&#x27;)</pre></div></li></ul></div></li><li class='xr-section-item'><input id='section-f88c02ee-a2a9-4808-90c9-eed32920d180' class='xr-section-summary-in' type='checkbox'  ><label for='section-f88c02ee-a2a9-4808-90c9-eed32920d180' class='xr-section-summary' >Indexes: <span>(2)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'><li class='xr-var-item'><div class='xr-index-name'><div>YEAR_MONTH</div></div><div class='xr-index-preview'>PandasIndex</div><div></div><input id='index-5cdd41d1-92d2-4661-9204-1b683bf645d8' class='xr-index-data-in' type='checkbox'/><label for='index-5cdd41d1-92d2-4661-9204-1b683bf645d8' title='Show/Hide index repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-index-data'><pre>PandasIndex(DatetimeIndex([&#x27;2014-01-01&#x27;, &#x27;2014-02-01&#x27;, &#x27;2014-03-01&#x27;, &#x27;2014-04-01&#x27;,\n",
       "               &#x27;2014-05-01&#x27;, &#x27;2014-06-01&#x27;, &#x27;2014-07-01&#x27;, &#x27;2014-08-01&#x27;,\n",
       "               &#x27;2014-09-01&#x27;, &#x27;2014-10-01&#x27;, &#x27;2014-11-01&#x27;, &#x27;2014-12-01&#x27;,\n",
       "               &#x27;2015-01-01&#x27;, &#x27;2015-02-01&#x27;, &#x27;2015-03-01&#x27;, &#x27;2015-04-01&#x27;,\n",
       "               &#x27;2015-05-01&#x27;, &#x27;2015-06-01&#x27;, &#x27;2015-07-01&#x27;, &#x27;2015-08-01&#x27;,\n",
       "               &#x27;2015-09-01&#x27;, &#x27;2015-10-01&#x27;, &#x27;2015-11-01&#x27;, &#x27;2015-12-01&#x27;,\n",
       "               &#x27;2016-01-01&#x27;, &#x27;2016-02-01&#x27;, &#x27;2016-03-01&#x27;, &#x27;2016-04-01&#x27;,\n",
       "               &#x27;2016-05-01&#x27;, &#x27;2016-06-01&#x27;, &#x27;2016-07-01&#x27;, &#x27;2016-08-01&#x27;,\n",
       "               &#x27;2016-09-01&#x27;, &#x27;2016-10-01&#x27;, &#x27;2016-11-01&#x27;, &#x27;2016-12-01&#x27;,\n",
       "               &#x27;2017-01-01&#x27;, &#x27;2017-02-01&#x27;, &#x27;2017-03-01&#x27;, &#x27;2017-04-01&#x27;,\n",
       "               &#x27;2017-05-01&#x27;, &#x27;2017-06-01&#x27;, &#x27;2017-07-01&#x27;, &#x27;2017-08-01&#x27;,\n",
       "               &#x27;2017-09-01&#x27;, &#x27;2017-10-01&#x27;, &#x27;2017-11-01&#x27;, &#x27;2017-12-01&#x27;],\n",
       "              dtype=&#x27;datetime64[ns]&#x27;, name=&#x27;YEAR_MONTH&#x27;, freq=&#x27;MS&#x27;))</pre></div></li><li class='xr-var-item'><div class='xr-index-name'><div>component</div></div><div class='xr-index-preview'>PandasIndex</div><div></div><input id='index-5dcaa8a7-4daa-4b3b-99b8-5db86fdc0a50' class='xr-index-data-in' type='checkbox'/><label for='index-5dcaa8a7-4daa-4b3b-99b8-5db86fdc0a50' title='Show/Hide index repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-index-data'><pre>PandasIndex(Index([&#x27;SALES&#x27;], dtype=&#x27;object&#x27;, name=&#x27;component&#x27;))</pre></div></li></ul></div></li><li class='xr-section-item'><input id='section-1defeeee-3ec0-4fc6-950d-695043cd9a45' class='xr-section-summary-in' type='checkbox'  checked><label for='section-1defeeee-3ec0-4fc6-950d-695043cd9a45' class='xr-section-summary' >Attributes: <span>(3)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><dl class='xr-attrs'><dt><span>static_covariates :</span></dt><dd>None</dd><dt><span>hierarchy :</span></dt><dd>None</dd><dt><span>metadata :</span></dt><dd>None</dd></dl></div></li></ul></div></div>"
      ],
      "text/plain": [
       "<TimeSeries (DataArray) (YEAR_MONTH: 48, component: 1, sample: 1)> Size: 192B\n",
       "array([[[12819.]],\n",
       "\n",
       "       [[17906.]],\n",
       "\n",
       "       [[12047.]],\n",
       "\n",
       "       [[15998.]],\n",
       "\n",
       "       [[17453.]],\n",
       "\n",
       "       [[17310.]],\n",
       "\n",
       "       [[13523.]],\n",
       "\n",
       "       [[13279.]],\n",
       "\n",
       "       [[11887.]],\n",
       "\n",
       "       [[18202.]],\n",
       "\n",
       "...\n",
       "\n",
       "       [[15957.]],\n",
       "\n",
       "       [[13524.]],\n",
       "\n",
       "       [[12601.]],\n",
       "\n",
       "       [[13516.]],\n",
       "\n",
       "       [[11642.]],\n",
       "\n",
       "       [[ 8858.]],\n",
       "\n",
       "       [[14215.]],\n",
       "\n",
       "       [[11029.]],\n",
       "\n",
       "       [[16095.]],\n",
       "\n",
       "       [[13111.]]], dtype=float32)\n",
       "Coordinates:\n",
       "  * YEAR_MONTH  (YEAR_MONTH) datetime64[ns] 384B 2014-01-01 ... 2017-12-01\n",
       "  * component   (component) <U5 20B 'SALES'\n",
       "Dimensions without coordinates: sample\n",
       "Attributes:\n",
       "    static_covariates:  None\n",
       "    hierarchy:          None\n",
       "    metadata:           None"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from darts.timeseries import TimeSeries\n",
    "\n",
    "# Convert sales data to float32 for Darts\n",
    "df_sum['SALES'] = df_sum['SALES'].map(np.float32)\n",
    "\n",
    "# Convert the dataframe index to a datetime index as required by Darts\n",
    "df_sum.index = pd.DatetimeIndex(df_sum.index)\n",
    "\n",
    "# Full year 2014 to 2017 is the training data\n",
    "train = df_sum.iloc[:-12]\n",
    "\n",
    "# Full year 2018 is the test data\n",
    "test = df_sum.iloc[-12:]\n",
    "\n",
    "# Convert the training data to a Darts time series\n",
    "train_series = TimeSeries.from_dataframe(train[['SALES']])\n",
    "\n",
    "# Inspect the time series format\n",
    "train_series"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f84b9420-7734-442d-93f9-9678e2959587",
   "metadata": {},
   "source": [
    "## Listing 22-3. Scaling the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2fc68665-4b2b-4296-9c26-a2acb397c11e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><svg style=\"position: absolute; width: 0; height: 0; overflow: hidden\">\n",
       "<defs>\n",
       "<symbol id=\"icon-database\" viewBox=\"0 0 32 32\">\n",
       "<path d=\"M16 0c-8.837 0-16 2.239-16 5v4c0 2.761 7.163 5 16 5s16-2.239 16-5v-4c0-2.761-7.163-5-16-5z\"></path>\n",
       "<path d=\"M16 17c-8.837 0-16-2.239-16-5v6c0 2.761 7.163 5 16 5s16-2.239 16-5v-6c0 2.761-7.163 5-16 5z\"></path>\n",
       "<path d=\"M16 26c-8.837 0-16-2.239-16-5v6c0 2.761 7.163 5 16 5s16-2.239 16-5v-6c0 2.761-7.163 5-16 5z\"></path>\n",
       "</symbol>\n",
       "<symbol id=\"icon-file-text2\" viewBox=\"0 0 32 32\">\n",
       "<path d=\"M28.681 7.159c-0.694-0.947-1.662-2.053-2.724-3.116s-2.169-2.030-3.116-2.724c-1.612-1.182-2.393-1.319-2.841-1.319h-15.5c-1.378 0-2.5 1.121-2.5 2.5v27c0 1.378 1.122 2.5 2.5 2.5h23c1.378 0 2.5-1.122 2.5-2.5v-19.5c0-0.448-0.137-1.23-1.319-2.841zM24.543 5.457c0.959 0.959 1.712 1.825 2.268 2.543h-4.811v-4.811c0.718 0.556 1.584 1.309 2.543 2.268zM28 29.5c0 0.271-0.229 0.5-0.5 0.5h-23c-0.271 0-0.5-0.229-0.5-0.5v-27c0-0.271 0.229-0.5 0.5-0.5 0 0 15.499-0 15.5 0v7c0 0.552 0.448 1 1 1h7v19.5z\"></path>\n",
       "<path d=\"M23 26h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "<path d=\"M23 22h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "<path d=\"M23 18h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "</symbol>\n",
       "</defs>\n",
       "</svg>\n",
       "<style>/* CSS stylesheet for displaying xarray objects in jupyterlab.\n",
       " *\n",
       " */\n",
       "\n",
       ":root {\n",
       "  --xr-font-color0: var(--jp-content-font-color0, rgba(0, 0, 0, 1));\n",
       "  --xr-font-color2: var(--jp-content-font-color2, rgba(0, 0, 0, 0.54));\n",
       "  --xr-font-color3: var(--jp-content-font-color3, rgba(0, 0, 0, 0.38));\n",
       "  --xr-border-color: var(--jp-border-color2, #e0e0e0);\n",
       "  --xr-disabled-color: var(--jp-layout-color3, #bdbdbd);\n",
       "  --xr-background-color: var(--jp-layout-color0, white);\n",
       "  --xr-background-color-row-even: var(--jp-layout-color1, white);\n",
       "  --xr-background-color-row-odd: var(--jp-layout-color2, #eeeeee);\n",
       "}\n",
       "\n",
       "html[theme=dark],\n",
       "html[data-theme=dark],\n",
       "body[data-theme=dark],\n",
       "body.vscode-dark {\n",
       "  --xr-font-color0: rgba(255, 255, 255, 1);\n",
       "  --xr-font-color2: rgba(255, 255, 255, 0.54);\n",
       "  --xr-font-color3: rgba(255, 255, 255, 0.38);\n",
       "  --xr-border-color: #1F1F1F;\n",
       "  --xr-disabled-color: #515151;\n",
       "  --xr-background-color: #111111;\n",
       "  --xr-background-color-row-even: #111111;\n",
       "  --xr-background-color-row-odd: #313131;\n",
       "}\n",
       "\n",
       ".xr-wrap {\n",
       "  display: block !important;\n",
       "  min-width: 300px;\n",
       "  max-width: 700px;\n",
       "}\n",
       "\n",
       ".xr-text-repr-fallback {\n",
       "  /* fallback to plain text repr when CSS is not injected (untrusted notebook) */\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-header {\n",
       "  padding-top: 6px;\n",
       "  padding-bottom: 6px;\n",
       "  margin-bottom: 4px;\n",
       "  border-bottom: solid 1px var(--xr-border-color);\n",
       "}\n",
       "\n",
       ".xr-header > div,\n",
       ".xr-header > ul {\n",
       "  display: inline;\n",
       "  margin-top: 0;\n",
       "  margin-bottom: 0;\n",
       "}\n",
       "\n",
       ".xr-obj-type,\n",
       ".xr-array-name {\n",
       "  margin-left: 2px;\n",
       "  margin-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-obj-type {\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-sections {\n",
       "  padding-left: 0 !important;\n",
       "  display: grid;\n",
       "  grid-template-columns: 150px auto auto 1fr 20px 20px;\n",
       "}\n",
       "\n",
       ".xr-section-item {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-section-item input {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-section-item input + label {\n",
       "  color: var(--xr-disabled-color);\n",
       "}\n",
       "\n",
       ".xr-section-item input:enabled + label {\n",
       "  cursor: pointer;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-section-item input:enabled + label:hover {\n",
       "  color: var(--xr-font-color0);\n",
       "}\n",
       "\n",
       ".xr-section-summary {\n",
       "  grid-column: 1;\n",
       "  color: var(--xr-font-color2);\n",
       "  font-weight: 500;\n",
       "}\n",
       "\n",
       ".xr-section-summary > span {\n",
       "  display: inline-block;\n",
       "  padding-left: 0.5em;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:disabled + label {\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-section-summary-in + label:before {\n",
       "  display: inline-block;\n",
       "  content: '►';\n",
       "  font-size: 11px;\n",
       "  width: 15px;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:disabled + label:before {\n",
       "  color: var(--xr-disabled-color);\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked + label:before {\n",
       "  content: '▼';\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked + label > span {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-section-summary,\n",
       ".xr-section-inline-details {\n",
       "  padding-top: 4px;\n",
       "  padding-bottom: 4px;\n",
       "}\n",
       "\n",
       ".xr-section-inline-details {\n",
       "  grid-column: 2 / -1;\n",
       "}\n",
       "\n",
       ".xr-section-details {\n",
       "  display: none;\n",
       "  grid-column: 1 / -1;\n",
       "  margin-bottom: 5px;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked ~ .xr-section-details {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-array-wrap {\n",
       "  grid-column: 1 / -1;\n",
       "  display: grid;\n",
       "  grid-template-columns: 20px auto;\n",
       "}\n",
       "\n",
       ".xr-array-wrap > label {\n",
       "  grid-column: 1;\n",
       "  vertical-align: top;\n",
       "}\n",
       "\n",
       ".xr-preview {\n",
       "  color: var(--xr-font-color3);\n",
       "}\n",
       "\n",
       ".xr-array-preview,\n",
       ".xr-array-data {\n",
       "  padding: 0 5px !important;\n",
       "  grid-column: 2;\n",
       "}\n",
       "\n",
       ".xr-array-data,\n",
       ".xr-array-in:checked ~ .xr-array-preview {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-array-in:checked ~ .xr-array-data,\n",
       ".xr-array-preview {\n",
       "  display: inline-block;\n",
       "}\n",
       "\n",
       ".xr-dim-list {\n",
       "  display: inline-block !important;\n",
       "  list-style: none;\n",
       "  padding: 0 !important;\n",
       "  margin: 0;\n",
       "}\n",
       "\n",
       ".xr-dim-list li {\n",
       "  display: inline-block;\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "}\n",
       "\n",
       ".xr-dim-list:before {\n",
       "  content: '(';\n",
       "}\n",
       "\n",
       ".xr-dim-list:after {\n",
       "  content: ')';\n",
       "}\n",
       "\n",
       ".xr-dim-list li:not(:last-child):after {\n",
       "  content: ',';\n",
       "  padding-right: 5px;\n",
       "}\n",
       "\n",
       ".xr-has-index {\n",
       "  font-weight: bold;\n",
       "}\n",
       "\n",
       ".xr-var-list,\n",
       ".xr-var-item {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-var-item > div,\n",
       ".xr-var-item label,\n",
       ".xr-var-item > .xr-var-name span {\n",
       "  background-color: var(--xr-background-color-row-even);\n",
       "  margin-bottom: 0;\n",
       "}\n",
       "\n",
       ".xr-var-item > .xr-var-name:hover span {\n",
       "  padding-right: 5px;\n",
       "}\n",
       "\n",
       ".xr-var-list > li:nth-child(odd) > div,\n",
       ".xr-var-list > li:nth-child(odd) > label,\n",
       ".xr-var-list > li:nth-child(odd) > .xr-var-name span {\n",
       "  background-color: var(--xr-background-color-row-odd);\n",
       "}\n",
       "\n",
       ".xr-var-name {\n",
       "  grid-column: 1;\n",
       "}\n",
       "\n",
       ".xr-var-dims {\n",
       "  grid-column: 2;\n",
       "}\n",
       "\n",
       ".xr-var-dtype {\n",
       "  grid-column: 3;\n",
       "  text-align: right;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-var-preview {\n",
       "  grid-column: 4;\n",
       "}\n",
       "\n",
       ".xr-index-preview {\n",
       "  grid-column: 2 / 5;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-var-name,\n",
       ".xr-var-dims,\n",
       ".xr-var-dtype,\n",
       ".xr-preview,\n",
       ".xr-attrs dt {\n",
       "  white-space: nowrap;\n",
       "  overflow: hidden;\n",
       "  text-overflow: ellipsis;\n",
       "  padding-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-var-name:hover,\n",
       ".xr-var-dims:hover,\n",
       ".xr-var-dtype:hover,\n",
       ".xr-attrs dt:hover {\n",
       "  overflow: visible;\n",
       "  width: auto;\n",
       "  z-index: 1;\n",
       "}\n",
       "\n",
       ".xr-var-attrs,\n",
       ".xr-var-data,\n",
       ".xr-index-data {\n",
       "  display: none;\n",
       "  background-color: var(--xr-background-color) !important;\n",
       "  padding-bottom: 5px !important;\n",
       "}\n",
       "\n",
       ".xr-var-attrs-in:checked ~ .xr-var-attrs,\n",
       ".xr-var-data-in:checked ~ .xr-var-data,\n",
       ".xr-index-data-in:checked ~ .xr-index-data {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       ".xr-var-data > table {\n",
       "  float: right;\n",
       "}\n",
       "\n",
       ".xr-var-name span,\n",
       ".xr-var-data,\n",
       ".xr-index-name div,\n",
       ".xr-index-data,\n",
       ".xr-attrs {\n",
       "  padding-left: 25px !important;\n",
       "}\n",
       "\n",
       ".xr-attrs,\n",
       ".xr-var-attrs,\n",
       ".xr-var-data,\n",
       ".xr-index-data {\n",
       "  grid-column: 1 / -1;\n",
       "}\n",
       "\n",
       "dl.xr-attrs {\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "  display: grid;\n",
       "  grid-template-columns: 125px auto;\n",
       "}\n",
       "\n",
       ".xr-attrs dt,\n",
       ".xr-attrs dd {\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "  float: left;\n",
       "  padding-right: 10px;\n",
       "  width: auto;\n",
       "}\n",
       "\n",
       ".xr-attrs dt {\n",
       "  font-weight: normal;\n",
       "  grid-column: 1;\n",
       "}\n",
       "\n",
       ".xr-attrs dt:hover span {\n",
       "  display: inline-block;\n",
       "  background: var(--xr-background-color);\n",
       "  padding-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-attrs dd {\n",
       "  grid-column: 2;\n",
       "  white-space: pre-wrap;\n",
       "  word-break: break-all;\n",
       "}\n",
       "\n",
       ".xr-icon-database,\n",
       ".xr-icon-file-text2,\n",
       ".xr-no-icon {\n",
       "  display: inline-block;\n",
       "  vertical-align: middle;\n",
       "  width: 1em;\n",
       "  height: 1.5em !important;\n",
       "  stroke-width: 0;\n",
       "  stroke: currentColor;\n",
       "  fill: currentColor;\n",
       "}\n",
       "</style><pre class='xr-text-repr-fallback'>&lt;TimeSeries (DataArray) (YEAR_MONTH: 48, component: 1, sample: 1)&gt; Size: 192B\n",
       "array([[[0.42390835]],\n",
       "\n",
       "       [[0.9683219 ]],\n",
       "\n",
       "       [[0.34128845]],\n",
       "\n",
       "       [[0.76412666]],\n",
       "\n",
       "       [[0.9198415 ]],\n",
       "\n",
       "       [[0.9045377 ]],\n",
       "\n",
       "       [[0.49925077]],\n",
       "\n",
       "       [[0.47313786]],\n",
       "\n",
       "       [[0.32416523]],\n",
       "\n",
       "       [[1.        ]],\n",
       "\n",
       "...\n",
       "\n",
       "       [[0.7597388 ]],\n",
       "\n",
       "       [[0.49935782]],\n",
       "\n",
       "       [[0.4005779 ]],\n",
       "\n",
       "       [[0.49850166]],\n",
       "\n",
       "       [[0.29794514]],\n",
       "\n",
       "       [[0.        ]],\n",
       "\n",
       "       [[0.57330906]],\n",
       "\n",
       "       [[0.23234153]],\n",
       "\n",
       "       [[0.77450764]],\n",
       "\n",
       "       [[0.45515835]]], dtype=float32)\n",
       "Coordinates:\n",
       "  * YEAR_MONTH  (YEAR_MONTH) datetime64[ns] 384B 2014-01-01 ... 2017-12-01\n",
       "  * component   (component) &lt;U5 20B &#x27;SALES&#x27;\n",
       "Dimensions without coordinates: sample\n",
       "Attributes:\n",
       "    static_covariates:  None\n",
       "    hierarchy:          None\n",
       "    metadata:           None</pre><div class='xr-wrap' style='display:none'><div class='xr-header'><div class='xr-obj-type'>TimeSeries (DataArray)</div><div class='xr-array-name'></div><ul class='xr-dim-list'><li><span class='xr-has-index'>YEAR_MONTH</span>: 48</li><li><span class='xr-has-index'>component</span>: 1</li><li><span>sample</span>: 1</li></ul></div><ul class='xr-sections'><li class='xr-section-item'><div class='xr-array-wrap'><input id='section-c8052a64-d2f5-42cf-8dad-f0d513c5b515' class='xr-array-in' type='checkbox' checked><label for='section-c8052a64-d2f5-42cf-8dad-f0d513c5b515' title='Show/hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-array-preview xr-preview'><span>0.4239 0.9683 0.3413 0.7641 0.9198 ... 0.0 0.5733 0.2323 0.7745 0.4552</span></div><div class='xr-array-data'><pre>array([[[0.42390835]],\n",
       "\n",
       "       [[0.9683219 ]],\n",
       "\n",
       "       [[0.34128845]],\n",
       "\n",
       "       [[0.76412666]],\n",
       "\n",
       "       [[0.9198415 ]],\n",
       "\n",
       "       [[0.9045377 ]],\n",
       "\n",
       "       [[0.49925077]],\n",
       "\n",
       "       [[0.47313786]],\n",
       "\n",
       "       [[0.32416523]],\n",
       "\n",
       "       [[1.        ]],\n",
       "\n",
       "...\n",
       "\n",
       "       [[0.7597388 ]],\n",
       "\n",
       "       [[0.49935782]],\n",
       "\n",
       "       [[0.4005779 ]],\n",
       "\n",
       "       [[0.49850166]],\n",
       "\n",
       "       [[0.29794514]],\n",
       "\n",
       "       [[0.        ]],\n",
       "\n",
       "       [[0.57330906]],\n",
       "\n",
       "       [[0.23234153]],\n",
       "\n",
       "       [[0.77450764]],\n",
       "\n",
       "       [[0.45515835]]], dtype=float32)</pre></div></div></li><li class='xr-section-item'><input id='section-1ab1714e-0a3c-4c2e-9132-675da1b7b74c' class='xr-section-summary-in' type='checkbox'  checked><label for='section-1ab1714e-0a3c-4c2e-9132-675da1b7b74c' class='xr-section-summary' >Coordinates: <span>(2)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>YEAR_MONTH</span></div><div class='xr-var-dims'>(YEAR_MONTH)</div><div class='xr-var-dtype'>datetime64[ns]</div><div class='xr-var-preview xr-preview'>2014-01-01 ... 2017-12-01</div><input id='attrs-46be99b9-27f8-4091-8c6f-3366292d6bea' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-46be99b9-27f8-4091-8c6f-3366292d6bea' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-dbc77748-3981-4add-b476-07e470761c34' class='xr-var-data-in' type='checkbox'><label for='data-dbc77748-3981-4add-b476-07e470761c34' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([&#x27;2014-01-01T00:00:00.000000000&#x27;, &#x27;2014-02-01T00:00:00.000000000&#x27;,\n",
       "       &#x27;2014-03-01T00:00:00.000000000&#x27;, &#x27;2014-04-01T00:00:00.000000000&#x27;,\n",
       "       &#x27;2014-05-01T00:00:00.000000000&#x27;, &#x27;2014-06-01T00:00:00.000000000&#x27;,\n",
       "       &#x27;2014-07-01T00:00:00.000000000&#x27;, &#x27;2014-08-01T00:00:00.000000000&#x27;,\n",
       "       &#x27;2014-09-01T00:00:00.000000000&#x27;, &#x27;2014-10-01T00:00:00.000000000&#x27;,\n",
       "       &#x27;2014-11-01T00:00:00.000000000&#x27;, &#x27;2014-12-01T00:00:00.000000000&#x27;,\n",
       "       &#x27;2015-01-01T00:00:00.000000000&#x27;, &#x27;2015-02-01T00:00:00.000000000&#x27;,\n",
       "       &#x27;2015-03-01T00:00:00.000000000&#x27;, &#x27;2015-04-01T00:00:00.000000000&#x27;,\n",
       "       &#x27;2015-05-01T00:00:00.000000000&#x27;, &#x27;2015-06-01T00:00:00.000000000&#x27;,\n",
       "       &#x27;2015-07-01T00:00:00.000000000&#x27;, &#x27;2015-08-01T00:00:00.000000000&#x27;,\n",
       "       &#x27;2015-09-01T00:00:00.000000000&#x27;, &#x27;2015-10-01T00:00:00.000000000&#x27;,\n",
       "       &#x27;2015-11-01T00:00:00.000000000&#x27;, &#x27;2015-12-01T00:00:00.000000000&#x27;,\n",
       "       &#x27;2016-01-01T00:00:00.000000000&#x27;, &#x27;2016-02-01T00:00:00.000000000&#x27;,\n",
       "       &#x27;2016-03-01T00:00:00.000000000&#x27;, &#x27;2016-04-01T00:00:00.000000000&#x27;,\n",
       "       &#x27;2016-05-01T00:00:00.000000000&#x27;, &#x27;2016-06-01T00:00:00.000000000&#x27;,\n",
       "       &#x27;2016-07-01T00:00:00.000000000&#x27;, &#x27;2016-08-01T00:00:00.000000000&#x27;,\n",
       "       &#x27;2016-09-01T00:00:00.000000000&#x27;, &#x27;2016-10-01T00:00:00.000000000&#x27;,\n",
       "       &#x27;2016-11-01T00:00:00.000000000&#x27;, &#x27;2016-12-01T00:00:00.000000000&#x27;,\n",
       "       &#x27;2017-01-01T00:00:00.000000000&#x27;, &#x27;2017-02-01T00:00:00.000000000&#x27;,\n",
       "       &#x27;2017-03-01T00:00:00.000000000&#x27;, &#x27;2017-04-01T00:00:00.000000000&#x27;,\n",
       "       &#x27;2017-05-01T00:00:00.000000000&#x27;, &#x27;2017-06-01T00:00:00.000000000&#x27;,\n",
       "       &#x27;2017-07-01T00:00:00.000000000&#x27;, &#x27;2017-08-01T00:00:00.000000000&#x27;,\n",
       "       &#x27;2017-09-01T00:00:00.000000000&#x27;, &#x27;2017-10-01T00:00:00.000000000&#x27;,\n",
       "       &#x27;2017-11-01T00:00:00.000000000&#x27;, &#x27;2017-12-01T00:00:00.000000000&#x27;],\n",
       "      dtype=&#x27;datetime64[ns]&#x27;)</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>component</span></div><div class='xr-var-dims'>(component)</div><div class='xr-var-dtype'>&lt;U5</div><div class='xr-var-preview xr-preview'>&#x27;SALES&#x27;</div><input id='attrs-ae81e9e7-e52e-447d-937a-c5dd44f62c7b' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-ae81e9e7-e52e-447d-937a-c5dd44f62c7b' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-e63c6fbf-92f0-4fa1-a41d-00967331f2d3' class='xr-var-data-in' type='checkbox'><label for='data-e63c6fbf-92f0-4fa1-a41d-00967331f2d3' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([&#x27;SALES&#x27;], dtype=&#x27;&lt;U5&#x27;)</pre></div></li></ul></div></li><li class='xr-section-item'><input id='section-0545078f-47a5-48a1-828e-04f1f881565e' class='xr-section-summary-in' type='checkbox'  ><label for='section-0545078f-47a5-48a1-828e-04f1f881565e' class='xr-section-summary' >Indexes: <span>(2)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'><li class='xr-var-item'><div class='xr-index-name'><div>YEAR_MONTH</div></div><div class='xr-index-preview'>PandasIndex</div><div></div><input id='index-7701d011-02e7-416d-ad89-e0943ff2bad4' class='xr-index-data-in' type='checkbox'/><label for='index-7701d011-02e7-416d-ad89-e0943ff2bad4' title='Show/Hide index repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-index-data'><pre>PandasIndex(DatetimeIndex([&#x27;2014-01-01&#x27;, &#x27;2014-02-01&#x27;, &#x27;2014-03-01&#x27;, &#x27;2014-04-01&#x27;,\n",
       "               &#x27;2014-05-01&#x27;, &#x27;2014-06-01&#x27;, &#x27;2014-07-01&#x27;, &#x27;2014-08-01&#x27;,\n",
       "               &#x27;2014-09-01&#x27;, &#x27;2014-10-01&#x27;, &#x27;2014-11-01&#x27;, &#x27;2014-12-01&#x27;,\n",
       "               &#x27;2015-01-01&#x27;, &#x27;2015-02-01&#x27;, &#x27;2015-03-01&#x27;, &#x27;2015-04-01&#x27;,\n",
       "               &#x27;2015-05-01&#x27;, &#x27;2015-06-01&#x27;, &#x27;2015-07-01&#x27;, &#x27;2015-08-01&#x27;,\n",
       "               &#x27;2015-09-01&#x27;, &#x27;2015-10-01&#x27;, &#x27;2015-11-01&#x27;, &#x27;2015-12-01&#x27;,\n",
       "               &#x27;2016-01-01&#x27;, &#x27;2016-02-01&#x27;, &#x27;2016-03-01&#x27;, &#x27;2016-04-01&#x27;,\n",
       "               &#x27;2016-05-01&#x27;, &#x27;2016-06-01&#x27;, &#x27;2016-07-01&#x27;, &#x27;2016-08-01&#x27;,\n",
       "               &#x27;2016-09-01&#x27;, &#x27;2016-10-01&#x27;, &#x27;2016-11-01&#x27;, &#x27;2016-12-01&#x27;,\n",
       "               &#x27;2017-01-01&#x27;, &#x27;2017-02-01&#x27;, &#x27;2017-03-01&#x27;, &#x27;2017-04-01&#x27;,\n",
       "               &#x27;2017-05-01&#x27;, &#x27;2017-06-01&#x27;, &#x27;2017-07-01&#x27;, &#x27;2017-08-01&#x27;,\n",
       "               &#x27;2017-09-01&#x27;, &#x27;2017-10-01&#x27;, &#x27;2017-11-01&#x27;, &#x27;2017-12-01&#x27;],\n",
       "              dtype=&#x27;datetime64[ns]&#x27;, name=&#x27;YEAR_MONTH&#x27;, freq=&#x27;MS&#x27;))</pre></div></li><li class='xr-var-item'><div class='xr-index-name'><div>component</div></div><div class='xr-index-preview'>PandasIndex</div><div></div><input id='index-b10104ef-ec82-4db1-8811-aadea01b9edb' class='xr-index-data-in' type='checkbox'/><label for='index-b10104ef-ec82-4db1-8811-aadea01b9edb' title='Show/Hide index repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-index-data'><pre>PandasIndex(Index([&#x27;SALES&#x27;], dtype=&#x27;object&#x27;, name=&#x27;component&#x27;))</pre></div></li></ul></div></li><li class='xr-section-item'><input id='section-3cefb811-d3e4-4e8c-ab50-534a047f59e9' class='xr-section-summary-in' type='checkbox'  checked><label for='section-3cefb811-d3e4-4e8c-ab50-534a047f59e9' class='xr-section-summary' >Attributes: <span>(3)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><dl class='xr-attrs'><dt><span>static_covariates :</span></dt><dd>None</dd><dt><span>hierarchy :</span></dt><dd>None</dd><dt><span>metadata :</span></dt><dd>None</dd></dl></div></li></ul></div></div>"
      ],
      "text/plain": [
       "<TimeSeries (DataArray) (YEAR_MONTH: 48, component: 1, sample: 1)> Size: 192B\n",
       "array([[[0.42390835]],\n",
       "\n",
       "       [[0.9683219 ]],\n",
       "\n",
       "       [[0.34128845]],\n",
       "\n",
       "       [[0.76412666]],\n",
       "\n",
       "       [[0.9198415 ]],\n",
       "\n",
       "       [[0.9045377 ]],\n",
       "\n",
       "       [[0.49925077]],\n",
       "\n",
       "       [[0.47313786]],\n",
       "\n",
       "       [[0.32416523]],\n",
       "\n",
       "       [[1.        ]],\n",
       "\n",
       "...\n",
       "\n",
       "       [[0.7597388 ]],\n",
       "\n",
       "       [[0.49935782]],\n",
       "\n",
       "       [[0.4005779 ]],\n",
       "\n",
       "       [[0.49850166]],\n",
       "\n",
       "       [[0.29794514]],\n",
       "\n",
       "       [[0.        ]],\n",
       "\n",
       "       [[0.57330906]],\n",
       "\n",
       "       [[0.23234153]],\n",
       "\n",
       "       [[0.77450764]],\n",
       "\n",
       "       [[0.45515835]]], dtype=float32)\n",
       "Coordinates:\n",
       "  * YEAR_MONTH  (YEAR_MONTH) datetime64[ns] 384B 2014-01-01 ... 2017-12-01\n",
       "  * component   (component) <U5 20B 'SALES'\n",
       "Dimensions without coordinates: sample\n",
       "Attributes:\n",
       "    static_covariates:  None\n",
       "    hierarchy:          None\n",
       "    metadata:           None"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scale the data based on the training data\n",
    "from darts.dataprocessing.transformers import Scaler\n",
    "my_scaler = Scaler()\n",
    "train_scaled = my_scaler.fit_transform(train_series)\n",
    "train_scaled\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d0221b3-d256-4d74-9283-d2d748bcf89b",
   "metadata": {},
   "source": [
    "## Listing 22-4. Create default model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e235512e-14fc-49ad-a173-6cab4bb1b101",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 15:57:40 INFO mlflow.tracking.fluent: Autologging successfully enabled for sklearn.\n",
      "2025/06/12 15:57:40 INFO mlflow.tracking.fluent: Autologging successfully enabled for statsmodels.\n",
      "2025/06/12 15:57:41 INFO mlflow.tracking.fluent: Autologging successfully enabled for pytorch_lightning.\n",
      "/opt/anaconda3/envs/chapter22/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2025/06/12 15:57:41 INFO mlflow.tracking.fluent: Autologging successfully enabled for xgboost.\n",
      "/opt/anaconda3/envs/chapter22/lib/python3.9/site-packages/torch/nn/modules/transformer.py:382: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "2025/06/12 15:57:41 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID '53be5543a8a24b109752397eb303c294', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current pytorch workflow\n",
      "\n",
      "  | Name                | Type                | Params | Mode \n",
      "--------------------------------------------------------------------\n",
      "0 | criterion           | MSELoss             | 0      | train\n",
      "1 | train_criterion     | MSELoss             | 0      | train\n",
      "2 | val_criterion       | MSELoss             | 0      | train\n",
      "3 | train_metrics       | MetricCollection    | 0      | train\n",
      "4 | val_metrics         | MetricCollection    | 0      | train\n",
      "5 | encoder             | Linear              | 128    | train\n",
      "6 | positional_encoding | _PositionalEncoding | 0      | train\n",
      "7 | transformer         | Transformer         | 548 K  | train\n",
      "8 | decoder             | Linear              | 780    | train\n",
      "--------------------------------------------------------------------\n",
      "549 K     Trainable params\n",
      "0         Non-trainable params\n",
      "549 K     Total params\n",
      "2.198     Total estimated model params size (MB)\n",
      "88        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "/opt/anaconda3/envs/chapter22/lib/python3.9/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 1/1 [00:00<00:00,  1.97it/s, train_loss=0.459]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 15:57:42 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 1/1 [00:00<00:00, 17.98it/s, train_loss=0.437]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 15:57:42 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 1/1 [00:00<00:00, 19.40it/s, train_loss=0.164]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 15:57:42 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 1/1 [00:00<00:00, 19.89it/s, train_loss=0.145]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 15:57:42 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 19.58it/s, train_loss=0.114]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 15:57:42 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 1/1 [00:00<00:00, 19.33it/s, train_loss=0.0918]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 15:57:42 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 1/1 [00:00<00:00, 20.11it/s, train_loss=0.0903]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 15:57:42 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 1/1 [00:00<00:00, 19.24it/s, train_loss=0.0947]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 15:57:42 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 1/1 [00:00<00:00, 19.95it/s, train_loss=0.0946]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 15:57:42 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 19.43it/s, train_loss=0.0896]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 15:57:42 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 1/1 [00:00<00:00, 19.19it/s, train_loss=0.0818]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 15:57:42 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: 100%|██████████| 1/1 [00:00<00:00, 20.15it/s, train_loss=0.0785]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 15:57:42 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: 100%|██████████| 1/1 [00:00<00:00, 20.44it/s, train_loss=0.0655]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 15:57:42 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: 100%|██████████| 1/1 [00:00<00:00, 19.28it/s, train_loss=0.0683]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 15:57:42 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|██████████| 1/1 [00:00<00:00, 19.21it/s, train_loss=0.0798]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 15:57:42 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15: 100%|██████████| 1/1 [00:00<00:00, 19.65it/s, train_loss=0.0633]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 15:57:42 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16: 100%|██████████| 1/1 [00:00<00:00, 20.37it/s, train_loss=0.0722]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 15:57:43 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17: 100%|██████████| 1/1 [00:00<00:00, 20.06it/s, train_loss=0.0773]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 15:57:43 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18: 100%|██████████| 1/1 [00:00<00:00, 19.33it/s, train_loss=0.0708]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 15:57:43 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 19.86it/s, train_loss=0.0701]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 15:57:43 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n",
      "`Trainer.fit` stopped: `max_epochs=20` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 19.03it/s, train_loss=0.0701]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/06/12 15:57:47 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TransformerModel(output_chunk_shift=0, d_model=64, nhead=4, num_encoder_layers=3, num_decoder_layers=3, dim_feedforward=512, dropout=0.1, activation=relu, norm_type=None, custom_encoder=None, custom_decoder=None, input_chunk_length=24, output_chunk_length=12, n_epochs=20, random_state=123)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use MLFlow autologging for Darts\n",
    "import mlflow\n",
    "mlflow.autolog()\n",
    "\n",
    "# import the TransformerModel\n",
    "from darts.models import TransformerModel\n",
    "\n",
    "# Specifying a default model\n",
    "model = TransformerModel(\n",
    "    # with input chunck length 24 (number of time steps used as input)\n",
    "    input_chunk_length=24,\n",
    "    # with output chunck 12 (number of time steps used as output)\n",
    "    output_chunk_length=12,\n",
    "    n_epochs=20,\n",
    "    random_state=123\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "model.fit(train_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04092442-f074-48b7-9bf5-6a4b077bd89d",
   "metadata": {},
   "source": [
    "## Listing 22-5. Build the forecast and analyze results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9eacf0bf-eb5a-4bf6-833f-fa96d0a402c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 10.74it/s]\n",
      "0.7827418893575668\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x30d1a0f70>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "\n",
    "# Forecast 12 steps using this model\n",
    "fcst = model.predict(12)\n",
    "\n",
    "# Rescale the predictions to the original scale\n",
    "fcst = my_scaler.inverse_transform(fcst).values()\n",
    "\n",
    "# Compute metric\n",
    "metric = 1 - mean_absolute_percentage_error(list(test['SALES']), fcst)\n",
    "print(metric)\n",
    "\n",
    "plt.plot(fcst)\n",
    "plt.plot(list(test['SALES']))\n",
    "plt.legend(['fcst', 'test'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34362db9-6d76-4898-83aa-e62eba766c0c",
   "metadata": {},
   "source": [
    "## Listing 22-6. Create multivariate train test split (future promos not possible)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3d271620-bfab-49ef-8153-877d87993123",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><svg style=\"position: absolute; width: 0; height: 0; overflow: hidden\">\n",
       "<defs>\n",
       "<symbol id=\"icon-database\" viewBox=\"0 0 32 32\">\n",
       "<path d=\"M16 0c-8.837 0-16 2.239-16 5v4c0 2.761 7.163 5 16 5s16-2.239 16-5v-4c0-2.761-7.163-5-16-5z\"></path>\n",
       "<path d=\"M16 17c-8.837 0-16-2.239-16-5v6c0 2.761 7.163 5 16 5s16-2.239 16-5v-6c0 2.761-7.163 5-16 5z\"></path>\n",
       "<path d=\"M16 26c-8.837 0-16-2.239-16-5v6c0 2.761 7.163 5 16 5s16-2.239 16-5v-6c0 2.761-7.163 5-16 5z\"></path>\n",
       "</symbol>\n",
       "<symbol id=\"icon-file-text2\" viewBox=\"0 0 32 32\">\n",
       "<path d=\"M28.681 7.159c-0.694-0.947-1.662-2.053-2.724-3.116s-2.169-2.030-3.116-2.724c-1.612-1.182-2.393-1.319-2.841-1.319h-15.5c-1.378 0-2.5 1.121-2.5 2.5v27c0 1.378 1.122 2.5 2.5 2.5h23c1.378 0 2.5-1.122 2.5-2.5v-19.5c0-0.448-0.137-1.23-1.319-2.841zM24.543 5.457c0.959 0.959 1.712 1.825 2.268 2.543h-4.811v-4.811c0.718 0.556 1.584 1.309 2.543 2.268zM28 29.5c0 0.271-0.229 0.5-0.5 0.5h-23c-0.271 0-0.5-0.229-0.5-0.5v-27c0-0.271 0.229-0.5 0.5-0.5 0 0 15.499-0 15.5 0v7c0 0.552 0.448 1 1 1h7v19.5z\"></path>\n",
       "<path d=\"M23 26h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "<path d=\"M23 22h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "<path d=\"M23 18h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "</symbol>\n",
       "</defs>\n",
       "</svg>\n",
       "<style>/* CSS stylesheet for displaying xarray objects in jupyterlab.\n",
       " *\n",
       " */\n",
       "\n",
       ":root {\n",
       "  --xr-font-color0: var(--jp-content-font-color0, rgba(0, 0, 0, 1));\n",
       "  --xr-font-color2: var(--jp-content-font-color2, rgba(0, 0, 0, 0.54));\n",
       "  --xr-font-color3: var(--jp-content-font-color3, rgba(0, 0, 0, 0.38));\n",
       "  --xr-border-color: var(--jp-border-color2, #e0e0e0);\n",
       "  --xr-disabled-color: var(--jp-layout-color3, #bdbdbd);\n",
       "  --xr-background-color: var(--jp-layout-color0, white);\n",
       "  --xr-background-color-row-even: var(--jp-layout-color1, white);\n",
       "  --xr-background-color-row-odd: var(--jp-layout-color2, #eeeeee);\n",
       "}\n",
       "\n",
       "html[theme=dark],\n",
       "html[data-theme=dark],\n",
       "body[data-theme=dark],\n",
       "body.vscode-dark {\n",
       "  --xr-font-color0: rgba(255, 255, 255, 1);\n",
       "  --xr-font-color2: rgba(255, 255, 255, 0.54);\n",
       "  --xr-font-color3: rgba(255, 255, 255, 0.38);\n",
       "  --xr-border-color: #1F1F1F;\n",
       "  --xr-disabled-color: #515151;\n",
       "  --xr-background-color: #111111;\n",
       "  --xr-background-color-row-even: #111111;\n",
       "  --xr-background-color-row-odd: #313131;\n",
       "}\n",
       "\n",
       ".xr-wrap {\n",
       "  display: block !important;\n",
       "  min-width: 300px;\n",
       "  max-width: 700px;\n",
       "}\n",
       "\n",
       ".xr-text-repr-fallback {\n",
       "  /* fallback to plain text repr when CSS is not injected (untrusted notebook) */\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-header {\n",
       "  padding-top: 6px;\n",
       "  padding-bottom: 6px;\n",
       "  margin-bottom: 4px;\n",
       "  border-bottom: solid 1px var(--xr-border-color);\n",
       "}\n",
       "\n",
       ".xr-header > div,\n",
       ".xr-header > ul {\n",
       "  display: inline;\n",
       "  margin-top: 0;\n",
       "  margin-bottom: 0;\n",
       "}\n",
       "\n",
       ".xr-obj-type,\n",
       ".xr-array-name {\n",
       "  margin-left: 2px;\n",
       "  margin-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-obj-type {\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-sections {\n",
       "  padding-left: 0 !important;\n",
       "  display: grid;\n",
       "  grid-template-columns: 150px auto auto 1fr 20px 20px;\n",
       "}\n",
       "\n",
       ".xr-section-item {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-section-item input {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-section-item input + label {\n",
       "  color: var(--xr-disabled-color);\n",
       "}\n",
       "\n",
       ".xr-section-item input:enabled + label {\n",
       "  cursor: pointer;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-section-item input:enabled + label:hover {\n",
       "  color: var(--xr-font-color0);\n",
       "}\n",
       "\n",
       ".xr-section-summary {\n",
       "  grid-column: 1;\n",
       "  color: var(--xr-font-color2);\n",
       "  font-weight: 500;\n",
       "}\n",
       "\n",
       ".xr-section-summary > span {\n",
       "  display: inline-block;\n",
       "  padding-left: 0.5em;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:disabled + label {\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-section-summary-in + label:before {\n",
       "  display: inline-block;\n",
       "  content: '►';\n",
       "  font-size: 11px;\n",
       "  width: 15px;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:disabled + label:before {\n",
       "  color: var(--xr-disabled-color);\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked + label:before {\n",
       "  content: '▼';\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked + label > span {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-section-summary,\n",
       ".xr-section-inline-details {\n",
       "  padding-top: 4px;\n",
       "  padding-bottom: 4px;\n",
       "}\n",
       "\n",
       ".xr-section-inline-details {\n",
       "  grid-column: 2 / -1;\n",
       "}\n",
       "\n",
       ".xr-section-details {\n",
       "  display: none;\n",
       "  grid-column: 1 / -1;\n",
       "  margin-bottom: 5px;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked ~ .xr-section-details {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-array-wrap {\n",
       "  grid-column: 1 / -1;\n",
       "  display: grid;\n",
       "  grid-template-columns: 20px auto;\n",
       "}\n",
       "\n",
       ".xr-array-wrap > label {\n",
       "  grid-column: 1;\n",
       "  vertical-align: top;\n",
       "}\n",
       "\n",
       ".xr-preview {\n",
       "  color: var(--xr-font-color3);\n",
       "}\n",
       "\n",
       ".xr-array-preview,\n",
       ".xr-array-data {\n",
       "  padding: 0 5px !important;\n",
       "  grid-column: 2;\n",
       "}\n",
       "\n",
       ".xr-array-data,\n",
       ".xr-array-in:checked ~ .xr-array-preview {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-array-in:checked ~ .xr-array-data,\n",
       ".xr-array-preview {\n",
       "  display: inline-block;\n",
       "}\n",
       "\n",
       ".xr-dim-list {\n",
       "  display: inline-block !important;\n",
       "  list-style: none;\n",
       "  padding: 0 !important;\n",
       "  margin: 0;\n",
       "}\n",
       "\n",
       ".xr-dim-list li {\n",
       "  display: inline-block;\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "}\n",
       "\n",
       ".xr-dim-list:before {\n",
       "  content: '(';\n",
       "}\n",
       "\n",
       ".xr-dim-list:after {\n",
       "  content: ')';\n",
       "}\n",
       "\n",
       ".xr-dim-list li:not(:last-child):after {\n",
       "  content: ',';\n",
       "  padding-right: 5px;\n",
       "}\n",
       "\n",
       ".xr-has-index {\n",
       "  font-weight: bold;\n",
       "}\n",
       "\n",
       ".xr-var-list,\n",
       ".xr-var-item {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-var-item > div,\n",
       ".xr-var-item label,\n",
       ".xr-var-item > .xr-var-name span {\n",
       "  background-color: var(--xr-background-color-row-even);\n",
       "  margin-bottom: 0;\n",
       "}\n",
       "\n",
       ".xr-var-item > .xr-var-name:hover span {\n",
       "  padding-right: 5px;\n",
       "}\n",
       "\n",
       ".xr-var-list > li:nth-child(odd) > div,\n",
       ".xr-var-list > li:nth-child(odd) > label,\n",
       ".xr-var-list > li:nth-child(odd) > .xr-var-name span {\n",
       "  background-color: var(--xr-background-color-row-odd);\n",
       "}\n",
       "\n",
       ".xr-var-name {\n",
       "  grid-column: 1;\n",
       "}\n",
       "\n",
       ".xr-var-dims {\n",
       "  grid-column: 2;\n",
       "}\n",
       "\n",
       ".xr-var-dtype {\n",
       "  grid-column: 3;\n",
       "  text-align: right;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-var-preview {\n",
       "  grid-column: 4;\n",
       "}\n",
       "\n",
       ".xr-index-preview {\n",
       "  grid-column: 2 / 5;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-var-name,\n",
       ".xr-var-dims,\n",
       ".xr-var-dtype,\n",
       ".xr-preview,\n",
       ".xr-attrs dt {\n",
       "  white-space: nowrap;\n",
       "  overflow: hidden;\n",
       "  text-overflow: ellipsis;\n",
       "  padding-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-var-name:hover,\n",
       ".xr-var-dims:hover,\n",
       ".xr-var-dtype:hover,\n",
       ".xr-attrs dt:hover {\n",
       "  overflow: visible;\n",
       "  width: auto;\n",
       "  z-index: 1;\n",
       "}\n",
       "\n",
       ".xr-var-attrs,\n",
       ".xr-var-data,\n",
       ".xr-index-data {\n",
       "  display: none;\n",
       "  background-color: var(--xr-background-color) !important;\n",
       "  padding-bottom: 5px !important;\n",
       "}\n",
       "\n",
       ".xr-var-attrs-in:checked ~ .xr-var-attrs,\n",
       ".xr-var-data-in:checked ~ .xr-var-data,\n",
       ".xr-index-data-in:checked ~ .xr-index-data {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       ".xr-var-data > table {\n",
       "  float: right;\n",
       "}\n",
       "\n",
       ".xr-var-name span,\n",
       ".xr-var-data,\n",
       ".xr-index-name div,\n",
       ".xr-index-data,\n",
       ".xr-attrs {\n",
       "  padding-left: 25px !important;\n",
       "}\n",
       "\n",
       ".xr-attrs,\n",
       ".xr-var-attrs,\n",
       ".xr-var-data,\n",
       ".xr-index-data {\n",
       "  grid-column: 1 / -1;\n",
       "}\n",
       "\n",
       "dl.xr-attrs {\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "  display: grid;\n",
       "  grid-template-columns: 125px auto;\n",
       "}\n",
       "\n",
       ".xr-attrs dt,\n",
       ".xr-attrs dd {\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "  float: left;\n",
       "  padding-right: 10px;\n",
       "  width: auto;\n",
       "}\n",
       "\n",
       ".xr-attrs dt {\n",
       "  font-weight: normal;\n",
       "  grid-column: 1;\n",
       "}\n",
       "\n",
       ".xr-attrs dt:hover span {\n",
       "  display: inline-block;\n",
       "  background: var(--xr-background-color);\n",
       "  padding-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-attrs dd {\n",
       "  grid-column: 2;\n",
       "  white-space: pre-wrap;\n",
       "  word-break: break-all;\n",
       "}\n",
       "\n",
       ".xr-icon-database,\n",
       ".xr-icon-file-text2,\n",
       ".xr-no-icon {\n",
       "  display: inline-block;\n",
       "  vertical-align: middle;\n",
       "  width: 1em;\n",
       "  height: 1.5em !important;\n",
       "  stroke-width: 0;\n",
       "  stroke: currentColor;\n",
       "  fill: currentColor;\n",
       "}\n",
       "</style><pre class='xr-text-repr-fallback'>&lt;TimeSeries (DataArray) (YEAR_MONTH: 48, component: 1, sample: 1)&gt; Size: 192B\n",
       "array([[[0.08514488]],\n",
       "\n",
       "       [[0.39221013]],\n",
       "\n",
       "       [[0.        ]],\n",
       "\n",
       "       [[0.30706525]],\n",
       "\n",
       "       [[0.414855  ]],\n",
       "\n",
       "       [[0.46014488]],\n",
       "\n",
       "       [[0.29981887]],\n",
       "\n",
       "       [[1.        ]],\n",
       "\n",
       "       [[0.07699275]],\n",
       "\n",
       "       [[0.384058  ]],\n",
       "\n",
       "...\n",
       "\n",
       "       [[0.41123188]],\n",
       "\n",
       "       [[0.37862313]],\n",
       "\n",
       "       [[0.4574275 ]],\n",
       "\n",
       "       [[0.35144925]],\n",
       "\n",
       "       [[0.6277174 ]],\n",
       "\n",
       "       [[0.24818838]],\n",
       "\n",
       "       [[0.6123189 ]],\n",
       "\n",
       "       [[0.49456525]],\n",
       "\n",
       "       [[0.5942029 ]],\n",
       "\n",
       "       [[0.5742754 ]]], dtype=float32)\n",
       "Coordinates:\n",
       "  * YEAR_MONTH  (YEAR_MONTH) datetime64[ns] 384B 2014-01-01 ... 2017-12-01\n",
       "  * component   (component) &lt;U5 20B &#x27;PROMO&#x27;\n",
       "Dimensions without coordinates: sample\n",
       "Attributes:\n",
       "    static_covariates:  None\n",
       "    hierarchy:          None\n",
       "    metadata:           None</pre><div class='xr-wrap' style='display:none'><div class='xr-header'><div class='xr-obj-type'>TimeSeries (DataArray)</div><div class='xr-array-name'></div><ul class='xr-dim-list'><li><span class='xr-has-index'>YEAR_MONTH</span>: 48</li><li><span class='xr-has-index'>component</span>: 1</li><li><span>sample</span>: 1</li></ul></div><ul class='xr-sections'><li class='xr-section-item'><div class='xr-array-wrap'><input id='section-3a67a3d1-dd0f-42bc-8d15-665dcf1c0b8d' class='xr-array-in' type='checkbox' checked><label for='section-3a67a3d1-dd0f-42bc-8d15-665dcf1c0b8d' title='Show/hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-array-preview xr-preview'><span>0.08514 0.3922 0.0 0.3071 0.4149 ... 0.6123 0.4946 0.5942 0.5743</span></div><div class='xr-array-data'><pre>array([[[0.08514488]],\n",
       "\n",
       "       [[0.39221013]],\n",
       "\n",
       "       [[0.        ]],\n",
       "\n",
       "       [[0.30706525]],\n",
       "\n",
       "       [[0.414855  ]],\n",
       "\n",
       "       [[0.46014488]],\n",
       "\n",
       "       [[0.29981887]],\n",
       "\n",
       "       [[1.        ]],\n",
       "\n",
       "       [[0.07699275]],\n",
       "\n",
       "       [[0.384058  ]],\n",
       "\n",
       "...\n",
       "\n",
       "       [[0.41123188]],\n",
       "\n",
       "       [[0.37862313]],\n",
       "\n",
       "       [[0.4574275 ]],\n",
       "\n",
       "       [[0.35144925]],\n",
       "\n",
       "       [[0.6277174 ]],\n",
       "\n",
       "       [[0.24818838]],\n",
       "\n",
       "       [[0.6123189 ]],\n",
       "\n",
       "       [[0.49456525]],\n",
       "\n",
       "       [[0.5942029 ]],\n",
       "\n",
       "       [[0.5742754 ]]], dtype=float32)</pre></div></div></li><li class='xr-section-item'><input id='section-8ac6451d-ef19-470c-a1a4-8a22d2354468' class='xr-section-summary-in' type='checkbox'  checked><label for='section-8ac6451d-ef19-470c-a1a4-8a22d2354468' class='xr-section-summary' >Coordinates: <span>(2)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>YEAR_MONTH</span></div><div class='xr-var-dims'>(YEAR_MONTH)</div><div class='xr-var-dtype'>datetime64[ns]</div><div class='xr-var-preview xr-preview'>2014-01-01 ... 2017-12-01</div><input id='attrs-1a9da374-7aaa-4186-8de3-0f99d160a7f3' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-1a9da374-7aaa-4186-8de3-0f99d160a7f3' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-9eb949b2-5c46-4f4e-9faa-f5040f014635' class='xr-var-data-in' type='checkbox'><label for='data-9eb949b2-5c46-4f4e-9faa-f5040f014635' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([&#x27;2014-01-01T00:00:00.000000000&#x27;, &#x27;2014-02-01T00:00:00.000000000&#x27;,\n",
       "       &#x27;2014-03-01T00:00:00.000000000&#x27;, &#x27;2014-04-01T00:00:00.000000000&#x27;,\n",
       "       &#x27;2014-05-01T00:00:00.000000000&#x27;, &#x27;2014-06-01T00:00:00.000000000&#x27;,\n",
       "       &#x27;2014-07-01T00:00:00.000000000&#x27;, &#x27;2014-08-01T00:00:00.000000000&#x27;,\n",
       "       &#x27;2014-09-01T00:00:00.000000000&#x27;, &#x27;2014-10-01T00:00:00.000000000&#x27;,\n",
       "       &#x27;2014-11-01T00:00:00.000000000&#x27;, &#x27;2014-12-01T00:00:00.000000000&#x27;,\n",
       "       &#x27;2015-01-01T00:00:00.000000000&#x27;, &#x27;2015-02-01T00:00:00.000000000&#x27;,\n",
       "       &#x27;2015-03-01T00:00:00.000000000&#x27;, &#x27;2015-04-01T00:00:00.000000000&#x27;,\n",
       "       &#x27;2015-05-01T00:00:00.000000000&#x27;, &#x27;2015-06-01T00:00:00.000000000&#x27;,\n",
       "       &#x27;2015-07-01T00:00:00.000000000&#x27;, &#x27;2015-08-01T00:00:00.000000000&#x27;,\n",
       "       &#x27;2015-09-01T00:00:00.000000000&#x27;, &#x27;2015-10-01T00:00:00.000000000&#x27;,\n",
       "       &#x27;2015-11-01T00:00:00.000000000&#x27;, &#x27;2015-12-01T00:00:00.000000000&#x27;,\n",
       "       &#x27;2016-01-01T00:00:00.000000000&#x27;, &#x27;2016-02-01T00:00:00.000000000&#x27;,\n",
       "       &#x27;2016-03-01T00:00:00.000000000&#x27;, &#x27;2016-04-01T00:00:00.000000000&#x27;,\n",
       "       &#x27;2016-05-01T00:00:00.000000000&#x27;, &#x27;2016-06-01T00:00:00.000000000&#x27;,\n",
       "       &#x27;2016-07-01T00:00:00.000000000&#x27;, &#x27;2016-08-01T00:00:00.000000000&#x27;,\n",
       "       &#x27;2016-09-01T00:00:00.000000000&#x27;, &#x27;2016-10-01T00:00:00.000000000&#x27;,\n",
       "       &#x27;2016-11-01T00:00:00.000000000&#x27;, &#x27;2016-12-01T00:00:00.000000000&#x27;,\n",
       "       &#x27;2017-01-01T00:00:00.000000000&#x27;, &#x27;2017-02-01T00:00:00.000000000&#x27;,\n",
       "       &#x27;2017-03-01T00:00:00.000000000&#x27;, &#x27;2017-04-01T00:00:00.000000000&#x27;,\n",
       "       &#x27;2017-05-01T00:00:00.000000000&#x27;, &#x27;2017-06-01T00:00:00.000000000&#x27;,\n",
       "       &#x27;2017-07-01T00:00:00.000000000&#x27;, &#x27;2017-08-01T00:00:00.000000000&#x27;,\n",
       "       &#x27;2017-09-01T00:00:00.000000000&#x27;, &#x27;2017-10-01T00:00:00.000000000&#x27;,\n",
       "       &#x27;2017-11-01T00:00:00.000000000&#x27;, &#x27;2017-12-01T00:00:00.000000000&#x27;],\n",
       "      dtype=&#x27;datetime64[ns]&#x27;)</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>component</span></div><div class='xr-var-dims'>(component)</div><div class='xr-var-dtype'>&lt;U5</div><div class='xr-var-preview xr-preview'>&#x27;PROMO&#x27;</div><input id='attrs-06614d3e-3a06-4835-be75-bbf313b3a387' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-06614d3e-3a06-4835-be75-bbf313b3a387' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-1ab7383a-0403-42c8-b551-e8f7e7604ad4' class='xr-var-data-in' type='checkbox'><label for='data-1ab7383a-0403-42c8-b551-e8f7e7604ad4' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([&#x27;PROMO&#x27;], dtype=&#x27;&lt;U5&#x27;)</pre></div></li></ul></div></li><li class='xr-section-item'><input id='section-99f0ebed-4456-4474-8ce0-cba6bb535379' class='xr-section-summary-in' type='checkbox'  ><label for='section-99f0ebed-4456-4474-8ce0-cba6bb535379' class='xr-section-summary' >Indexes: <span>(2)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'><li class='xr-var-item'><div class='xr-index-name'><div>YEAR_MONTH</div></div><div class='xr-index-preview'>PandasIndex</div><div></div><input id='index-b664bffc-8ded-4ab1-9740-db01bbe01449' class='xr-index-data-in' type='checkbox'/><label for='index-b664bffc-8ded-4ab1-9740-db01bbe01449' title='Show/Hide index repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-index-data'><pre>PandasIndex(DatetimeIndex([&#x27;2014-01-01&#x27;, &#x27;2014-02-01&#x27;, &#x27;2014-03-01&#x27;, &#x27;2014-04-01&#x27;,\n",
       "               &#x27;2014-05-01&#x27;, &#x27;2014-06-01&#x27;, &#x27;2014-07-01&#x27;, &#x27;2014-08-01&#x27;,\n",
       "               &#x27;2014-09-01&#x27;, &#x27;2014-10-01&#x27;, &#x27;2014-11-01&#x27;, &#x27;2014-12-01&#x27;,\n",
       "               &#x27;2015-01-01&#x27;, &#x27;2015-02-01&#x27;, &#x27;2015-03-01&#x27;, &#x27;2015-04-01&#x27;,\n",
       "               &#x27;2015-05-01&#x27;, &#x27;2015-06-01&#x27;, &#x27;2015-07-01&#x27;, &#x27;2015-08-01&#x27;,\n",
       "               &#x27;2015-09-01&#x27;, &#x27;2015-10-01&#x27;, &#x27;2015-11-01&#x27;, &#x27;2015-12-01&#x27;,\n",
       "               &#x27;2016-01-01&#x27;, &#x27;2016-02-01&#x27;, &#x27;2016-03-01&#x27;, &#x27;2016-04-01&#x27;,\n",
       "               &#x27;2016-05-01&#x27;, &#x27;2016-06-01&#x27;, &#x27;2016-07-01&#x27;, &#x27;2016-08-01&#x27;,\n",
       "               &#x27;2016-09-01&#x27;, &#x27;2016-10-01&#x27;, &#x27;2016-11-01&#x27;, &#x27;2016-12-01&#x27;,\n",
       "               &#x27;2017-01-01&#x27;, &#x27;2017-02-01&#x27;, &#x27;2017-03-01&#x27;, &#x27;2017-04-01&#x27;,\n",
       "               &#x27;2017-05-01&#x27;, &#x27;2017-06-01&#x27;, &#x27;2017-07-01&#x27;, &#x27;2017-08-01&#x27;,\n",
       "               &#x27;2017-09-01&#x27;, &#x27;2017-10-01&#x27;, &#x27;2017-11-01&#x27;, &#x27;2017-12-01&#x27;],\n",
       "              dtype=&#x27;datetime64[ns]&#x27;, name=&#x27;YEAR_MONTH&#x27;, freq=&#x27;MS&#x27;))</pre></div></li><li class='xr-var-item'><div class='xr-index-name'><div>component</div></div><div class='xr-index-preview'>PandasIndex</div><div></div><input id='index-2e74dade-0f46-4e8e-ba8a-af5c444a8240' class='xr-index-data-in' type='checkbox'/><label for='index-2e74dade-0f46-4e8e-ba8a-af5c444a8240' title='Show/Hide index repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-index-data'><pre>PandasIndex(Index([&#x27;PROMO&#x27;], dtype=&#x27;object&#x27;, name=&#x27;component&#x27;))</pre></div></li></ul></div></li><li class='xr-section-item'><input id='section-cee1377e-c842-41ff-a28e-b85f566b4cf4' class='xr-section-summary-in' type='checkbox'  checked><label for='section-cee1377e-c842-41ff-a28e-b85f566b4cf4' class='xr-section-summary' >Attributes: <span>(3)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><dl class='xr-attrs'><dt><span>static_covariates :</span></dt><dd>None</dd><dt><span>hierarchy :</span></dt><dd>None</dd><dt><span>metadata :</span></dt><dd>None</dd></dl></div></li></ul></div></div>"
      ],
      "text/plain": [
       "<TimeSeries (DataArray) (YEAR_MONTH: 48, component: 1, sample: 1)> Size: 192B\n",
       "array([[[0.08514488]],\n",
       "\n",
       "       [[0.39221013]],\n",
       "\n",
       "       [[0.        ]],\n",
       "\n",
       "       [[0.30706525]],\n",
       "\n",
       "       [[0.414855  ]],\n",
       "\n",
       "       [[0.46014488]],\n",
       "\n",
       "       [[0.29981887]],\n",
       "\n",
       "       [[1.        ]],\n",
       "\n",
       "       [[0.07699275]],\n",
       "\n",
       "       [[0.384058  ]],\n",
       "\n",
       "...\n",
       "\n",
       "       [[0.41123188]],\n",
       "\n",
       "       [[0.37862313]],\n",
       "\n",
       "       [[0.4574275 ]],\n",
       "\n",
       "       [[0.35144925]],\n",
       "\n",
       "       [[0.6277174 ]],\n",
       "\n",
       "       [[0.24818838]],\n",
       "\n",
       "       [[0.6123189 ]],\n",
       "\n",
       "       [[0.49456525]],\n",
       "\n",
       "       [[0.5942029 ]],\n",
       "\n",
       "       [[0.5742754 ]]], dtype=float32)\n",
       "Coordinates:\n",
       "  * YEAR_MONTH  (YEAR_MONTH) datetime64[ns] 384B 2014-01-01 ... 2017-12-01\n",
       "  * component   (component) <U5 20B 'PROMO'\n",
       "Dimensions without coordinates: sample\n",
       "Attributes:\n",
       "    static_covariates:  None\n",
       "    hierarchy:          None\n",
       "    metadata:           None"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sum['PROMO'] = df_sum['PROMO'].map(np.float32)\n",
    "\n",
    "# Convert the training data to a Darts time series\n",
    "promos_train = TimeSeries.from_dataframe(train[['PROMO']])\n",
    "\n",
    "# Convert to float32 for Darts\n",
    "promos_train = promos_train.astype(np.float32)\n",
    "\n",
    "promo_scaler = Scaler()\n",
    "promos_train = promo_scaler.fit_transform(promos_train)\n",
    "promos_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f314c8d1-aa77-443b-80b0-571d35158283",
   "metadata": {},
   "source": [
    "## Listing 22-7 Create multivariate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c442bc58-62c8-400c-bc9d-964ac6f77027",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/chapter22/lib/python3.9/site-packages/torch/nn/modules/transformer.py:382: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "2025/06/12 16:06:49 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID '12e3ac97729f464c9665a7786c3c724c', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current pytorch workflow\n",
      "\n",
      "  | Name                | Type                | Params | Mode \n",
      "--------------------------------------------------------------------\n",
      "0 | criterion           | MSELoss             | 0      | train\n",
      "1 | train_criterion     | MSELoss             | 0      | train\n",
      "2 | val_criterion       | MSELoss             | 0      | train\n",
      "3 | train_metrics       | MetricCollection    | 0      | train\n",
      "4 | val_metrics         | MetricCollection    | 0      | train\n",
      "5 | encoder             | Linear              | 192    | train\n",
      "6 | positional_encoding | _PositionalEncoding | 0      | train\n",
      "7 | transformer         | Transformer         | 548 K  | train\n",
      "8 | decoder             | Linear              | 780    | train\n",
      "--------------------------------------------------------------------\n",
      "549 K     Trainable params\n",
      "0         Non-trainable params\n",
      "549 K     Total params\n",
      "2.198     Total estimated model params size (MB)\n",
      "88        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "/opt/anaconda3/envs/chapter22/lib/python3.9/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 1/1 [00:00<00:00, 15.15it/s, train_loss=0.689]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 16:06:49 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 1/1 [00:00<00:00, 17.77it/s, train_loss=0.493]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 16:06:49 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 1/1 [00:00<00:00, 18.15it/s, train_loss=0.210]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 16:06:50 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 1/1 [00:00<00:00, 17.76it/s, train_loss=0.136]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 16:06:50 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 18.07it/s, train_loss=0.0828]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 16:06:50 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 1/1 [00:00<00:00, 18.55it/s, train_loss=0.0801]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 16:06:50 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 1/1 [00:00<00:00, 18.28it/s, train_loss=0.0878]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 16:06:50 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 1/1 [00:00<00:00, 18.41it/s, train_loss=0.0903]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 16:06:50 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 1/1 [00:00<00:00, 18.33it/s, train_loss=0.0887]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 16:06:50 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 18.32it/s, train_loss=0.100] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 16:06:50 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 1/1 [00:00<00:00, 18.44it/s, train_loss=0.0834]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 16:06:50 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: 100%|██████████| 1/1 [00:00<00:00, 17.42it/s, train_loss=0.0716]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 16:06:50 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: 100%|██████████| 1/1 [00:00<00:00, 17.95it/s, train_loss=0.0589]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 16:06:50 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: 100%|██████████| 1/1 [00:00<00:00, 18.00it/s, train_loss=0.0763]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 16:06:50 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|██████████| 1/1 [00:00<00:00, 18.19it/s, train_loss=0.0594]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 16:06:50 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15: 100%|██████████| 1/1 [00:00<00:00, 17.37it/s, train_loss=0.0541]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 16:06:50 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16: 100%|██████████| 1/1 [00:00<00:00, 16.98it/s, train_loss=0.0739]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 16:06:50 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17: 100%|██████████| 1/1 [00:00<00:00, 16.98it/s, train_loss=0.0728]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 16:06:50 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18: 100%|██████████| 1/1 [00:00<00:00, 17.57it/s, train_loss=0.0665]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 16:06:50 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 18.04it/s, train_loss=0.0646]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 16:06:50 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n",
      "`Trainer.fit` stopped: `max_epochs=20` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 17.37it/s, train_loss=0.0646]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/06/12 16:06:55 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 91.49it/s]\n",
      "0.8098367005586624\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x32257b9d0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Specifying a default model\n",
    "model = TransformerModel(\n",
    "    # with input chunck length 24 (number of time steps used as input)\n",
    "    input_chunk_length=24,\n",
    "    # with output chunck 12 (number of time steps used as output)\n",
    "    output_chunk_length=12,\n",
    "    n_epochs=20,\n",
    "    random_state=123   \n",
    ")\n",
    "\n",
    "# Train the model\n",
    "model.fit(\n",
    "    train_scaled,\n",
    "    \n",
    "    # add the promotions as past covariates\n",
    "    past_covariates=promos_train\n",
    ")\n",
    "\n",
    "\n",
    "# Forecast 12 steps using this model\n",
    "fcst = model.predict(\n",
    "    n=12,\n",
    "\n",
    "    # add past covariates (promos train)\n",
    "    past_covariates=promos_train,\n",
    ")\n",
    "\n",
    "\n",
    "# Rescale the predictions to the original scale\n",
    "fcst = my_scaler.inverse_transform(fcst).values()\n",
    "\n",
    "# Compute metric\n",
    "metric = 1 - mean_absolute_percentage_error(list(test['SALES']), fcst)\n",
    "print(metric)\n",
    "\n",
    "plt.plot(fcst)\n",
    "plt.plot(list(test['SALES']))\n",
    "plt.legend(['fcst', 'test'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f1fd58f-26f0-4dd6-b432-1a6145f083b8",
   "metadata": {},
   "source": [
    "## Listing 22-8. Tune multivariate model hyperparameters and analyze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b17b7bd7-66ed-40ee-8c2d-b76f1b0f2c96",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/chapter22/lib/python3.9/site-packages/torch/nn/modules/transformer.py:382: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "2025/06/12 17:13:01 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID '173f42e085874bc7a4b51770814e6c07', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current pytorch workflow\n",
      "\n",
      "  | Name                | Type                | Params | Mode \n",
      "--------------------------------------------------------------------\n",
      "0 | criterion           | MSELoss             | 0      | train\n",
      "1 | train_criterion     | MSELoss             | 0      | train\n",
      "2 | val_criterion       | MSELoss             | 0      | train\n",
      "3 | train_metrics       | MetricCollection    | 0      | train\n",
      "4 | val_metrics         | MetricCollection    | 0      | train\n",
      "5 | encoder             | Linear              | 96     | train\n",
      "6 | positional_encoding | _PositionalEncoding | 0      | train\n",
      "7 | transformer         | Transformer         | 201 K  | train\n",
      "8 | decoder             | Linear              | 396    | train\n",
      "--------------------------------------------------------------------\n",
      "201 K     Trainable params\n",
      "0         Non-trainable params\n",
      "201 K     Total params\n",
      "0.807     Total estimated model params size (MB)\n",
      "78        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "/opt/anaconda3/envs/chapter22/lib/python3.9/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 1/1 [00:00<00:00, 10.42it/s, train_loss=0.666]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:13:01 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 1/1 [00:00<00:00, 18.30it/s, train_loss=0.343]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:13:01 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 1/1 [00:00<00:00, 17.68it/s, train_loss=0.174]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:13:01 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 1/1 [00:00<00:00, 18.33it/s, train_loss=0.155]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:13:01 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 18.49it/s, train_loss=0.141]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:13:01 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n",
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 17.48it/s, train_loss=0.141]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/06/12 17:13:06 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 67.48it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/chapter22/lib/python3.9/site-packages/torch/nn/modules/transformer.py:382: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "2025/06/12 17:13:06 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID 'ad67763ab7b74435ab3b458d57b047ab', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current pytorch workflow\n",
      "\n",
      "  | Name                | Type                | Params | Mode \n",
      "--------------------------------------------------------------------\n",
      "0 | criterion           | MSELoss             | 0      | train\n",
      "1 | train_criterion     | MSELoss             | 0      | train\n",
      "2 | val_criterion       | MSELoss             | 0      | train\n",
      "3 | train_metrics       | MetricCollection    | 0      | train\n",
      "4 | val_metrics         | MetricCollection    | 0      | train\n",
      "5 | encoder             | Linear              | 96     | train\n",
      "6 | positional_encoding | _PositionalEncoding | 0      | train\n",
      "7 | transformer         | Transformer         | 243 K  | train\n",
      "8 | decoder             | Linear              | 396    | train\n",
      "--------------------------------------------------------------------\n",
      "243 K     Trainable params\n",
      "0         Non-trainable params\n",
      "243 K     Total params\n",
      "0.975     Total estimated model params size (MB)\n",
      "92        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "/opt/anaconda3/envs/chapter22/lib/python3.9/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 0: 100%|██████████| 1/1 [00:00<00:00, 13.69it/s, train_loss=1.030]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:13:06 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 1/1 [00:00<00:00, 14.91it/s, train_loss=0.329]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:13:06 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 1/1 [00:00<00:00, 16.32it/s, train_loss=0.202]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:13:06 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 1/1 [00:00<00:00, 17.04it/s, train_loss=0.125]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:13:06 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 15.93it/s, train_loss=0.0905]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:13:06 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n",
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 15.31it/s, train_loss=0.0905]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/06/12 17:13:10 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 87.93it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/chapter22/lib/python3.9/site-packages/torch/nn/modules/transformer.py:382: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "2025/06/12 17:13:10 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID 'b135b622acc443c2a417f69967840244', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current pytorch workflow\n",
      "\n",
      "  | Name                | Type                | Params | Mode \n",
      "--------------------------------------------------------------------\n",
      "0 | criterion           | MSELoss             | 0      | train\n",
      "1 | train_criterion     | MSELoss             | 0      | train\n",
      "2 | val_criterion       | MSELoss             | 0      | train\n",
      "3 | train_metrics       | MetricCollection    | 0      | train\n",
      "4 | val_metrics         | MetricCollection    | 0      | train\n",
      "5 | encoder             | Linear              | 96     | train\n",
      "6 | positional_encoding | _PositionalEncoding | 0      | train\n",
      "7 | transformer         | Transformer         | 238 K  | train\n",
      "8 | decoder             | Linear              | 396    | train\n",
      "--------------------------------------------------------------------\n",
      "239 K     Trainable params\n",
      "0         Non-trainable params\n",
      "239 K     Total params\n",
      "0.958     Total estimated model params size (MB)\n",
      "88        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "/opt/anaconda3/envs/chapter22/lib/python3.9/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 0: 100%|██████████| 1/1 [00:00<00:00, 15.10it/s, train_loss=0.886]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:13:10 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 1/1 [00:00<00:00, 16.38it/s, train_loss=0.352]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:13:10 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 1/1 [00:00<00:00, 16.56it/s, train_loss=0.168]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:13:11 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 1/1 [00:00<00:00, 16.17it/s, train_loss=0.109]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:13:11 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 16.59it/s, train_loss=0.112]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:13:11 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n",
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 15.87it/s, train_loss=0.112]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/06/12 17:13:15 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 77.30it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/chapter22/lib/python3.9/site-packages/torch/nn/modules/transformer.py:382: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "2025/06/12 17:13:15 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID '1611574821fc4ffdbe2b4f49ed4322e7', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current pytorch workflow\n",
      "\n",
      "  | Name                | Type                | Params | Mode \n",
      "--------------------------------------------------------------------\n",
      "0 | criterion           | MSELoss             | 0      | train\n",
      "1 | train_criterion     | MSELoss             | 0      | train\n",
      "2 | val_criterion       | MSELoss             | 0      | train\n",
      "3 | train_metrics       | MetricCollection    | 0      | train\n",
      "4 | val_metrics         | MetricCollection    | 0      | train\n",
      "5 | encoder             | Linear              | 96     | train\n",
      "6 | positional_encoding | _PositionalEncoding | 0      | train\n",
      "7 | transformer         | Transformer         | 280 K  | train\n",
      "8 | decoder             | Linear              | 396    | train\n",
      "--------------------------------------------------------------------\n",
      "281 K     Trainable params\n",
      "0         Non-trainable params\n",
      "281 K     Total params\n",
      "1.126     Total estimated model params size (MB)\n",
      "102       Modules in train mode\n",
      "0         Modules in eval mode\n",
      "/opt/anaconda3/envs/chapter22/lib/python3.9/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 0: 100%|██████████| 1/1 [00:00<00:00, 12.74it/s, train_loss=0.738]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:13:15 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 1/1 [00:00<00:00, 13.57it/s, train_loss=0.290]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:13:15 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 1/1 [00:00<00:00, 14.20it/s, train_loss=0.212]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:13:15 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 1/1 [00:00<00:00, 14.32it/s, train_loss=0.155]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:13:15 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 13.97it/s, train_loss=0.113]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:13:15 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n",
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 13.39it/s, train_loss=0.113]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/06/12 17:13:19 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 76.63it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/chapter22/lib/python3.9/site-packages/torch/nn/modules/transformer.py:382: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "2025/06/12 17:13:19 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID '06191f84b5b747a6af9b8c8b8a75de3f', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current pytorch workflow\n",
      "\n",
      "  | Name                | Type                | Params | Mode \n",
      "--------------------------------------------------------------------\n",
      "0 | criterion           | MSELoss             | 0      | train\n",
      "1 | train_criterion     | MSELoss             | 0      | train\n",
      "2 | val_criterion       | MSELoss             | 0      | train\n",
      "3 | train_metrics       | MetricCollection    | 0      | train\n",
      "4 | val_metrics         | MetricCollection    | 0      | train\n",
      "5 | encoder             | Linear              | 96     | train\n",
      "6 | positional_encoding | _PositionalEncoding | 0      | train\n",
      "7 | transformer         | Transformer         | 276 K  | train\n",
      "8 | decoder             | Linear              | 396    | train\n",
      "--------------------------------------------------------------------\n",
      "277 K     Trainable params\n",
      "0         Non-trainable params\n",
      "277 K     Total params\n",
      "1.109     Total estimated model params size (MB)\n",
      "98        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "/opt/anaconda3/envs/chapter22/lib/python3.9/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 0: 100%|██████████| 1/1 [00:00<00:00, 13.21it/s, train_loss=0.463]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:13:19 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 1/1 [00:00<00:00, 15.64it/s, train_loss=0.258]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:13:19 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 1/1 [00:00<00:00, 14.80it/s, train_loss=0.169]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:13:19 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 1/1 [00:00<00:00, 14.99it/s, train_loss=0.125]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:13:20 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 14.93it/s, train_loss=0.113]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:13:20 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n",
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 14.28it/s, train_loss=0.113]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/06/12 17:13:23 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 83.08it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/chapter22/lib/python3.9/site-packages/torch/nn/modules/transformer.py:382: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "2025/06/12 17:13:24 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID '65ac61ce637b4d158057fd979ba5ef38', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current pytorch workflow\n",
      "\n",
      "  | Name                | Type                | Params | Mode \n",
      "--------------------------------------------------------------------\n",
      "0 | criterion           | MSELoss             | 0      | train\n",
      "1 | train_criterion     | MSELoss             | 0      | train\n",
      "2 | val_criterion       | MSELoss             | 0      | train\n",
      "3 | train_metrics       | MetricCollection    | 0      | train\n",
      "4 | val_metrics         | MetricCollection    | 0      | train\n",
      "5 | encoder             | Linear              | 96     | train\n",
      "6 | positional_encoding | _PositionalEncoding | 0      | train\n",
      "7 | transformer         | Transformer         | 318 K  | train\n",
      "8 | decoder             | Linear              | 396    | train\n",
      "--------------------------------------------------------------------\n",
      "319 K     Trainable params\n",
      "0         Non-trainable params\n",
      "319 K     Total params\n",
      "1.276     Total estimated model params size (MB)\n",
      "112       Modules in train mode\n",
      "0         Modules in eval mode\n",
      "/opt/anaconda3/envs/chapter22/lib/python3.9/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 0: 100%|██████████| 1/1 [00:00<00:00, 12.10it/s, train_loss=0.504]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:13:24 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 1/1 [00:00<00:00, 12.93it/s, train_loss=0.266]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:13:24 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 1/1 [00:00<00:00, 13.17it/s, train_loss=0.148]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:13:24 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 1/1 [00:00<00:00, 13.62it/s, train_loss=0.121]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:13:24 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 13.37it/s, train_loss=0.109]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:13:24 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n",
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 12.88it/s, train_loss=0.109]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/06/12 17:13:28 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 82.12it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/chapter22/lib/python3.9/site-packages/torch/nn/modules/transformer.py:382: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "2025/06/12 17:13:28 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID '4bd5ebb4c6774b8aa2cb6557c89c016f', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current pytorch workflow\n",
      "\n",
      "  | Name                | Type                | Params | Mode \n",
      "--------------------------------------------------------------------\n",
      "0 | criterion           | MSELoss             | 0      | train\n",
      "1 | train_criterion     | MSELoss             | 0      | train\n",
      "2 | val_criterion       | MSELoss             | 0      | train\n",
      "3 | train_metrics       | MetricCollection    | 0      | train\n",
      "4 | val_metrics         | MetricCollection    | 0      | train\n",
      "5 | encoder             | Linear              | 96     | train\n",
      "6 | positional_encoding | _PositionalEncoding | 0      | train\n",
      "7 | transformer         | Transformer         | 201 K  | train\n",
      "8 | decoder             | Linear              | 396    | train\n",
      "--------------------------------------------------------------------\n",
      "201 K     Trainable params\n",
      "0         Non-trainable params\n",
      "201 K     Total params\n",
      "0.807     Total estimated model params size (MB)\n",
      "78        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "/opt/anaconda3/envs/chapter22/lib/python3.9/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 0: 100%|██████████| 1/1 [00:00<00:00, 13.12it/s, train_loss=0.666]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:13:28 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 1/1 [00:00<00:00, 19.59it/s, train_loss=0.334]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:13:28 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 1/1 [00:00<00:00, 18.57it/s, train_loss=0.177]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:13:28 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 1/1 [00:00<00:00, 19.22it/s, train_loss=0.141]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:13:28 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 18.90it/s, train_loss=0.137]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:13:28 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n",
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 18.09it/s, train_loss=0.137]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/06/12 17:13:32 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 104.03it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/chapter22/lib/python3.9/site-packages/torch/nn/modules/transformer.py:382: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "2025/06/12 17:13:32 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID '60c85995409d4239a8af2913cf489667', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current pytorch workflow\n",
      "\n",
      "  | Name                | Type                | Params | Mode \n",
      "--------------------------------------------------------------------\n",
      "0 | criterion           | MSELoss             | 0      | train\n",
      "1 | train_criterion     | MSELoss             | 0      | train\n",
      "2 | val_criterion       | MSELoss             | 0      | train\n",
      "3 | train_metrics       | MetricCollection    | 0      | train\n",
      "4 | val_metrics         | MetricCollection    | 0      | train\n",
      "5 | encoder             | Linear              | 96     | train\n",
      "6 | positional_encoding | _PositionalEncoding | 0      | train\n",
      "7 | transformer         | Transformer         | 243 K  | train\n",
      "8 | decoder             | Linear              | 396    | train\n",
      "--------------------------------------------------------------------\n",
      "243 K     Trainable params\n",
      "0         Non-trainable params\n",
      "243 K     Total params\n",
      "0.975     Total estimated model params size (MB)\n",
      "92        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "/opt/anaconda3/envs/chapter22/lib/python3.9/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 0: 100%|██████████| 1/1 [00:00<00:00, 16.59it/s, train_loss=0.996]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:13:32 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 1/1 [00:00<00:00, 16.14it/s, train_loss=0.335]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:13:32 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 1/1 [00:00<00:00, 18.08it/s, train_loss=0.204]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:13:32 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 1/1 [00:00<00:00, 16.84it/s, train_loss=0.126]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:13:32 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 17.98it/s, train_loss=0.0851]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:13:32 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n",
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 17.20it/s, train_loss=0.0851]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/06/12 17:13:36 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 84.34it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/chapter22/lib/python3.9/site-packages/torch/nn/modules/transformer.py:382: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "2025/06/12 17:13:36 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID 'c90f7d6156a94e2fa6a08d72581f0e22', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current pytorch workflow\n",
      "\n",
      "  | Name                | Type                | Params | Mode \n",
      "--------------------------------------------------------------------\n",
      "0 | criterion           | MSELoss             | 0      | train\n",
      "1 | train_criterion     | MSELoss             | 0      | train\n",
      "2 | val_criterion       | MSELoss             | 0      | train\n",
      "3 | train_metrics       | MetricCollection    | 0      | train\n",
      "4 | val_metrics         | MetricCollection    | 0      | train\n",
      "5 | encoder             | Linear              | 96     | train\n",
      "6 | positional_encoding | _PositionalEncoding | 0      | train\n",
      "7 | transformer         | Transformer         | 238 K  | train\n",
      "8 | decoder             | Linear              | 396    | train\n",
      "--------------------------------------------------------------------\n",
      "239 K     Trainable params\n",
      "0         Non-trainable params\n",
      "239 K     Total params\n",
      "0.958     Total estimated model params size (MB)\n",
      "88        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "/opt/anaconda3/envs/chapter22/lib/python3.9/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 0: 100%|██████████| 1/1 [00:00<00:00, 15.63it/s, train_loss=0.869]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:13:36 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 1/1 [00:00<00:00, 16.51it/s, train_loss=0.345]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:13:36 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 1/1 [00:00<00:00, 16.31it/s, train_loss=0.163]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:13:36 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 1/1 [00:00<00:00, 16.38it/s, train_loss=0.113]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:13:36 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 16.95it/s, train_loss=0.115]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:13:37 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n",
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 16.23it/s, train_loss=0.115]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/06/12 17:13:40 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 79.71it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/chapter22/lib/python3.9/site-packages/torch/nn/modules/transformer.py:382: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "2025/06/12 17:13:40 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID '29ed7be1e3f64a1c9642c86e532b4345', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current pytorch workflow\n",
      "\n",
      "  | Name                | Type                | Params | Mode \n",
      "--------------------------------------------------------------------\n",
      "0 | criterion           | MSELoss             | 0      | train\n",
      "1 | train_criterion     | MSELoss             | 0      | train\n",
      "2 | val_criterion       | MSELoss             | 0      | train\n",
      "3 | train_metrics       | MetricCollection    | 0      | train\n",
      "4 | val_metrics         | MetricCollection    | 0      | train\n",
      "5 | encoder             | Linear              | 96     | train\n",
      "6 | positional_encoding | _PositionalEncoding | 0      | train\n",
      "7 | transformer         | Transformer         | 280 K  | train\n",
      "8 | decoder             | Linear              | 396    | train\n",
      "--------------------------------------------------------------------\n",
      "281 K     Trainable params\n",
      "0         Non-trainable params\n",
      "281 K     Total params\n",
      "1.126     Total estimated model params size (MB)\n",
      "102       Modules in train mode\n",
      "0         Modules in eval mode\n",
      "/opt/anaconda3/envs/chapter22/lib/python3.9/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 0: 100%|██████████| 1/1 [00:00<00:00, 13.95it/s, train_loss=0.787]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:13:40 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 1/1 [00:00<00:00, 14.60it/s, train_loss=0.284]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:13:40 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 1/1 [00:00<00:00, 15.24it/s, train_loss=0.211]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:13:41 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 1/1 [00:00<00:00, 14.72it/s, train_loss=0.160]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:13:41 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 14.42it/s, train_loss=0.118]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:13:41 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n",
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 13.90it/s, train_loss=0.118]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/06/12 17:13:44 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 81.67it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/chapter22/lib/python3.9/site-packages/torch/nn/modules/transformer.py:382: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "2025/06/12 17:13:44 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID 'a9c1d209e98f4b298c2a3e23cda04cc8', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current pytorch workflow\n",
      "\n",
      "  | Name                | Type                | Params | Mode \n",
      "--------------------------------------------------------------------\n",
      "0 | criterion           | MSELoss             | 0      | train\n",
      "1 | train_criterion     | MSELoss             | 0      | train\n",
      "2 | val_criterion       | MSELoss             | 0      | train\n",
      "3 | train_metrics       | MetricCollection    | 0      | train\n",
      "4 | val_metrics         | MetricCollection    | 0      | train\n",
      "5 | encoder             | Linear              | 96     | train\n",
      "6 | positional_encoding | _PositionalEncoding | 0      | train\n",
      "7 | transformer         | Transformer         | 276 K  | train\n",
      "8 | decoder             | Linear              | 396    | train\n",
      "--------------------------------------------------------------------\n",
      "277 K     Trainable params\n",
      "0         Non-trainable params\n",
      "277 K     Total params\n",
      "1.109     Total estimated model params size (MB)\n",
      "98        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "/opt/anaconda3/envs/chapter22/lib/python3.9/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 0: 100%|██████████| 1/1 [00:00<00:00, 14.32it/s, train_loss=0.444]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:13:45 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 1/1 [00:00<00:00, 16.05it/s, train_loss=0.269]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:13:45 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 1/1 [00:00<00:00, 15.55it/s, train_loss=0.167]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:13:45 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 1/1 [00:00<00:00, 15.16it/s, train_loss=0.131]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:13:45 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 16.20it/s, train_loss=0.125]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:13:45 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n",
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 15.52it/s, train_loss=0.125]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/06/12 17:13:48 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 85.05it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/chapter22/lib/python3.9/site-packages/torch/nn/modules/transformer.py:382: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "2025/06/12 17:13:49 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID '712606a1f3a941e9b54d41a2e8ea1d0a', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current pytorch workflow\n",
      "\n",
      "  | Name                | Type                | Params | Mode \n",
      "--------------------------------------------------------------------\n",
      "0 | criterion           | MSELoss             | 0      | train\n",
      "1 | train_criterion     | MSELoss             | 0      | train\n",
      "2 | val_criterion       | MSELoss             | 0      | train\n",
      "3 | train_metrics       | MetricCollection    | 0      | train\n",
      "4 | val_metrics         | MetricCollection    | 0      | train\n",
      "5 | encoder             | Linear              | 96     | train\n",
      "6 | positional_encoding | _PositionalEncoding | 0      | train\n",
      "7 | transformer         | Transformer         | 318 K  | train\n",
      "8 | decoder             | Linear              | 396    | train\n",
      "--------------------------------------------------------------------\n",
      "319 K     Trainable params\n",
      "0         Non-trainable params\n",
      "319 K     Total params\n",
      "1.276     Total estimated model params size (MB)\n",
      "112       Modules in train mode\n",
      "0         Modules in eval mode\n",
      "/opt/anaconda3/envs/chapter22/lib/python3.9/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 0: 100%|██████████| 1/1 [00:00<00:00, 12.38it/s, train_loss=0.577]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:13:49 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 1/1 [00:00<00:00, 13.25it/s, train_loss=0.253]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:13:49 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 1/1 [00:00<00:00, 13.66it/s, train_loss=0.140]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:13:49 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 1/1 [00:00<00:00, 14.05it/s, train_loss=0.117]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:13:49 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 14.18it/s, train_loss=0.110]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:13:49 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n",
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 13.65it/s, train_loss=0.110]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/06/12 17:13:53 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 75.80it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/chapter22/lib/python3.9/site-packages/torch/nn/modules/transformer.py:382: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "2025/06/12 17:13:53 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID 'ca27bd33280e4fd0954c00e185711e81', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current pytorch workflow\n",
      "\n",
      "  | Name                | Type                | Params | Mode \n",
      "--------------------------------------------------------------------\n",
      "0 | criterion           | MSELoss             | 0      | train\n",
      "1 | train_criterion     | MSELoss             | 0      | train\n",
      "2 | val_criterion       | MSELoss             | 0      | train\n",
      "3 | train_metrics       | MetricCollection    | 0      | train\n",
      "4 | val_metrics         | MetricCollection    | 0      | train\n",
      "5 | encoder             | Linear              | 192    | train\n",
      "6 | positional_encoding | _PositionalEncoding | 0      | train\n",
      "7 | transformer         | Transformer         | 465 K  | train\n",
      "8 | decoder             | Linear              | 780    | train\n",
      "--------------------------------------------------------------------\n",
      "466 K     Trainable params\n",
      "0         Non-trainable params\n",
      "466 K     Total params\n",
      "1.866     Total estimated model params size (MB)\n",
      "78        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "/opt/anaconda3/envs/chapter22/lib/python3.9/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 0: 100%|██████████| 1/1 [00:00<00:00, 13.03it/s, train_loss=0.457]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:13:53 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 1/1 [00:00<00:00, 19.92it/s, train_loss=0.333]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:13:53 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 1/1 [00:00<00:00, 19.96it/s, train_loss=0.157]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:13:53 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 1/1 [00:00<00:00, 19.96it/s, train_loss=0.109]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:13:53 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 19.46it/s, train_loss=0.0958]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:13:53 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n",
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 18.48it/s, train_loss=0.0958]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/06/12 17:13:57 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 88.79it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/chapter22/lib/python3.9/site-packages/torch/nn/modules/transformer.py:382: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "2025/06/12 17:13:57 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID 'f4f5d3ecb9ff4048b33ed0d6276c56a4', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current pytorch workflow\n",
      "\n",
      "  | Name                | Type                | Params | Mode \n",
      "--------------------------------------------------------------------\n",
      "0 | criterion           | MSELoss             | 0      | train\n",
      "1 | train_criterion     | MSELoss             | 0      | train\n",
      "2 | val_criterion       | MSELoss             | 0      | train\n",
      "3 | train_metrics       | MetricCollection    | 0      | train\n",
      "4 | val_metrics         | MetricCollection    | 0      | train\n",
      "5 | encoder             | Linear              | 192    | train\n",
      "6 | positional_encoding | _PositionalEncoding | 0      | train\n",
      "7 | transformer         | Transformer         | 565 K  | train\n",
      "8 | decoder             | Linear              | 780    | train\n",
      "--------------------------------------------------------------------\n",
      "566 K     Trainable params\n",
      "0         Non-trainable params\n",
      "566 K     Total params\n",
      "2.265     Total estimated model params size (MB)\n",
      "92        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "/opt/anaconda3/envs/chapter22/lib/python3.9/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 0: 100%|██████████| 1/1 [00:00<00:00, 14.52it/s, train_loss=0.752]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:13:57 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 1/1 [00:00<00:00, 16.41it/s, train_loss=0.558]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:13:57 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 1/1 [00:00<00:00, 16.25it/s, train_loss=0.247]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:13:57 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 1/1 [00:00<00:00, 16.91it/s, train_loss=0.123]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:13:57 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 16.79it/s, train_loss=0.116]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:13:57 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n",
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 16.03it/s, train_loss=0.116]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/06/12 17:14:01 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 82.05it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/chapter22/lib/python3.9/site-packages/torch/nn/modules/transformer.py:382: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "2025/06/12 17:14:01 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID '1333aaf4e34045b9ab98c593f69f7e7c', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current pytorch workflow\n",
      "\n",
      "  | Name                | Type                | Params | Mode \n",
      "--------------------------------------------------------------------\n",
      "0 | criterion           | MSELoss             | 0      | train\n",
      "1 | train_criterion     | MSELoss             | 0      | train\n",
      "2 | val_criterion       | MSELoss             | 0      | train\n",
      "3 | train_metrics       | MetricCollection    | 0      | train\n",
      "4 | val_metrics         | MetricCollection    | 0      | train\n",
      "5 | encoder             | Linear              | 192    | train\n",
      "6 | positional_encoding | _PositionalEncoding | 0      | train\n",
      "7 | transformer         | Transformer         | 548 K  | train\n",
      "8 | decoder             | Linear              | 780    | train\n",
      "--------------------------------------------------------------------\n",
      "549 K     Trainable params\n",
      "0         Non-trainable params\n",
      "549 K     Total params\n",
      "2.198     Total estimated model params size (MB)\n",
      "88        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "/opt/anaconda3/envs/chapter22/lib/python3.9/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 0: 100%|██████████| 1/1 [00:00<00:00, 15.66it/s, train_loss=0.773]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:14:01 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 1/1 [00:00<00:00, 16.80it/s, train_loss=0.454]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:14:01 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 1/1 [00:00<00:00, 16.99it/s, train_loss=0.204]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:14:01 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 1/1 [00:00<00:00, 17.56it/s, train_loss=0.122]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:14:01 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 17.38it/s, train_loss=0.116]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:14:01 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n",
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 16.49it/s, train_loss=0.116]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/06/12 17:14:05 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 86.77it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/chapter22/lib/python3.9/site-packages/torch/nn/modules/transformer.py:382: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "2025/06/12 17:14:05 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID '978dd9b79b39430da3d9000f784d7dff', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current pytorch workflow\n",
      "\n",
      "  | Name                | Type                | Params | Mode \n",
      "--------------------------------------------------------------------\n",
      "0 | criterion           | MSELoss             | 0      | train\n",
      "1 | train_criterion     | MSELoss             | 0      | train\n",
      "2 | val_criterion       | MSELoss             | 0      | train\n",
      "3 | train_metrics       | MetricCollection    | 0      | train\n",
      "4 | val_metrics         | MetricCollection    | 0      | train\n",
      "5 | encoder             | Linear              | 192    | train\n",
      "6 | positional_encoding | _PositionalEncoding | 0      | train\n",
      "7 | transformer         | Transformer         | 648 K  | train\n",
      "8 | decoder             | Linear              | 780    | train\n",
      "--------------------------------------------------------------------\n",
      "649 K     Trainable params\n",
      "0         Non-trainable params\n",
      "649 K     Total params\n",
      "2.597     Total estimated model params size (MB)\n",
      "102       Modules in train mode\n",
      "0         Modules in eval mode\n",
      "/opt/anaconda3/envs/chapter22/lib/python3.9/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 0: 100%|██████████| 1/1 [00:00<00:00, 13.65it/s, train_loss=0.729]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:14:05 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 1/1 [00:00<00:00, 14.76it/s, train_loss=0.258]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:14:05 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 1/1 [00:00<00:00, 14.83it/s, train_loss=0.140]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:14:06 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 1/1 [00:00<00:00, 14.74it/s, train_loss=0.121]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:14:06 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 14.95it/s, train_loss=0.105]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:14:06 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n",
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 14.43it/s, train_loss=0.105]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/06/12 17:14:09 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 76.64it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/chapter22/lib/python3.9/site-packages/torch/nn/modules/transformer.py:382: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "2025/06/12 17:14:09 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID '0482bb09993b4e25b1b522f5a5b59b22', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current pytorch workflow\n",
      "\n",
      "  | Name                | Type                | Params | Mode \n",
      "--------------------------------------------------------------------\n",
      "0 | criterion           | MSELoss             | 0      | train\n",
      "1 | train_criterion     | MSELoss             | 0      | train\n",
      "2 | val_criterion       | MSELoss             | 0      | train\n",
      "3 | train_metrics       | MetricCollection    | 0      | train\n",
      "4 | val_metrics         | MetricCollection    | 0      | train\n",
      "5 | encoder             | Linear              | 192    | train\n",
      "6 | positional_encoding | _PositionalEncoding | 0      | train\n",
      "7 | transformer         | Transformer         | 631 K  | train\n",
      "8 | decoder             | Linear              | 780    | train\n",
      "--------------------------------------------------------------------\n",
      "632 K     Trainable params\n",
      "0         Non-trainable params\n",
      "632 K     Total params\n",
      "2.530     Total estimated model params size (MB)\n",
      "98        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "/opt/anaconda3/envs/chapter22/lib/python3.9/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 0: 100%|██████████| 1/1 [00:00<00:00, 14.22it/s, train_loss=0.749]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:14:10 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 1/1 [00:00<00:00, 15.99it/s, train_loss=0.287]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:14:10 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 1/1 [00:00<00:00, 16.07it/s, train_loss=0.196]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:14:10 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 1/1 [00:00<00:00, 15.53it/s, train_loss=0.124]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:14:10 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 15.24it/s, train_loss=0.106]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:14:10 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n",
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 14.60it/s, train_loss=0.106]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/06/12 17:14:13 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 79.55it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/chapter22/lib/python3.9/site-packages/torch/nn/modules/transformer.py:382: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "2025/06/12 17:14:14 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID '64e9f32da5aa4af9925a855a851199ba', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current pytorch workflow\n",
      "\n",
      "  | Name                | Type                | Params | Mode \n",
      "--------------------------------------------------------------------\n",
      "0 | criterion           | MSELoss             | 0      | train\n",
      "1 | train_criterion     | MSELoss             | 0      | train\n",
      "2 | val_criterion       | MSELoss             | 0      | train\n",
      "3 | train_metrics       | MetricCollection    | 0      | train\n",
      "4 | val_metrics         | MetricCollection    | 0      | train\n",
      "5 | encoder             | Linear              | 192    | train\n",
      "6 | positional_encoding | _PositionalEncoding | 0      | train\n",
      "7 | transformer         | Transformer         | 731 K  | train\n",
      "8 | decoder             | Linear              | 780    | train\n",
      "--------------------------------------------------------------------\n",
      "732 K     Trainable params\n",
      "0         Non-trainable params\n",
      "732 K     Total params\n",
      "2.929     Total estimated model params size (MB)\n",
      "112       Modules in train mode\n",
      "0         Modules in eval mode\n",
      "/opt/anaconda3/envs/chapter22/lib/python3.9/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 0: 100%|██████████| 1/1 [00:00<00:00, 12.38it/s, train_loss=0.759]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:14:14 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 1/1 [00:00<00:00, 13.69it/s, train_loss=0.395]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:14:14 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 1/1 [00:00<00:00, 13.67it/s, train_loss=0.148]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:14:14 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 1/1 [00:00<00:00, 13.48it/s, train_loss=0.103]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:14:14 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 13.84it/s, train_loss=0.110]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:14:14 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n",
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 13.35it/s, train_loss=0.110]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/06/12 17:14:18 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 72.15it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/chapter22/lib/python3.9/site-packages/torch/nn/modules/transformer.py:382: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "2025/06/12 17:14:18 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID 'b2f9c4ae4d484587938e5fa61eedeb71', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current pytorch workflow\n",
      "\n",
      "  | Name                | Type                | Params | Mode \n",
      "--------------------------------------------------------------------\n",
      "0 | criterion           | MSELoss             | 0      | train\n",
      "1 | train_criterion     | MSELoss             | 0      | train\n",
      "2 | val_criterion       | MSELoss             | 0      | train\n",
      "3 | train_metrics       | MetricCollection    | 0      | train\n",
      "4 | val_metrics         | MetricCollection    | 0      | train\n",
      "5 | encoder             | Linear              | 192    | train\n",
      "6 | positional_encoding | _PositionalEncoding | 0      | train\n",
      "7 | transformer         | Transformer         | 465 K  | train\n",
      "8 | decoder             | Linear              | 780    | train\n",
      "--------------------------------------------------------------------\n",
      "466 K     Trainable params\n",
      "0         Non-trainable params\n",
      "466 K     Total params\n",
      "1.866     Total estimated model params size (MB)\n",
      "78        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "/opt/anaconda3/envs/chapter22/lib/python3.9/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 0: 100%|██████████| 1/1 [00:00<00:00, 14.01it/s, train_loss=0.456]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:14:18 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 1/1 [00:00<00:00, 19.82it/s, train_loss=0.345]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:14:18 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 1/1 [00:00<00:00, 19.92it/s, train_loss=0.155]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:14:18 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 1/1 [00:00<00:00, 19.19it/s, train_loss=0.107]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:14:18 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 19.51it/s, train_loss=0.0928]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:14:18 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n",
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 18.56it/s, train_loss=0.0928]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/06/12 17:14:22 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 95.80it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/chapter22/lib/python3.9/site-packages/torch/nn/modules/transformer.py:382: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "2025/06/12 17:14:22 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID '0a4f747022ae45f794d6b379bfb0c293', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current pytorch workflow\n",
      "\n",
      "  | Name                | Type                | Params | Mode \n",
      "--------------------------------------------------------------------\n",
      "0 | criterion           | MSELoss             | 0      | train\n",
      "1 | train_criterion     | MSELoss             | 0      | train\n",
      "2 | val_criterion       | MSELoss             | 0      | train\n",
      "3 | train_metrics       | MetricCollection    | 0      | train\n",
      "4 | val_metrics         | MetricCollection    | 0      | train\n",
      "5 | encoder             | Linear              | 192    | train\n",
      "6 | positional_encoding | _PositionalEncoding | 0      | train\n",
      "7 | transformer         | Transformer         | 565 K  | train\n",
      "8 | decoder             | Linear              | 780    | train\n",
      "--------------------------------------------------------------------\n",
      "566 K     Trainable params\n",
      "0         Non-trainable params\n",
      "566 K     Total params\n",
      "2.265     Total estimated model params size (MB)\n",
      "92        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "/opt/anaconda3/envs/chapter22/lib/python3.9/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 0: 100%|██████████| 1/1 [00:00<00:00, 15.18it/s, train_loss=0.736]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:14:22 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 1/1 [00:00<00:00, 16.47it/s, train_loss=0.546]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:14:22 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 1/1 [00:00<00:00, 16.31it/s, train_loss=0.239]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:14:22 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 1/1 [00:00<00:00, 16.54it/s, train_loss=0.129]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:14:22 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 16.87it/s, train_loss=0.114]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:14:22 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n",
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 16.10it/s, train_loss=0.114]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/06/12 17:14:26 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 82.09it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/chapter22/lib/python3.9/site-packages/torch/nn/modules/transformer.py:382: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "2025/06/12 17:14:26 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID 'f034aeb00c694020ac4958663388548a', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current pytorch workflow\n",
      "\n",
      "  | Name                | Type                | Params | Mode \n",
      "--------------------------------------------------------------------\n",
      "0 | criterion           | MSELoss             | 0      | train\n",
      "1 | train_criterion     | MSELoss             | 0      | train\n",
      "2 | val_criterion       | MSELoss             | 0      | train\n",
      "3 | train_metrics       | MetricCollection    | 0      | train\n",
      "4 | val_metrics         | MetricCollection    | 0      | train\n",
      "5 | encoder             | Linear              | 192    | train\n",
      "6 | positional_encoding | _PositionalEncoding | 0      | train\n",
      "7 | transformer         | Transformer         | 548 K  | train\n",
      "8 | decoder             | Linear              | 780    | train\n",
      "--------------------------------------------------------------------\n",
      "549 K     Trainable params\n",
      "0         Non-trainable params\n",
      "549 K     Total params\n",
      "2.198     Total estimated model params size (MB)\n",
      "88        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "/opt/anaconda3/envs/chapter22/lib/python3.9/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 0: 100%|██████████| 1/1 [00:00<00:00, 15.90it/s, train_loss=0.797]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:14:26 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 1/1 [00:00<00:00, 16.72it/s, train_loss=0.440]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:14:26 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 1/1 [00:00<00:00, 17.40it/s, train_loss=0.209]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:14:26 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 1/1 [00:00<00:00, 17.41it/s, train_loss=0.120]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:14:26 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 17.54it/s, train_loss=0.119]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:14:26 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n",
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 16.78it/s, train_loss=0.119]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/06/12 17:14:30 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 84.65it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/chapter22/lib/python3.9/site-packages/torch/nn/modules/transformer.py:382: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "2025/06/12 17:14:30 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID 'fe893529f65d4523a43545e9d2d168ed', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current pytorch workflow\n",
      "\n",
      "  | Name                | Type                | Params | Mode \n",
      "--------------------------------------------------------------------\n",
      "0 | criterion           | MSELoss             | 0      | train\n",
      "1 | train_criterion     | MSELoss             | 0      | train\n",
      "2 | val_criterion       | MSELoss             | 0      | train\n",
      "3 | train_metrics       | MetricCollection    | 0      | train\n",
      "4 | val_metrics         | MetricCollection    | 0      | train\n",
      "5 | encoder             | Linear              | 192    | train\n",
      "6 | positional_encoding | _PositionalEncoding | 0      | train\n",
      "7 | transformer         | Transformer         | 648 K  | train\n",
      "8 | decoder             | Linear              | 780    | train\n",
      "--------------------------------------------------------------------\n",
      "649 K     Trainable params\n",
      "0         Non-trainable params\n",
      "649 K     Total params\n",
      "2.597     Total estimated model params size (MB)\n",
      "102       Modules in train mode\n",
      "0         Modules in eval mode\n",
      "/opt/anaconda3/envs/chapter22/lib/python3.9/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 0: 100%|██████████| 1/1 [00:00<00:00, 13.64it/s, train_loss=0.719]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:14:30 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 1/1 [00:00<00:00, 15.14it/s, train_loss=0.264]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:14:30 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 1/1 [00:00<00:00, 14.55it/s, train_loss=0.138]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:14:30 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 1/1 [00:00<00:00, 15.11it/s, train_loss=0.119]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:14:30 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 15.22it/s, train_loss=0.102]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:14:30 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n",
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 14.63it/s, train_loss=0.102]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/06/12 17:14:34 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 80.52it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/chapter22/lib/python3.9/site-packages/torch/nn/modules/transformer.py:382: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "2025/06/12 17:14:34 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID 'eafdc3d791524eb4ad8ad4e16db1a6ce', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current pytorch workflow\n",
      "\n",
      "  | Name                | Type                | Params | Mode \n",
      "--------------------------------------------------------------------\n",
      "0 | criterion           | MSELoss             | 0      | train\n",
      "1 | train_criterion     | MSELoss             | 0      | train\n",
      "2 | val_criterion       | MSELoss             | 0      | train\n",
      "3 | train_metrics       | MetricCollection    | 0      | train\n",
      "4 | val_metrics         | MetricCollection    | 0      | train\n",
      "5 | encoder             | Linear              | 192    | train\n",
      "6 | positional_encoding | _PositionalEncoding | 0      | train\n",
      "7 | transformer         | Transformer         | 631 K  | train\n",
      "8 | decoder             | Linear              | 780    | train\n",
      "--------------------------------------------------------------------\n",
      "632 K     Trainable params\n",
      "0         Non-trainable params\n",
      "632 K     Total params\n",
      "2.530     Total estimated model params size (MB)\n",
      "98        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "/opt/anaconda3/envs/chapter22/lib/python3.9/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 0: 100%|██████████| 1/1 [00:00<00:00, 14.35it/s, train_loss=0.733]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:14:34 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 1/1 [00:00<00:00, 15.94it/s, train_loss=0.273]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:14:34 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 1/1 [00:00<00:00, 16.03it/s, train_loss=0.194]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:14:34 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 1/1 [00:00<00:00, 15.80it/s, train_loss=0.126]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:14:35 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 15.67it/s, train_loss=0.110]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:14:35 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n",
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 15.08it/s, train_loss=0.110]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/06/12 17:14:38 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 80.65it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/chapter22/lib/python3.9/site-packages/torch/nn/modules/transformer.py:382: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "2025/06/12 17:14:38 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID '68aa674fb3d44ef7a4a0111315f7ac60', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current pytorch workflow\n",
      "\n",
      "  | Name                | Type                | Params | Mode \n",
      "--------------------------------------------------------------------\n",
      "0 | criterion           | MSELoss             | 0      | train\n",
      "1 | train_criterion     | MSELoss             | 0      | train\n",
      "2 | val_criterion       | MSELoss             | 0      | train\n",
      "3 | train_metrics       | MetricCollection    | 0      | train\n",
      "4 | val_metrics         | MetricCollection    | 0      | train\n",
      "5 | encoder             | Linear              | 192    | train\n",
      "6 | positional_encoding | _PositionalEncoding | 0      | train\n",
      "7 | transformer         | Transformer         | 731 K  | train\n",
      "8 | decoder             | Linear              | 780    | train\n",
      "--------------------------------------------------------------------\n",
      "732 K     Trainable params\n",
      "0         Non-trainable params\n",
      "732 K     Total params\n",
      "2.929     Total estimated model params size (MB)\n",
      "112       Modules in train mode\n",
      "0         Modules in eval mode\n",
      "/opt/anaconda3/envs/chapter22/lib/python3.9/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 0: 100%|██████████| 1/1 [00:00<00:00, 12.51it/s, train_loss=0.778]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:14:39 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 1/1 [00:00<00:00, 14.01it/s, train_loss=0.405]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:14:39 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 1/1 [00:00<00:00, 13.35it/s, train_loss=0.155]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:14:39 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 1/1 [00:00<00:00, 13.66it/s, train_loss=0.103]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:14:39 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 13.92it/s, train_loss=0.107]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:14:39 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n",
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 13.42it/s, train_loss=0.107]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/06/12 17:14:43 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 70.87it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/chapter22/lib/python3.9/site-packages/torch/nn/modules/transformer.py:382: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "2025/06/12 17:14:43 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID '8ab9fb6970f04b279744c843eb8830e0', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current pytorch workflow\n",
      "\n",
      "  | Name                | Type                | Params | Mode \n",
      "--------------------------------------------------------------------\n",
      "0 | criterion           | MSELoss             | 0      | train\n",
      "1 | train_criterion     | MSELoss             | 0      | train\n",
      "2 | val_criterion       | MSELoss             | 0      | train\n",
      "3 | train_metrics       | MetricCollection    | 0      | train\n",
      "4 | val_metrics         | MetricCollection    | 0      | train\n",
      "5 | encoder             | Linear              | 96     | train\n",
      "6 | positional_encoding | _PositionalEncoding | 0      | train\n",
      "7 | transformer         | Transformer         | 201 K  | train\n",
      "8 | decoder             | Linear              | 396    | train\n",
      "--------------------------------------------------------------------\n",
      "201 K     Trainable params\n",
      "0         Non-trainable params\n",
      "201 K     Total params\n",
      "0.807     Total estimated model params size (MB)\n",
      "78        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "/opt/anaconda3/envs/chapter22/lib/python3.9/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 0: 100%|██████████| 1/1 [00:00<00:00, 13.38it/s, train_loss=0.666]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:14:43 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 1/1 [00:00<00:00, 18.60it/s, train_loss=0.343]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:14:43 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 1/1 [00:00<00:00, 18.86it/s, train_loss=0.174]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:14:43 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 1/1 [00:00<00:00, 18.69it/s, train_loss=0.155]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:14:43 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 18.95it/s, train_loss=0.141]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:14:43 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 1/1 [00:00<00:00, 18.36it/s, train_loss=0.115]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:14:43 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 1/1 [00:00<00:00, 18.79it/s, train_loss=0.0923]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:14:43 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 1/1 [00:00<00:00, 19.29it/s, train_loss=0.0861]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:14:43 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 1/1 [00:00<00:00, 18.95it/s, train_loss=0.0857]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:14:43 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 18.86it/s, train_loss=0.0918]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:14:43 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n",
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 18.02it/s, train_loss=0.0918]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/06/12 17:14:47 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 94.56it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/chapter22/lib/python3.9/site-packages/torch/nn/modules/transformer.py:382: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "2025/06/12 17:14:47 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID '79805ec6d2fc4269bab31e55e6bb67f9', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current pytorch workflow\n",
      "\n",
      "  | Name                | Type                | Params | Mode \n",
      "--------------------------------------------------------------------\n",
      "0 | criterion           | MSELoss             | 0      | train\n",
      "1 | train_criterion     | MSELoss             | 0      | train\n",
      "2 | val_criterion       | MSELoss             | 0      | train\n",
      "3 | train_metrics       | MetricCollection    | 0      | train\n",
      "4 | val_metrics         | MetricCollection    | 0      | train\n",
      "5 | encoder             | Linear              | 96     | train\n",
      "6 | positional_encoding | _PositionalEncoding | 0      | train\n",
      "7 | transformer         | Transformer         | 243 K  | train\n",
      "8 | decoder             | Linear              | 396    | train\n",
      "--------------------------------------------------------------------\n",
      "243 K     Trainable params\n",
      "0         Non-trainable params\n",
      "243 K     Total params\n",
      "0.975     Total estimated model params size (MB)\n",
      "92        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "/opt/anaconda3/envs/chapter22/lib/python3.9/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 0: 100%|██████████| 1/1 [00:00<00:00, 14.69it/s, train_loss=1.030]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:14:47 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 1/1 [00:00<00:00, 15.93it/s, train_loss=0.329]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:14:47 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 1/1 [00:00<00:00, 15.33it/s, train_loss=0.202]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:14:47 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 1/1 [00:00<00:00, 15.71it/s, train_loss=0.125]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:14:47 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 16.58it/s, train_loss=0.0905]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:14:47 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 1/1 [00:00<00:00, 16.29it/s, train_loss=0.0872]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:14:47 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 1/1 [00:00<00:00, 15.80it/s, train_loss=0.0951]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:14:48 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 1/1 [00:00<00:00, 15.90it/s, train_loss=0.0974]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:14:48 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 1/1 [00:00<00:00, 16.35it/s, train_loss=0.0898]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:14:48 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 16.49it/s, train_loss=0.0914]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:14:48 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n",
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 15.71it/s, train_loss=0.0914]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/06/12 17:14:51 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 80.34it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/chapter22/lib/python3.9/site-packages/torch/nn/modules/transformer.py:382: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "2025/06/12 17:14:51 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID '45e933e4c5fc4f74b0dd270a01b8503f', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current pytorch workflow\n",
      "\n",
      "  | Name                | Type                | Params | Mode \n",
      "--------------------------------------------------------------------\n",
      "0 | criterion           | MSELoss             | 0      | train\n",
      "1 | train_criterion     | MSELoss             | 0      | train\n",
      "2 | val_criterion       | MSELoss             | 0      | train\n",
      "3 | train_metrics       | MetricCollection    | 0      | train\n",
      "4 | val_metrics         | MetricCollection    | 0      | train\n",
      "5 | encoder             | Linear              | 96     | train\n",
      "6 | positional_encoding | _PositionalEncoding | 0      | train\n",
      "7 | transformer         | Transformer         | 238 K  | train\n",
      "8 | decoder             | Linear              | 396    | train\n",
      "--------------------------------------------------------------------\n",
      "239 K     Trainable params\n",
      "0         Non-trainable params\n",
      "239 K     Total params\n",
      "0.958     Total estimated model params size (MB)\n",
      "88        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "/opt/anaconda3/envs/chapter22/lib/python3.9/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 0: 100%|██████████| 1/1 [00:00<00:00, 15.07it/s, train_loss=0.886]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:14:52 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 1/1 [00:00<00:00, 17.24it/s, train_loss=0.352]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:14:52 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 1/1 [00:00<00:00, 16.69it/s, train_loss=0.168]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:14:52 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 1/1 [00:00<00:00, 16.41it/s, train_loss=0.109]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:14:52 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 17.21it/s, train_loss=0.112]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:14:52 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 1/1 [00:00<00:00, 16.83it/s, train_loss=0.0958]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:14:52 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 1/1 [00:00<00:00, 15.90it/s, train_loss=0.108] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:14:52 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 1/1 [00:00<00:00, 16.78it/s, train_loss=0.0938]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:14:52 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 1/1 [00:00<00:00, 16.40it/s, train_loss=0.0906]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:14:52 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 17.04it/s, train_loss=0.0881]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:14:52 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n",
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 16.25it/s, train_loss=0.0881]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/06/12 17:14:56 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 85.84it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/chapter22/lib/python3.9/site-packages/torch/nn/modules/transformer.py:382: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "2025/06/12 17:14:56 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID '319f43aa963340af8f26acbfd0f631cb', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current pytorch workflow\n",
      "\n",
      "  | Name                | Type                | Params | Mode \n",
      "--------------------------------------------------------------------\n",
      "0 | criterion           | MSELoss             | 0      | train\n",
      "1 | train_criterion     | MSELoss             | 0      | train\n",
      "2 | val_criterion       | MSELoss             | 0      | train\n",
      "3 | train_metrics       | MetricCollection    | 0      | train\n",
      "4 | val_metrics         | MetricCollection    | 0      | train\n",
      "5 | encoder             | Linear              | 96     | train\n",
      "6 | positional_encoding | _PositionalEncoding | 0      | train\n",
      "7 | transformer         | Transformer         | 280 K  | train\n",
      "8 | decoder             | Linear              | 396    | train\n",
      "--------------------------------------------------------------------\n",
      "281 K     Trainable params\n",
      "0         Non-trainable params\n",
      "281 K     Total params\n",
      "1.126     Total estimated model params size (MB)\n",
      "102       Modules in train mode\n",
      "0         Modules in eval mode\n",
      "/opt/anaconda3/envs/chapter22/lib/python3.9/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 0: 100%|██████████| 1/1 [00:00<00:00, 12.70it/s, train_loss=0.738]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:14:56 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 1/1 [00:00<00:00, 14.14it/s, train_loss=0.290]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:14:56 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 1/1 [00:00<00:00, 15.19it/s, train_loss=0.212]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:14:56 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 1/1 [00:00<00:00, 15.23it/s, train_loss=0.155]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:14:56 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 15.22it/s, train_loss=0.113]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:14:56 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 1/1 [00:00<00:00, 14.57it/s, train_loss=0.090]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:14:56 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 1/1 [00:00<00:00, 14.63it/s, train_loss=0.0865]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:14:56 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 1/1 [00:00<00:00, 15.22it/s, train_loss=0.0945]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:14:57 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 1/1 [00:00<00:00, 14.30it/s, train_loss=0.0856]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:14:57 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 15.19it/s, train_loss=0.0924]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:14:57 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n",
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 14.59it/s, train_loss=0.0924]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/06/12 17:15:00 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 78.66it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/chapter22/lib/python3.9/site-packages/torch/nn/modules/transformer.py:382: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "2025/06/12 17:15:00 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID '8758351dec38487b9fee3941e518b840', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current pytorch workflow\n",
      "\n",
      "  | Name                | Type                | Params | Mode \n",
      "--------------------------------------------------------------------\n",
      "0 | criterion           | MSELoss             | 0      | train\n",
      "1 | train_criterion     | MSELoss             | 0      | train\n",
      "2 | val_criterion       | MSELoss             | 0      | train\n",
      "3 | train_metrics       | MetricCollection    | 0      | train\n",
      "4 | val_metrics         | MetricCollection    | 0      | train\n",
      "5 | encoder             | Linear              | 96     | train\n",
      "6 | positional_encoding | _PositionalEncoding | 0      | train\n",
      "7 | transformer         | Transformer         | 276 K  | train\n",
      "8 | decoder             | Linear              | 396    | train\n",
      "--------------------------------------------------------------------\n",
      "277 K     Trainable params\n",
      "0         Non-trainable params\n",
      "277 K     Total params\n",
      "1.109     Total estimated model params size (MB)\n",
      "98        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "/opt/anaconda3/envs/chapter22/lib/python3.9/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 0: 100%|██████████| 1/1 [00:00<00:00, 13.71it/s, train_loss=0.463]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:15:01 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 1/1 [00:00<00:00, 14.94it/s, train_loss=0.258]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:15:01 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 1/1 [00:00<00:00, 15.24it/s, train_loss=0.169]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:15:01 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 1/1 [00:00<00:00, 15.32it/s, train_loss=0.125]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:15:01 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 15.58it/s, train_loss=0.113]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:15:01 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 1/1 [00:00<00:00, 15.35it/s, train_loss=0.0958]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:15:01 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 1/1 [00:00<00:00, 15.56it/s, train_loss=0.0989]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:15:01 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 1/1 [00:00<00:00, 15.83it/s, train_loss=0.0926]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:15:01 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 1/1 [00:00<00:00, 15.98it/s, train_loss=0.0958]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:15:01 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 15.43it/s, train_loss=0.0842]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:15:01 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n",
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 14.84it/s, train_loss=0.0842]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/06/12 17:15:05 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 76.61it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/chapter22/lib/python3.9/site-packages/torch/nn/modules/transformer.py:382: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "2025/06/12 17:15:05 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID '7d563cc33d0d4e85ae3180ef12049abf', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current pytorch workflow\n",
      "\n",
      "  | Name                | Type                | Params | Mode \n",
      "--------------------------------------------------------------------\n",
      "0 | criterion           | MSELoss             | 0      | train\n",
      "1 | train_criterion     | MSELoss             | 0      | train\n",
      "2 | val_criterion       | MSELoss             | 0      | train\n",
      "3 | train_metrics       | MetricCollection    | 0      | train\n",
      "4 | val_metrics         | MetricCollection    | 0      | train\n",
      "5 | encoder             | Linear              | 96     | train\n",
      "6 | positional_encoding | _PositionalEncoding | 0      | train\n",
      "7 | transformer         | Transformer         | 318 K  | train\n",
      "8 | decoder             | Linear              | 396    | train\n",
      "--------------------------------------------------------------------\n",
      "319 K     Trainable params\n",
      "0         Non-trainable params\n",
      "319 K     Total params\n",
      "1.276     Total estimated model params size (MB)\n",
      "112       Modules in train mode\n",
      "0         Modules in eval mode\n",
      "/opt/anaconda3/envs/chapter22/lib/python3.9/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 0: 100%|██████████| 1/1 [00:00<00:00, 12.49it/s, train_loss=0.504]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:15:05 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 1/1 [00:00<00:00, 13.92it/s, train_loss=0.266]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:15:05 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 1/1 [00:00<00:00, 13.61it/s, train_loss=0.148]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:15:05 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 1/1 [00:00<00:00, 13.61it/s, train_loss=0.121]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:15:05 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 14.52it/s, train_loss=0.109]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:15:05 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 1/1 [00:00<00:00, 13.97it/s, train_loss=0.106]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:15:05 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 1/1 [00:00<00:00, 13.94it/s, train_loss=0.089]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:15:05 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 1/1 [00:00<00:00, 13.40it/s, train_loss=0.0856]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:15:06 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 1/1 [00:00<00:00, 14.21it/s, train_loss=0.0861]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:15:06 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 13.88it/s, train_loss=0.0861]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:15:06 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n",
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 13.33it/s, train_loss=0.0861]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/06/12 17:15:09 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 73.59it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/chapter22/lib/python3.9/site-packages/torch/nn/modules/transformer.py:382: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "2025/06/12 17:15:10 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID 'b4144585e8124dc2912fc8beceef27bd', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current pytorch workflow\n",
      "\n",
      "  | Name                | Type                | Params | Mode \n",
      "--------------------------------------------------------------------\n",
      "0 | criterion           | MSELoss             | 0      | train\n",
      "1 | train_criterion     | MSELoss             | 0      | train\n",
      "2 | val_criterion       | MSELoss             | 0      | train\n",
      "3 | train_metrics       | MetricCollection    | 0      | train\n",
      "4 | val_metrics         | MetricCollection    | 0      | train\n",
      "5 | encoder             | Linear              | 96     | train\n",
      "6 | positional_encoding | _PositionalEncoding | 0      | train\n",
      "7 | transformer         | Transformer         | 201 K  | train\n",
      "8 | decoder             | Linear              | 396    | train\n",
      "--------------------------------------------------------------------\n",
      "201 K     Trainable params\n",
      "0         Non-trainable params\n",
      "201 K     Total params\n",
      "0.807     Total estimated model params size (MB)\n",
      "78        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "/opt/anaconda3/envs/chapter22/lib/python3.9/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 0: 100%|██████████| 1/1 [00:00<00:00, 13.50it/s, train_loss=0.666]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:15:10 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 1/1 [00:00<00:00, 18.18it/s, train_loss=0.334]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:15:10 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 1/1 [00:00<00:00, 18.01it/s, train_loss=0.177]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:15:10 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 1/1 [00:00<00:00, 17.92it/s, train_loss=0.141]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:15:10 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 18.64it/s, train_loss=0.137]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:15:10 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 1/1 [00:00<00:00, 17.90it/s, train_loss=0.109]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:15:10 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 1/1 [00:00<00:00, 18.23it/s, train_loss=0.0889]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:15:10 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 1/1 [00:00<00:00, 17.42it/s, train_loss=0.0819]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:15:10 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 1/1 [00:00<00:00, 18.09it/s, train_loss=0.0862]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:15:10 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 18.60it/s, train_loss=0.0907]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:15:10 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n",
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 17.65it/s, train_loss=0.0907]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/06/12 17:15:14 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 84.20it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/chapter22/lib/python3.9/site-packages/torch/nn/modules/transformer.py:382: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "2025/06/12 17:15:14 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID 'ac6c398dc3f349479819c3e03032e1c7', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current pytorch workflow\n",
      "\n",
      "  | Name                | Type                | Params | Mode \n",
      "--------------------------------------------------------------------\n",
      "0 | criterion           | MSELoss             | 0      | train\n",
      "1 | train_criterion     | MSELoss             | 0      | train\n",
      "2 | val_criterion       | MSELoss             | 0      | train\n",
      "3 | train_metrics       | MetricCollection    | 0      | train\n",
      "4 | val_metrics         | MetricCollection    | 0      | train\n",
      "5 | encoder             | Linear              | 96     | train\n",
      "6 | positional_encoding | _PositionalEncoding | 0      | train\n",
      "7 | transformer         | Transformer         | 243 K  | train\n",
      "8 | decoder             | Linear              | 396    | train\n",
      "--------------------------------------------------------------------\n",
      "243 K     Trainable params\n",
      "0         Non-trainable params\n",
      "243 K     Total params\n",
      "0.975     Total estimated model params size (MB)\n",
      "92        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "/opt/anaconda3/envs/chapter22/lib/python3.9/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 0: 100%|██████████| 1/1 [00:00<00:00, 14.02it/s, train_loss=0.996]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:15:14 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 1/1 [00:00<00:00, 15.58it/s, train_loss=0.335]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:15:14 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 1/1 [00:00<00:00, 15.39it/s, train_loss=0.204]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:15:14 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 1/1 [00:00<00:00, 15.77it/s, train_loss=0.126]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:15:14 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 15.44it/s, train_loss=0.0851]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:15:14 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 1/1 [00:00<00:00, 15.82it/s, train_loss=0.090] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:15:14 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 1/1 [00:00<00:00, 15.62it/s, train_loss=0.0967]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:15:14 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 1/1 [00:00<00:00, 15.15it/s, train_loss=0.101] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:15:15 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 1/1 [00:00<00:00, 14.58it/s, train_loss=0.0909]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:15:15 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 15.70it/s, train_loss=0.0881]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:15:15 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n",
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 15.07it/s, train_loss=0.0881]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/06/12 17:15:18 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 83.89it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/chapter22/lib/python3.9/site-packages/torch/nn/modules/transformer.py:382: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "2025/06/12 17:15:18 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID '3d447ced6eec4cbba9f975c84af40e1e', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current pytorch workflow\n",
      "\n",
      "  | Name                | Type                | Params | Mode \n",
      "--------------------------------------------------------------------\n",
      "0 | criterion           | MSELoss             | 0      | train\n",
      "1 | train_criterion     | MSELoss             | 0      | train\n",
      "2 | val_criterion       | MSELoss             | 0      | train\n",
      "3 | train_metrics       | MetricCollection    | 0      | train\n",
      "4 | val_metrics         | MetricCollection    | 0      | train\n",
      "5 | encoder             | Linear              | 96     | train\n",
      "6 | positional_encoding | _PositionalEncoding | 0      | train\n",
      "7 | transformer         | Transformer         | 238 K  | train\n",
      "8 | decoder             | Linear              | 396    | train\n",
      "--------------------------------------------------------------------\n",
      "239 K     Trainable params\n",
      "0         Non-trainable params\n",
      "239 K     Total params\n",
      "0.958     Total estimated model params size (MB)\n",
      "88        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "/opt/anaconda3/envs/chapter22/lib/python3.9/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 0: 100%|██████████| 1/1 [00:00<00:00, 14.37it/s, train_loss=0.869]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:15:19 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 1/1 [00:00<00:00, 16.41it/s, train_loss=0.345]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:15:19 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 1/1 [00:00<00:00, 16.77it/s, train_loss=0.163]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:15:19 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 1/1 [00:00<00:00, 15.70it/s, train_loss=0.113]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:15:19 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 16.11it/s, train_loss=0.115]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:15:19 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 1/1 [00:00<00:00, 17.52it/s, train_loss=0.0925]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:15:19 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 1/1 [00:00<00:00, 15.10it/s, train_loss=0.104] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:15:19 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 1/1 [00:00<00:00, 16.01it/s, train_loss=0.0977]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:15:19 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 1/1 [00:00<00:00, 16.62it/s, train_loss=0.0937]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:15:19 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 16.68it/s, train_loss=0.0885]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:15:19 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n",
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 15.90it/s, train_loss=0.0885]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/06/12 17:15:23 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 86.45it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/chapter22/lib/python3.9/site-packages/torch/nn/modules/transformer.py:382: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "2025/06/12 17:15:23 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID '52680f5059774dd3867e3a2f8f77a818', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current pytorch workflow\n",
      "\n",
      "  | Name                | Type                | Params | Mode \n",
      "--------------------------------------------------------------------\n",
      "0 | criterion           | MSELoss             | 0      | train\n",
      "1 | train_criterion     | MSELoss             | 0      | train\n",
      "2 | val_criterion       | MSELoss             | 0      | train\n",
      "3 | train_metrics       | MetricCollection    | 0      | train\n",
      "4 | val_metrics         | MetricCollection    | 0      | train\n",
      "5 | encoder             | Linear              | 96     | train\n",
      "6 | positional_encoding | _PositionalEncoding | 0      | train\n",
      "7 | transformer         | Transformer         | 280 K  | train\n",
      "8 | decoder             | Linear              | 396    | train\n",
      "--------------------------------------------------------------------\n",
      "281 K     Trainable params\n",
      "0         Non-trainable params\n",
      "281 K     Total params\n",
      "1.126     Total estimated model params size (MB)\n",
      "102       Modules in train mode\n",
      "0         Modules in eval mode\n",
      "/opt/anaconda3/envs/chapter22/lib/python3.9/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 0: 100%|██████████| 1/1 [00:00<00:00, 12.92it/s, train_loss=0.787]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:15:23 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 1/1 [00:00<00:00, 13.62it/s, train_loss=0.284]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:15:23 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 1/1 [00:00<00:00, 13.52it/s, train_loss=0.211]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:15:23 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 1/1 [00:00<00:00, 14.48it/s, train_loss=0.160]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:15:23 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 13.07it/s, train_loss=0.118]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:15:23 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 1/1 [00:00<00:00, 13.56it/s, train_loss=0.0912]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:15:23 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 1/1 [00:00<00:00, 14.16it/s, train_loss=0.0876]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:15:24 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 1/1 [00:00<00:00, 13.90it/s, train_loss=0.0871]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:15:24 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 1/1 [00:00<00:00, 14.13it/s, train_loss=0.0844]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:15:24 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 14.27it/s, train_loss=0.0917]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:15:24 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n",
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 13.71it/s, train_loss=0.0917]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/06/12 17:15:27 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 78.69it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/chapter22/lib/python3.9/site-packages/torch/nn/modules/transformer.py:382: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "2025/06/12 17:15:28 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID '5f1efa5945e9436683b1ce05d4c30a74', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current pytorch workflow\n",
      "\n",
      "  | Name                | Type                | Params | Mode \n",
      "--------------------------------------------------------------------\n",
      "0 | criterion           | MSELoss             | 0      | train\n",
      "1 | train_criterion     | MSELoss             | 0      | train\n",
      "2 | val_criterion       | MSELoss             | 0      | train\n",
      "3 | train_metrics       | MetricCollection    | 0      | train\n",
      "4 | val_metrics         | MetricCollection    | 0      | train\n",
      "5 | encoder             | Linear              | 96     | train\n",
      "6 | positional_encoding | _PositionalEncoding | 0      | train\n",
      "7 | transformer         | Transformer         | 276 K  | train\n",
      "8 | decoder             | Linear              | 396    | train\n",
      "--------------------------------------------------------------------\n",
      "277 K     Trainable params\n",
      "0         Non-trainable params\n",
      "277 K     Total params\n",
      "1.109     Total estimated model params size (MB)\n",
      "98        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "/opt/anaconda3/envs/chapter22/lib/python3.9/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 0: 100%|██████████| 1/1 [00:00<00:00, 13.05it/s, train_loss=0.444]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:15:28 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 1/1 [00:00<00:00, 14.37it/s, train_loss=0.269]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:15:28 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 1/1 [00:00<00:00, 14.75it/s, train_loss=0.167]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:15:28 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 1/1 [00:00<00:00, 15.14it/s, train_loss=0.131]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:15:28 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 14.85it/s, train_loss=0.125]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:15:28 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 1/1 [00:00<00:00, 14.98it/s, train_loss=0.106]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:15:28 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 1/1 [00:00<00:00, 15.16it/s, train_loss=0.0996]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:15:28 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 1/1 [00:00<00:00, 15.25it/s, train_loss=0.0869]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:15:28 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 1/1 [00:00<00:00, 15.46it/s, train_loss=0.0939]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:15:28 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 14.57it/s, train_loss=0.0814]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:15:28 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n",
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 13.96it/s, train_loss=0.0814]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/06/12 17:15:32 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 80.01it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/chapter22/lib/python3.9/site-packages/torch/nn/modules/transformer.py:382: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "2025/06/12 17:15:32 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID '6cd8b3e9bb24408296df5054ffa8917f', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current pytorch workflow\n",
      "\n",
      "  | Name                | Type                | Params | Mode \n",
      "--------------------------------------------------------------------\n",
      "0 | criterion           | MSELoss             | 0      | train\n",
      "1 | train_criterion     | MSELoss             | 0      | train\n",
      "2 | val_criterion       | MSELoss             | 0      | train\n",
      "3 | train_metrics       | MetricCollection    | 0      | train\n",
      "4 | val_metrics         | MetricCollection    | 0      | train\n",
      "5 | encoder             | Linear              | 96     | train\n",
      "6 | positional_encoding | _PositionalEncoding | 0      | train\n",
      "7 | transformer         | Transformer         | 318 K  | train\n",
      "8 | decoder             | Linear              | 396    | train\n",
      "--------------------------------------------------------------------\n",
      "319 K     Trainable params\n",
      "0         Non-trainable params\n",
      "319 K     Total params\n",
      "1.276     Total estimated model params size (MB)\n",
      "112       Modules in train mode\n",
      "0         Modules in eval mode\n",
      "/opt/anaconda3/envs/chapter22/lib/python3.9/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 0: 100%|██████████| 1/1 [00:00<00:00, 11.87it/s, train_loss=0.577]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:15:32 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 1/1 [00:00<00:00, 13.58it/s, train_loss=0.253]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:15:32 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 1/1 [00:00<00:00, 13.55it/s, train_loss=0.140]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:15:32 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 1/1 [00:00<00:00, 13.38it/s, train_loss=0.117]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:15:32 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 13.27it/s, train_loss=0.110]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:15:33 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 1/1 [00:00<00:00, 13.49it/s, train_loss=0.105]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:15:33 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 1/1 [00:00<00:00, 12.77it/s, train_loss=0.092]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:15:33 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 1/1 [00:00<00:00, 13.24it/s, train_loss=0.0855]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:15:33 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 1/1 [00:00<00:00, 12.99it/s, train_loss=0.0809]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:15:33 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 13.16it/s, train_loss=0.0848]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:15:33 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n",
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 12.69it/s, train_loss=0.0848]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/06/12 17:15:37 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 67.83it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/chapter22/lib/python3.9/site-packages/torch/nn/modules/transformer.py:382: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "2025/06/12 17:15:37 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID '46ab3f4534f041309f2965cc112d407f', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current pytorch workflow\n",
      "\n",
      "  | Name                | Type                | Params | Mode \n",
      "--------------------------------------------------------------------\n",
      "0 | criterion           | MSELoss             | 0      | train\n",
      "1 | train_criterion     | MSELoss             | 0      | train\n",
      "2 | val_criterion       | MSELoss             | 0      | train\n",
      "3 | train_metrics       | MetricCollection    | 0      | train\n",
      "4 | val_metrics         | MetricCollection    | 0      | train\n",
      "5 | encoder             | Linear              | 192    | train\n",
      "6 | positional_encoding | _PositionalEncoding | 0      | train\n",
      "7 | transformer         | Transformer         | 465 K  | train\n",
      "8 | decoder             | Linear              | 780    | train\n",
      "--------------------------------------------------------------------\n",
      "466 K     Trainable params\n",
      "0         Non-trainable params\n",
      "466 K     Total params\n",
      "1.866     Total estimated model params size (MB)\n",
      "78        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "/opt/anaconda3/envs/chapter22/lib/python3.9/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 0: 100%|██████████| 1/1 [00:00<00:00, 13.09it/s, train_loss=0.457]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:15:37 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 1/1 [00:00<00:00, 18.51it/s, train_loss=0.333]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:15:37 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 1/1 [00:00<00:00, 17.44it/s, train_loss=0.157]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:15:37 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 1/1 [00:00<00:00, 17.87it/s, train_loss=0.109]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:15:37 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 18.00it/s, train_loss=0.0958]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:15:37 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 1/1 [00:00<00:00, 19.43it/s, train_loss=0.107] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:15:37 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 1/1 [00:00<00:00, 18.75it/s, train_loss=0.105]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:15:37 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 1/1 [00:00<00:00, 18.38it/s, train_loss=0.0961]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:15:37 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 1/1 [00:00<00:00, 18.94it/s, train_loss=0.0904]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:15:37 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 19.72it/s, train_loss=0.0862]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:15:37 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n",
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 18.69it/s, train_loss=0.0862]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/06/12 17:15:41 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 88.81it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/chapter22/lib/python3.9/site-packages/torch/nn/modules/transformer.py:382: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "2025/06/12 17:15:41 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID '939cf3e16a544fc08e44235963b0d5d3', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current pytorch workflow\n",
      "\n",
      "  | Name                | Type                | Params | Mode \n",
      "--------------------------------------------------------------------\n",
      "0 | criterion           | MSELoss             | 0      | train\n",
      "1 | train_criterion     | MSELoss             | 0      | train\n",
      "2 | val_criterion       | MSELoss             | 0      | train\n",
      "3 | train_metrics       | MetricCollection    | 0      | train\n",
      "4 | val_metrics         | MetricCollection    | 0      | train\n",
      "5 | encoder             | Linear              | 192    | train\n",
      "6 | positional_encoding | _PositionalEncoding | 0      | train\n",
      "7 | transformer         | Transformer         | 565 K  | train\n",
      "8 | decoder             | Linear              | 780    | train\n",
      "--------------------------------------------------------------------\n",
      "566 K     Trainable params\n",
      "0         Non-trainable params\n",
      "566 K     Total params\n",
      "2.265     Total estimated model params size (MB)\n",
      "92        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "/opt/anaconda3/envs/chapter22/lib/python3.9/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 0: 100%|██████████| 1/1 [00:00<00:00, 13.78it/s, train_loss=0.752]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:15:41 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 1/1 [00:00<00:00, 16.12it/s, train_loss=0.558]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:15:41 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 1/1 [00:00<00:00, 15.62it/s, train_loss=0.247]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:15:41 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 1/1 [00:00<00:00, 15.28it/s, train_loss=0.123]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:15:41 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 15.80it/s, train_loss=0.116]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:15:41 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 1/1 [00:00<00:00, 15.55it/s, train_loss=0.125]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:15:41 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 1/1 [00:00<00:00, 15.17it/s, train_loss=0.119]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:15:42 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 1/1 [00:00<00:00, 15.47it/s, train_loss=0.116]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:15:42 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 1/1 [00:00<00:00, 14.64it/s, train_loss=0.103]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:15:42 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 13.86it/s, train_loss=0.0918]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:15:42 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n",
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 13.31it/s, train_loss=0.0918]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/06/12 17:15:45 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 81.91it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/chapter22/lib/python3.9/site-packages/torch/nn/modules/transformer.py:382: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "2025/06/12 17:15:46 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID 'dacc9f17d05f44fd878b3e53f7159e45', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current pytorch workflow\n",
      "\n",
      "  | Name                | Type                | Params | Mode \n",
      "--------------------------------------------------------------------\n",
      "0 | criterion           | MSELoss             | 0      | train\n",
      "1 | train_criterion     | MSELoss             | 0      | train\n",
      "2 | val_criterion       | MSELoss             | 0      | train\n",
      "3 | train_metrics       | MetricCollection    | 0      | train\n",
      "4 | val_metrics         | MetricCollection    | 0      | train\n",
      "5 | encoder             | Linear              | 192    | train\n",
      "6 | positional_encoding | _PositionalEncoding | 0      | train\n",
      "7 | transformer         | Transformer         | 548 K  | train\n",
      "8 | decoder             | Linear              | 780    | train\n",
      "--------------------------------------------------------------------\n",
      "549 K     Trainable params\n",
      "0         Non-trainable params\n",
      "549 K     Total params\n",
      "2.198     Total estimated model params size (MB)\n",
      "88        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "/opt/anaconda3/envs/chapter22/lib/python3.9/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 0: 100%|██████████| 1/1 [00:00<00:00, 14.59it/s, train_loss=0.773]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:15:46 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 1/1 [00:00<00:00, 15.13it/s, train_loss=0.454]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:15:46 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 1/1 [00:00<00:00, 16.24it/s, train_loss=0.204]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:15:46 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 1/1 [00:00<00:00, 16.12it/s, train_loss=0.122]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:15:46 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 16.42it/s, train_loss=0.116]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:15:46 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 1/1 [00:00<00:00, 16.10it/s, train_loss=0.0994]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:15:46 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 1/1 [00:00<00:00, 16.32it/s, train_loss=0.109] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:15:46 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 1/1 [00:00<00:00, 16.53it/s, train_loss=0.104]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:15:46 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 1/1 [00:00<00:00, 17.21it/s, train_loss=0.0988]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:15:46 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 16.62it/s, train_loss=0.113] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:15:46 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n",
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 15.81it/s, train_loss=0.113]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/06/12 17:15:50 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 78.32it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/chapter22/lib/python3.9/site-packages/torch/nn/modules/transformer.py:382: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "2025/06/12 17:15:50 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID 'd341861da35a47f6a016377c0b411e1c', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current pytorch workflow\n",
      "\n",
      "  | Name                | Type                | Params | Mode \n",
      "--------------------------------------------------------------------\n",
      "0 | criterion           | MSELoss             | 0      | train\n",
      "1 | train_criterion     | MSELoss             | 0      | train\n",
      "2 | val_criterion       | MSELoss             | 0      | train\n",
      "3 | train_metrics       | MetricCollection    | 0      | train\n",
      "4 | val_metrics         | MetricCollection    | 0      | train\n",
      "5 | encoder             | Linear              | 192    | train\n",
      "6 | positional_encoding | _PositionalEncoding | 0      | train\n",
      "7 | transformer         | Transformer         | 648 K  | train\n",
      "8 | decoder             | Linear              | 780    | train\n",
      "--------------------------------------------------------------------\n",
      "649 K     Trainable params\n",
      "0         Non-trainable params\n",
      "649 K     Total params\n",
      "2.597     Total estimated model params size (MB)\n",
      "102       Modules in train mode\n",
      "0         Modules in eval mode\n",
      "/opt/anaconda3/envs/chapter22/lib/python3.9/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 0: 100%|██████████| 1/1 [00:00<00:00, 12.58it/s, train_loss=0.729]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:15:50 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 1/1 [00:00<00:00, 12.84it/s, train_loss=0.258]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:15:50 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 1/1 [00:00<00:00, 13.64it/s, train_loss=0.140]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:15:50 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 1/1 [00:00<00:00, 13.71it/s, train_loss=0.121]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:15:50 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 13.86it/s, train_loss=0.105]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:15:50 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 1/1 [00:00<00:00, 14.00it/s, train_loss=0.0989]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:15:50 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 1/1 [00:00<00:00, 14.15it/s, train_loss=0.0867]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:15:51 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 1/1 [00:00<00:00, 14.35it/s, train_loss=0.0855]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:15:51 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 1/1 [00:00<00:00, 13.65it/s, train_loss=0.0728]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:15:51 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 12.83it/s, train_loss=0.0833]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:15:51 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n",
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 12.34it/s, train_loss=0.0833]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/06/12 17:15:54 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 76.06it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/chapter22/lib/python3.9/site-packages/torch/nn/modules/transformer.py:382: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "2025/06/12 17:15:55 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID 'a42de61db5074ee4881e3717342788c9', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current pytorch workflow\n",
      "\n",
      "  | Name                | Type                | Params | Mode \n",
      "--------------------------------------------------------------------\n",
      "0 | criterion           | MSELoss             | 0      | train\n",
      "1 | train_criterion     | MSELoss             | 0      | train\n",
      "2 | val_criterion       | MSELoss             | 0      | train\n",
      "3 | train_metrics       | MetricCollection    | 0      | train\n",
      "4 | val_metrics         | MetricCollection    | 0      | train\n",
      "5 | encoder             | Linear              | 192    | train\n",
      "6 | positional_encoding | _PositionalEncoding | 0      | train\n",
      "7 | transformer         | Transformer         | 631 K  | train\n",
      "8 | decoder             | Linear              | 780    | train\n",
      "--------------------------------------------------------------------\n",
      "632 K     Trainable params\n",
      "0         Non-trainable params\n",
      "632 K     Total params\n",
      "2.530     Total estimated model params size (MB)\n",
      "98        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "/opt/anaconda3/envs/chapter22/lib/python3.9/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 0: 100%|██████████| 1/1 [00:00<00:00, 13.34it/s, train_loss=0.749]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:15:55 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 1/1 [00:00<00:00, 14.89it/s, train_loss=0.287]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:15:55 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 1/1 [00:00<00:00, 15.16it/s, train_loss=0.196]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:15:55 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 1/1 [00:00<00:00, 14.93it/s, train_loss=0.124]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:15:55 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 14.82it/s, train_loss=0.106]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:15:55 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 1/1 [00:00<00:00, 14.79it/s, train_loss=0.0977]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:15:55 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 1/1 [00:00<00:00, 15.70it/s, train_loss=0.0921]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:15:55 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 1/1 [00:00<00:00, 15.61it/s, train_loss=0.0885]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:15:55 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 1/1 [00:00<00:00, 14.82it/s, train_loss=0.092] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:15:55 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 14.88it/s, train_loss=0.0964]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:15:55 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n",
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 14.29it/s, train_loss=0.0964]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/06/12 17:15:59 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 69.57it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/chapter22/lib/python3.9/site-packages/torch/nn/modules/transformer.py:382: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "2025/06/12 17:15:59 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID '7c675a3db291455aa2d62a27f204bf79', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current pytorch workflow\n",
      "\n",
      "  | Name                | Type                | Params | Mode \n",
      "--------------------------------------------------------------------\n",
      "0 | criterion           | MSELoss             | 0      | train\n",
      "1 | train_criterion     | MSELoss             | 0      | train\n",
      "2 | val_criterion       | MSELoss             | 0      | train\n",
      "3 | train_metrics       | MetricCollection    | 0      | train\n",
      "4 | val_metrics         | MetricCollection    | 0      | train\n",
      "5 | encoder             | Linear              | 192    | train\n",
      "6 | positional_encoding | _PositionalEncoding | 0      | train\n",
      "7 | transformer         | Transformer         | 731 K  | train\n",
      "8 | decoder             | Linear              | 780    | train\n",
      "--------------------------------------------------------------------\n",
      "732 K     Trainable params\n",
      "0         Non-trainable params\n",
      "732 K     Total params\n",
      "2.929     Total estimated model params size (MB)\n",
      "112       Modules in train mode\n",
      "0         Modules in eval mode\n",
      "/opt/anaconda3/envs/chapter22/lib/python3.9/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 0: 100%|██████████| 1/1 [00:00<00:00, 12.14it/s, train_loss=0.759]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:15:59 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 1/1 [00:00<00:00, 12.84it/s, train_loss=0.395]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:15:59 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 1/1 [00:00<00:00, 12.60it/s, train_loss=0.148]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:15:59 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 1/1 [00:00<00:00, 12.60it/s, train_loss=0.103]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:15:59 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 13.70it/s, train_loss=0.110]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:15:59 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 1/1 [00:00<00:00, 12.94it/s, train_loss=0.103]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:16:00 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 1/1 [00:00<00:00, 12.87it/s, train_loss=0.095]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:16:00 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 1/1 [00:00<00:00, 12.99it/s, train_loss=0.0868]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:16:00 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 1/1 [00:00<00:00, 12.95it/s, train_loss=0.0854]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:16:00 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 13.18it/s, train_loss=0.0859]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:16:00 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n",
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 12.73it/s, train_loss=0.0859]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/06/12 17:16:04 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 75.38it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/chapter22/lib/python3.9/site-packages/torch/nn/modules/transformer.py:382: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "2025/06/12 17:16:04 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID 'ddc3df4fb0614298916039cd464ae30d', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current pytorch workflow\n",
      "\n",
      "  | Name                | Type                | Params | Mode \n",
      "--------------------------------------------------------------------\n",
      "0 | criterion           | MSELoss             | 0      | train\n",
      "1 | train_criterion     | MSELoss             | 0      | train\n",
      "2 | val_criterion       | MSELoss             | 0      | train\n",
      "3 | train_metrics       | MetricCollection    | 0      | train\n",
      "4 | val_metrics         | MetricCollection    | 0      | train\n",
      "5 | encoder             | Linear              | 192    | train\n",
      "6 | positional_encoding | _PositionalEncoding | 0      | train\n",
      "7 | transformer         | Transformer         | 465 K  | train\n",
      "8 | decoder             | Linear              | 780    | train\n",
      "--------------------------------------------------------------------\n",
      "466 K     Trainable params\n",
      "0         Non-trainable params\n",
      "466 K     Total params\n",
      "1.866     Total estimated model params size (MB)\n",
      "78        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "/opt/anaconda3/envs/chapter22/lib/python3.9/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 0: 100%|██████████| 1/1 [00:00<00:00, 13.11it/s, train_loss=0.456]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:16:04 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 1/1 [00:00<00:00, 18.88it/s, train_loss=0.345]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:16:04 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 1/1 [00:00<00:00, 19.25it/s, train_loss=0.155]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:16:04 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 1/1 [00:00<00:00, 19.47it/s, train_loss=0.107]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:16:04 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 18.42it/s, train_loss=0.0928]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:16:04 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 1/1 [00:00<00:00, 17.98it/s, train_loss=0.108] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:16:04 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 1/1 [00:00<00:00, 19.08it/s, train_loss=0.104]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:16:04 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 1/1 [00:00<00:00, 18.45it/s, train_loss=0.0976]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:16:04 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 1/1 [00:00<00:00, 18.61it/s, train_loss=0.0922]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:16:04 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 18.28it/s, train_loss=0.088] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:16:04 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n",
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 17.39it/s, train_loss=0.088]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/06/12 17:16:08 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 88.09it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/chapter22/lib/python3.9/site-packages/torch/nn/modules/transformer.py:382: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "2025/06/12 17:16:08 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID '8b65d9f5cf09405da1927dd51cb380f2', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current pytorch workflow\n",
      "\n",
      "  | Name                | Type                | Params | Mode \n",
      "--------------------------------------------------------------------\n",
      "0 | criterion           | MSELoss             | 0      | train\n",
      "1 | train_criterion     | MSELoss             | 0      | train\n",
      "2 | val_criterion       | MSELoss             | 0      | train\n",
      "3 | train_metrics       | MetricCollection    | 0      | train\n",
      "4 | val_metrics         | MetricCollection    | 0      | train\n",
      "5 | encoder             | Linear              | 192    | train\n",
      "6 | positional_encoding | _PositionalEncoding | 0      | train\n",
      "7 | transformer         | Transformer         | 565 K  | train\n",
      "8 | decoder             | Linear              | 780    | train\n",
      "--------------------------------------------------------------------\n",
      "566 K     Trainable params\n",
      "0         Non-trainable params\n",
      "566 K     Total params\n",
      "2.265     Total estimated model params size (MB)\n",
      "92        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "/opt/anaconda3/envs/chapter22/lib/python3.9/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 0: 100%|██████████| 1/1 [00:00<00:00, 14.32it/s, train_loss=0.736]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:16:08 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 1/1 [00:00<00:00, 15.64it/s, train_loss=0.546]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:16:08 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 1/1 [00:00<00:00, 16.01it/s, train_loss=0.239]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:16:08 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 1/1 [00:00<00:00, 15.79it/s, train_loss=0.129]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:16:08 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 15.25it/s, train_loss=0.114]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:16:08 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 1/1 [00:00<00:00, 15.17it/s, train_loss=0.126]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:16:08 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 1/1 [00:00<00:00, 16.51it/s, train_loss=0.121]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:16:09 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 1/1 [00:00<00:00, 16.39it/s, train_loss=0.117]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:16:09 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 1/1 [00:00<00:00, 16.05it/s, train_loss=0.103]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:16:09 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 16.16it/s, train_loss=0.0902]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:16:09 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n",
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 15.46it/s, train_loss=0.0902]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/06/12 17:16:12 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 89.81it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/chapter22/lib/python3.9/site-packages/torch/nn/modules/transformer.py:382: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "2025/06/12 17:16:12 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID '3ba16680378544f5a05b5a44b52290b9', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current pytorch workflow\n",
      "\n",
      "  | Name                | Type                | Params | Mode \n",
      "--------------------------------------------------------------------\n",
      "0 | criterion           | MSELoss             | 0      | train\n",
      "1 | train_criterion     | MSELoss             | 0      | train\n",
      "2 | val_criterion       | MSELoss             | 0      | train\n",
      "3 | train_metrics       | MetricCollection    | 0      | train\n",
      "4 | val_metrics         | MetricCollection    | 0      | train\n",
      "5 | encoder             | Linear              | 192    | train\n",
      "6 | positional_encoding | _PositionalEncoding | 0      | train\n",
      "7 | transformer         | Transformer         | 548 K  | train\n",
      "8 | decoder             | Linear              | 780    | train\n",
      "--------------------------------------------------------------------\n",
      "549 K     Trainable params\n",
      "0         Non-trainable params\n",
      "549 K     Total params\n",
      "2.198     Total estimated model params size (MB)\n",
      "88        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "/opt/anaconda3/envs/chapter22/lib/python3.9/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 0: 100%|██████████| 1/1 [00:00<00:00, 15.40it/s, train_loss=0.797]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:16:13 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 1/1 [00:00<00:00, 17.32it/s, train_loss=0.440]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:16:13 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 1/1 [00:00<00:00, 17.39it/s, train_loss=0.209]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:16:13 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 1/1 [00:00<00:00, 16.76it/s, train_loss=0.120]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:16:13 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 17.19it/s, train_loss=0.119]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:16:13 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 1/1 [00:00<00:00, 17.27it/s, train_loss=0.0959]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:16:13 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 1/1 [00:00<00:00, 16.40it/s, train_loss=0.106] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:16:13 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 1/1 [00:00<00:00, 17.32it/s, train_loss=0.106]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:16:13 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 1/1 [00:00<00:00, 16.54it/s, train_loss=0.101]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:16:13 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 16.01it/s, train_loss=0.109]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:16:13 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n",
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 15.28it/s, train_loss=0.109]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/06/12 17:16:17 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 80.26it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/chapter22/lib/python3.9/site-packages/torch/nn/modules/transformer.py:382: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "2025/06/12 17:16:17 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID '1117084f388d4b5691418f1ed7a25457', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current pytorch workflow\n",
      "\n",
      "  | Name                | Type                | Params | Mode \n",
      "--------------------------------------------------------------------\n",
      "0 | criterion           | MSELoss             | 0      | train\n",
      "1 | train_criterion     | MSELoss             | 0      | train\n",
      "2 | val_criterion       | MSELoss             | 0      | train\n",
      "3 | train_metrics       | MetricCollection    | 0      | train\n",
      "4 | val_metrics         | MetricCollection    | 0      | train\n",
      "5 | encoder             | Linear              | 192    | train\n",
      "6 | positional_encoding | _PositionalEncoding | 0      | train\n",
      "7 | transformer         | Transformer         | 648 K  | train\n",
      "8 | decoder             | Linear              | 780    | train\n",
      "--------------------------------------------------------------------\n",
      "649 K     Trainable params\n",
      "0         Non-trainable params\n",
      "649 K     Total params\n",
      "2.597     Total estimated model params size (MB)\n",
      "102       Modules in train mode\n",
      "0         Modules in eval mode\n",
      "/opt/anaconda3/envs/chapter22/lib/python3.9/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 0: 100%|██████████| 1/1 [00:00<00:00, 13.12it/s, train_loss=0.719]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:16:17 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 1/1 [00:00<00:00, 14.01it/s, train_loss=0.264]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:16:17 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 1/1 [00:00<00:00, 14.86it/s, train_loss=0.138]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:16:17 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 1/1 [00:00<00:00, 13.86it/s, train_loss=0.119]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:16:17 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 15.33it/s, train_loss=0.102]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:16:17 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 1/1 [00:00<00:00, 13.94it/s, train_loss=0.102]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:16:17 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 1/1 [00:00<00:00, 13.87it/s, train_loss=0.0894]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:16:18 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 1/1 [00:00<00:00, 13.74it/s, train_loss=0.0841]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:16:18 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 1/1 [00:00<00:00, 14.22it/s, train_loss=0.071] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:16:18 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 14.37it/s, train_loss=0.0833]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:16:18 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n",
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 13.75it/s, train_loss=0.0833]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/06/12 17:16:21 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 78.56it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/chapter22/lib/python3.9/site-packages/torch/nn/modules/transformer.py:382: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "2025/06/12 17:16:22 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID 'd2b2a5aa3e9748589c264bc4cc6daa0f', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current pytorch workflow\n",
      "\n",
      "  | Name                | Type                | Params | Mode \n",
      "--------------------------------------------------------------------\n",
      "0 | criterion           | MSELoss             | 0      | train\n",
      "1 | train_criterion     | MSELoss             | 0      | train\n",
      "2 | val_criterion       | MSELoss             | 0      | train\n",
      "3 | train_metrics       | MetricCollection    | 0      | train\n",
      "4 | val_metrics         | MetricCollection    | 0      | train\n",
      "5 | encoder             | Linear              | 192    | train\n",
      "6 | positional_encoding | _PositionalEncoding | 0      | train\n",
      "7 | transformer         | Transformer         | 631 K  | train\n",
      "8 | decoder             | Linear              | 780    | train\n",
      "--------------------------------------------------------------------\n",
      "632 K     Trainable params\n",
      "0         Non-trainable params\n",
      "632 K     Total params\n",
      "2.530     Total estimated model params size (MB)\n",
      "98        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "/opt/anaconda3/envs/chapter22/lib/python3.9/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 0: 100%|██████████| 1/1 [00:00<00:00, 14.28it/s, train_loss=0.733]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:16:22 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 1/1 [00:00<00:00, 15.14it/s, train_loss=0.273]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:16:22 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 1/1 [00:00<00:00, 15.14it/s, train_loss=0.194]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:16:22 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 1/1 [00:00<00:00, 14.42it/s, train_loss=0.126]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:16:22 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 15.07it/s, train_loss=0.110]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:16:22 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 1/1 [00:00<00:00, 14.69it/s, train_loss=0.0983]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:16:22 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 1/1 [00:00<00:00, 14.66it/s, train_loss=0.0878]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:16:22 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 1/1 [00:00<00:00, 13.80it/s, train_loss=0.0917]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:16:22 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 1/1 [00:00<00:00, 14.77it/s, train_loss=0.0942]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:16:22 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 14.85it/s, train_loss=0.0946]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:16:22 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n",
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 14.29it/s, train_loss=0.0946]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/06/12 17:16:26 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 83.32it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/chapter22/lib/python3.9/site-packages/torch/nn/modules/transformer.py:382: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "2025/06/12 17:16:26 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID '9299ca6503d74d139eaeb4d3b0be38bb', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current pytorch workflow\n",
      "\n",
      "  | Name                | Type                | Params | Mode \n",
      "--------------------------------------------------------------------\n",
      "0 | criterion           | MSELoss             | 0      | train\n",
      "1 | train_criterion     | MSELoss             | 0      | train\n",
      "2 | val_criterion       | MSELoss             | 0      | train\n",
      "3 | train_metrics       | MetricCollection    | 0      | train\n",
      "4 | val_metrics         | MetricCollection    | 0      | train\n",
      "5 | encoder             | Linear              | 192    | train\n",
      "6 | positional_encoding | _PositionalEncoding | 0      | train\n",
      "7 | transformer         | Transformer         | 731 K  | train\n",
      "8 | decoder             | Linear              | 780    | train\n",
      "--------------------------------------------------------------------\n",
      "732 K     Trainable params\n",
      "0         Non-trainable params\n",
      "732 K     Total params\n",
      "2.929     Total estimated model params size (MB)\n",
      "112       Modules in train mode\n",
      "0         Modules in eval mode\n",
      "/opt/anaconda3/envs/chapter22/lib/python3.9/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 0: 100%|██████████| 1/1 [00:00<00:00, 12.35it/s, train_loss=0.778]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:16:26 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 1/1 [00:00<00:00, 13.58it/s, train_loss=0.405]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:16:26 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 1/1 [00:00<00:00, 13.73it/s, train_loss=0.155]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:16:26 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 1/1 [00:00<00:00, 13.18it/s, train_loss=0.103]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:16:26 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 13.53it/s, train_loss=0.107]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:16:27 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 1/1 [00:00<00:00, 13.35it/s, train_loss=0.103]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:16:27 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 1/1 [00:00<00:00, 13.10it/s, train_loss=0.0916]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:16:27 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 1/1 [00:00<00:00, 12.81it/s, train_loss=0.0857]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:16:27 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 1/1 [00:00<00:00, 13.10it/s, train_loss=0.0878]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:16:27 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 12.38it/s, train_loss=0.0902]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:16:27 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n",
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 11.95it/s, train_loss=0.0902]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/06/12 17:16:31 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 74.84it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/chapter22/lib/python3.9/site-packages/torch/nn/modules/transformer.py:382: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "2025/06/12 17:16:31 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID 'a1f7070a0691482abbfda136fff28f39', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current pytorch workflow\n",
      "\n",
      "  | Name                | Type                | Params | Mode \n",
      "--------------------------------------------------------------------\n",
      "0 | criterion           | MSELoss             | 0      | train\n",
      "1 | train_criterion     | MSELoss             | 0      | train\n",
      "2 | val_criterion       | MSELoss             | 0      | train\n",
      "3 | train_metrics       | MetricCollection    | 0      | train\n",
      "4 | val_metrics         | MetricCollection    | 0      | train\n",
      "5 | encoder             | Linear              | 96     | train\n",
      "6 | positional_encoding | _PositionalEncoding | 0      | train\n",
      "7 | transformer         | Transformer         | 201 K  | train\n",
      "8 | decoder             | Linear              | 396    | train\n",
      "--------------------------------------------------------------------\n",
      "201 K     Trainable params\n",
      "0         Non-trainable params\n",
      "201 K     Total params\n",
      "0.807     Total estimated model params size (MB)\n",
      "78        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "/opt/anaconda3/envs/chapter22/lib/python3.9/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 0: 100%|██████████| 1/1 [00:00<00:00, 12.56it/s, train_loss=0.560]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:16:31 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 1/1 [00:00<00:00, 19.88it/s, train_loss=0.270]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:16:31 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 1/1 [00:00<00:00, 18.53it/s, train_loss=0.183]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:16:31 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 1/1 [00:00<00:00, 18.65it/s, train_loss=0.134]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:16:31 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 17.40it/s, train_loss=0.118]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:16:31 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n",
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 16.54it/s, train_loss=0.118]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/06/12 17:16:35 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 81.99it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/chapter22/lib/python3.9/site-packages/torch/nn/modules/transformer.py:382: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "2025/06/12 17:16:35 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID '76ee2e9d78d04863b43b66e8b62de85a', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current pytorch workflow\n",
      "\n",
      "  | Name                | Type                | Params | Mode \n",
      "--------------------------------------------------------------------\n",
      "0 | criterion           | MSELoss             | 0      | train\n",
      "1 | train_criterion     | MSELoss             | 0      | train\n",
      "2 | val_criterion       | MSELoss             | 0      | train\n",
      "3 | train_metrics       | MetricCollection    | 0      | train\n",
      "4 | val_metrics         | MetricCollection    | 0      | train\n",
      "5 | encoder             | Linear              | 96     | train\n",
      "6 | positional_encoding | _PositionalEncoding | 0      | train\n",
      "7 | transformer         | Transformer         | 243 K  | train\n",
      "8 | decoder             | Linear              | 396    | train\n",
      "--------------------------------------------------------------------\n",
      "243 K     Trainable params\n",
      "0         Non-trainable params\n",
      "243 K     Total params\n",
      "0.975     Total estimated model params size (MB)\n",
      "92        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "/opt/anaconda3/envs/chapter22/lib/python3.9/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 0: 100%|██████████| 1/1 [00:00<00:00, 14.33it/s, train_loss=0.945]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:16:35 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 1/1 [00:00<00:00, 14.61it/s, train_loss=0.344]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:16:35 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 1/1 [00:00<00:00, 15.81it/s, train_loss=0.215]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:16:35 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 1/1 [00:00<00:00, 16.34it/s, train_loss=0.113]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:16:35 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 16.69it/s, train_loss=0.0676]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:16:35 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n",
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 15.94it/s, train_loss=0.0676]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/06/12 17:16:39 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 85.72it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/chapter22/lib/python3.9/site-packages/torch/nn/modules/transformer.py:382: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "2025/06/12 17:16:39 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID 'd80b9a6c08004e5ea20ceacc9b264bb2', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current pytorch workflow\n",
      "\n",
      "  | Name                | Type                | Params | Mode \n",
      "--------------------------------------------------------------------\n",
      "0 | criterion           | MSELoss             | 0      | train\n",
      "1 | train_criterion     | MSELoss             | 0      | train\n",
      "2 | val_criterion       | MSELoss             | 0      | train\n",
      "3 | train_metrics       | MetricCollection    | 0      | train\n",
      "4 | val_metrics         | MetricCollection    | 0      | train\n",
      "5 | encoder             | Linear              | 96     | train\n",
      "6 | positional_encoding | _PositionalEncoding | 0      | train\n",
      "7 | transformer         | Transformer         | 238 K  | train\n",
      "8 | decoder             | Linear              | 396    | train\n",
      "--------------------------------------------------------------------\n",
      "239 K     Trainable params\n",
      "0         Non-trainable params\n",
      "239 K     Total params\n",
      "0.958     Total estimated model params size (MB)\n",
      "88        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "/opt/anaconda3/envs/chapter22/lib/python3.9/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 0: 100%|██████████| 1/1 [00:00<00:00, 14.70it/s, train_loss=0.841]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:16:39 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 1/1 [00:00<00:00, 16.40it/s, train_loss=0.338]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:16:39 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 1/1 [00:00<00:00, 17.12it/s, train_loss=0.155]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:16:39 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 1/1 [00:00<00:00, 17.05it/s, train_loss=0.0972]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:16:39 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 16.47it/s, train_loss=0.0737]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:16:39 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n",
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 15.74it/s, train_loss=0.0737]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/06/12 17:16:43 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 90.52it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/chapter22/lib/python3.9/site-packages/torch/nn/modules/transformer.py:382: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "2025/06/12 17:16:43 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID '65d6cffdc9764a54bbb1f11fd61ab329', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current pytorch workflow\n",
      "\n",
      "  | Name                | Type                | Params | Mode \n",
      "--------------------------------------------------------------------\n",
      "0 | criterion           | MSELoss             | 0      | train\n",
      "1 | train_criterion     | MSELoss             | 0      | train\n",
      "2 | val_criterion       | MSELoss             | 0      | train\n",
      "3 | train_metrics       | MetricCollection    | 0      | train\n",
      "4 | val_metrics         | MetricCollection    | 0      | train\n",
      "5 | encoder             | Linear              | 96     | train\n",
      "6 | positional_encoding | _PositionalEncoding | 0      | train\n",
      "7 | transformer         | Transformer         | 280 K  | train\n",
      "8 | decoder             | Linear              | 396    | train\n",
      "--------------------------------------------------------------------\n",
      "281 K     Trainable params\n",
      "0         Non-trainable params\n",
      "281 K     Total params\n",
      "1.126     Total estimated model params size (MB)\n",
      "102       Modules in train mode\n",
      "0         Modules in eval mode\n",
      "/opt/anaconda3/envs/chapter22/lib/python3.9/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 0: 100%|██████████| 1/1 [00:00<00:00, 13.15it/s, train_loss=0.745]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:16:43 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 1/1 [00:00<00:00, 13.56it/s, train_loss=0.258]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:16:43 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 1/1 [00:00<00:00, 14.15it/s, train_loss=0.209]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:16:43 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 1/1 [00:00<00:00, 14.02it/s, train_loss=0.149]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:16:43 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 14.92it/s, train_loss=0.102]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:16:44 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n",
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 14.25it/s, train_loss=0.102]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/06/12 17:16:47 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 74.80it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/chapter22/lib/python3.9/site-packages/torch/nn/modules/transformer.py:382: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "2025/06/12 17:16:47 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID '06f40f4e09434c688c6b89b040fe35af', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current pytorch workflow\n",
      "\n",
      "  | Name                | Type                | Params | Mode \n",
      "--------------------------------------------------------------------\n",
      "0 | criterion           | MSELoss             | 0      | train\n",
      "1 | train_criterion     | MSELoss             | 0      | train\n",
      "2 | val_criterion       | MSELoss             | 0      | train\n",
      "3 | train_metrics       | MetricCollection    | 0      | train\n",
      "4 | val_metrics         | MetricCollection    | 0      | train\n",
      "5 | encoder             | Linear              | 96     | train\n",
      "6 | positional_encoding | _PositionalEncoding | 0      | train\n",
      "7 | transformer         | Transformer         | 276 K  | train\n",
      "8 | decoder             | Linear              | 396    | train\n",
      "--------------------------------------------------------------------\n",
      "277 K     Trainable params\n",
      "0         Non-trainable params\n",
      "277 K     Total params\n",
      "1.109     Total estimated model params size (MB)\n",
      "98        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "/opt/anaconda3/envs/chapter22/lib/python3.9/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 0: 100%|██████████| 1/1 [00:00<00:00, 13.57it/s, train_loss=0.383]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:16:47 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 1/1 [00:00<00:00, 15.52it/s, train_loss=0.208]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:16:47 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 1/1 [00:00<00:00, 14.69it/s, train_loss=0.147]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:16:48 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 1/1 [00:00<00:00, 14.88it/s, train_loss=0.0958]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:16:48 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 14.24it/s, train_loss=0.0855]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:16:48 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n",
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 13.64it/s, train_loss=0.0855]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/06/12 17:16:51 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 76.49it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/chapter22/lib/python3.9/site-packages/torch/nn/modules/transformer.py:382: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "2025/06/12 17:16:52 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID '046fa19dfc5f4f10925f4ffc1e826872', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current pytorch workflow\n",
      "\n",
      "  | Name                | Type                | Params | Mode \n",
      "--------------------------------------------------------------------\n",
      "0 | criterion           | MSELoss             | 0      | train\n",
      "1 | train_criterion     | MSELoss             | 0      | train\n",
      "2 | val_criterion       | MSELoss             | 0      | train\n",
      "3 | train_metrics       | MetricCollection    | 0      | train\n",
      "4 | val_metrics         | MetricCollection    | 0      | train\n",
      "5 | encoder             | Linear              | 96     | train\n",
      "6 | positional_encoding | _PositionalEncoding | 0      | train\n",
      "7 | transformer         | Transformer         | 318 K  | train\n",
      "8 | decoder             | Linear              | 396    | train\n",
      "--------------------------------------------------------------------\n",
      "319 K     Trainable params\n",
      "0         Non-trainable params\n",
      "319 K     Total params\n",
      "1.276     Total estimated model params size (MB)\n",
      "112       Modules in train mode\n",
      "0         Modules in eval mode\n",
      "/opt/anaconda3/envs/chapter22/lib/python3.9/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 0: 100%|██████████| 1/1 [00:00<00:00, 12.03it/s, train_loss=0.426]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:16:52 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 1/1 [00:00<00:00, 13.01it/s, train_loss=0.227]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:16:52 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 1/1 [00:00<00:00, 12.53it/s, train_loss=0.101]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:16:52 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 1/1 [00:00<00:00, 12.43it/s, train_loss=0.101]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:16:52 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 12.56it/s, train_loss=0.0894]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:16:52 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n",
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 12.10it/s, train_loss=0.0894]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/06/12 17:16:56 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 66.06it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/chapter22/lib/python3.9/site-packages/torch/nn/modules/transformer.py:382: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "2025/06/12 17:16:56 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID '0978e8adb6e8416b9833eda499ee3eb1', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current pytorch workflow\n",
      "\n",
      "  | Name                | Type                | Params | Mode \n",
      "--------------------------------------------------------------------\n",
      "0 | criterion           | MSELoss             | 0      | train\n",
      "1 | train_criterion     | MSELoss             | 0      | train\n",
      "2 | val_criterion       | MSELoss             | 0      | train\n",
      "3 | train_metrics       | MetricCollection    | 0      | train\n",
      "4 | val_metrics         | MetricCollection    | 0      | train\n",
      "5 | encoder             | Linear              | 96     | train\n",
      "6 | positional_encoding | _PositionalEncoding | 0      | train\n",
      "7 | transformer         | Transformer         | 201 K  | train\n",
      "8 | decoder             | Linear              | 396    | train\n",
      "--------------------------------------------------------------------\n",
      "201 K     Trainable params\n",
      "0         Non-trainable params\n",
      "201 K     Total params\n",
      "0.807     Total estimated model params size (MB)\n",
      "78        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "/opt/anaconda3/envs/chapter22/lib/python3.9/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 0: 100%|██████████| 1/1 [00:00<00:00, 12.80it/s, train_loss=0.577]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:16:56 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 1/1 [00:00<00:00, 16.68it/s, train_loss=0.311]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:16:56 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 1/1 [00:00<00:00, 18.98it/s, train_loss=0.169]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:16:56 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 1/1 [00:00<00:00, 18.06it/s, train_loss=0.128]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:16:56 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 19.16it/s, train_loss=0.124]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:16:56 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n",
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 18.22it/s, train_loss=0.124]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/06/12 17:17:00 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 82.82it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/chapter22/lib/python3.9/site-packages/torch/nn/modules/transformer.py:382: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "2025/06/12 17:17:00 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID '02d5c6cb686e4932b07176b110ae5720', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current pytorch workflow\n",
      "\n",
      "  | Name                | Type                | Params | Mode \n",
      "--------------------------------------------------------------------\n",
      "0 | criterion           | MSELoss             | 0      | train\n",
      "1 | train_criterion     | MSELoss             | 0      | train\n",
      "2 | val_criterion       | MSELoss             | 0      | train\n",
      "3 | train_metrics       | MetricCollection    | 0      | train\n",
      "4 | val_metrics         | MetricCollection    | 0      | train\n",
      "5 | encoder             | Linear              | 96     | train\n",
      "6 | positional_encoding | _PositionalEncoding | 0      | train\n",
      "7 | transformer         | Transformer         | 243 K  | train\n",
      "8 | decoder             | Linear              | 396    | train\n",
      "--------------------------------------------------------------------\n",
      "243 K     Trainable params\n",
      "0         Non-trainable params\n",
      "243 K     Total params\n",
      "0.975     Total estimated model params size (MB)\n",
      "92        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "/opt/anaconda3/envs/chapter22/lib/python3.9/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 0: 100%|██████████| 1/1 [00:00<00:00, 13.53it/s, train_loss=0.972]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:17:00 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 1/1 [00:00<00:00, 15.97it/s, train_loss=0.392]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:17:00 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 1/1 [00:00<00:00, 16.21it/s, train_loss=0.231]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:17:00 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 1/1 [00:00<00:00, 15.99it/s, train_loss=0.134]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:17:00 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 16.83it/s, train_loss=0.0693]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:17:00 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n",
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 16.05it/s, train_loss=0.0693]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/06/12 17:17:04 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 85.11it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/chapter22/lib/python3.9/site-packages/torch/nn/modules/transformer.py:382: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "2025/06/12 17:17:04 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID '0b661ec3d8fe43538ff3563fd630db8d', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current pytorch workflow\n",
      "\n",
      "  | Name                | Type                | Params | Mode \n",
      "--------------------------------------------------------------------\n",
      "0 | criterion           | MSELoss             | 0      | train\n",
      "1 | train_criterion     | MSELoss             | 0      | train\n",
      "2 | val_criterion       | MSELoss             | 0      | train\n",
      "3 | train_metrics       | MetricCollection    | 0      | train\n",
      "4 | val_metrics         | MetricCollection    | 0      | train\n",
      "5 | encoder             | Linear              | 96     | train\n",
      "6 | positional_encoding | _PositionalEncoding | 0      | train\n",
      "7 | transformer         | Transformer         | 238 K  | train\n",
      "8 | decoder             | Linear              | 396    | train\n",
      "--------------------------------------------------------------------\n",
      "239 K     Trainable params\n",
      "0         Non-trainable params\n",
      "239 K     Total params\n",
      "0.958     Total estimated model params size (MB)\n",
      "88        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "/opt/anaconda3/envs/chapter22/lib/python3.9/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 0: 100%|██████████| 1/1 [00:00<00:00, 15.78it/s, train_loss=0.836]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:17:04 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 1/1 [00:00<00:00, 16.37it/s, train_loss=0.349]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:17:04 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 1/1 [00:00<00:00, 16.89it/s, train_loss=0.149]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:17:04 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 1/1 [00:00<00:00, 16.75it/s, train_loss=0.0851]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:17:04 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 17.95it/s, train_loss=0.0772]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:17:04 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n",
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 17.06it/s, train_loss=0.0772]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/06/12 17:17:08 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 81.04it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/chapter22/lib/python3.9/site-packages/torch/nn/modules/transformer.py:382: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "2025/06/12 17:17:08 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID 'b1c28d97b7a8488cbff9a61b74d96952', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current pytorch workflow\n",
      "\n",
      "  | Name                | Type                | Params | Mode \n",
      "--------------------------------------------------------------------\n",
      "0 | criterion           | MSELoss             | 0      | train\n",
      "1 | train_criterion     | MSELoss             | 0      | train\n",
      "2 | val_criterion       | MSELoss             | 0      | train\n",
      "3 | train_metrics       | MetricCollection    | 0      | train\n",
      "4 | val_metrics         | MetricCollection    | 0      | train\n",
      "5 | encoder             | Linear              | 96     | train\n",
      "6 | positional_encoding | _PositionalEncoding | 0      | train\n",
      "7 | transformer         | Transformer         | 280 K  | train\n",
      "8 | decoder             | Linear              | 396    | train\n",
      "--------------------------------------------------------------------\n",
      "281 K     Trainable params\n",
      "0         Non-trainable params\n",
      "281 K     Total params\n",
      "1.126     Total estimated model params size (MB)\n",
      "102       Modules in train mode\n",
      "0         Modules in eval mode\n",
      "/opt/anaconda3/envs/chapter22/lib/python3.9/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 0: 100%|██████████| 1/1 [00:00<00:00, 13.02it/s, train_loss=0.799]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:17:08 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 1/1 [00:00<00:00, 14.38it/s, train_loss=0.247]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:17:08 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 1/1 [00:00<00:00, 14.91it/s, train_loss=0.186]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:17:08 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 1/1 [00:00<00:00, 13.62it/s, train_loss=0.137]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:17:09 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 14.07it/s, train_loss=0.0957]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:17:09 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n",
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 13.47it/s, train_loss=0.0957]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/06/12 17:17:12 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 75.90it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/chapter22/lib/python3.9/site-packages/torch/nn/modules/transformer.py:382: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "2025/06/12 17:17:12 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID '8357ad13bcbd4beeb449cba1897833e8', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current pytorch workflow\n",
      "\n",
      "  | Name                | Type                | Params | Mode \n",
      "--------------------------------------------------------------------\n",
      "0 | criterion           | MSELoss             | 0      | train\n",
      "1 | train_criterion     | MSELoss             | 0      | train\n",
      "2 | val_criterion       | MSELoss             | 0      | train\n",
      "3 | train_metrics       | MetricCollection    | 0      | train\n",
      "4 | val_metrics         | MetricCollection    | 0      | train\n",
      "5 | encoder             | Linear              | 96     | train\n",
      "6 | positional_encoding | _PositionalEncoding | 0      | train\n",
      "7 | transformer         | Transformer         | 276 K  | train\n",
      "8 | decoder             | Linear              | 396    | train\n",
      "--------------------------------------------------------------------\n",
      "277 K     Trainable params\n",
      "0         Non-trainable params\n",
      "277 K     Total params\n",
      "1.109     Total estimated model params size (MB)\n",
      "98        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "/opt/anaconda3/envs/chapter22/lib/python3.9/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 0: 100%|██████████| 1/1 [00:00<00:00, 14.44it/s, train_loss=0.395]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:17:13 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 1/1 [00:00<00:00, 15.41it/s, train_loss=0.234]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:17:13 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 1/1 [00:00<00:00, 15.23it/s, train_loss=0.137]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:17:13 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 1/1 [00:00<00:00, 14.69it/s, train_loss=0.107]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:17:13 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 15.40it/s, train_loss=0.105]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:17:13 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n",
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 14.74it/s, train_loss=0.105]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/06/12 17:17:16 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 75.97it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/chapter22/lib/python3.9/site-packages/torch/nn/modules/transformer.py:382: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "2025/06/12 17:17:17 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID '44a614dc4f574e928ba977ce840bb03d', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current pytorch workflow\n",
      "\n",
      "  | Name                | Type                | Params | Mode \n",
      "--------------------------------------------------------------------\n",
      "0 | criterion           | MSELoss             | 0      | train\n",
      "1 | train_criterion     | MSELoss             | 0      | train\n",
      "2 | val_criterion       | MSELoss             | 0      | train\n",
      "3 | train_metrics       | MetricCollection    | 0      | train\n",
      "4 | val_metrics         | MetricCollection    | 0      | train\n",
      "5 | encoder             | Linear              | 96     | train\n",
      "6 | positional_encoding | _PositionalEncoding | 0      | train\n",
      "7 | transformer         | Transformer         | 318 K  | train\n",
      "8 | decoder             | Linear              | 396    | train\n",
      "--------------------------------------------------------------------\n",
      "319 K     Trainable params\n",
      "0         Non-trainable params\n",
      "319 K     Total params\n",
      "1.276     Total estimated model params size (MB)\n",
      "112       Modules in train mode\n",
      "0         Modules in eval mode\n",
      "/opt/anaconda3/envs/chapter22/lib/python3.9/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 0: 100%|██████████| 1/1 [00:00<00:00, 12.10it/s, train_loss=0.477]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:17:17 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 1/1 [00:00<00:00, 13.06it/s, train_loss=0.238]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:17:17 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 1/1 [00:00<00:00, 12.88it/s, train_loss=0.112]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:17:17 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 1/1 [00:00<00:00, 13.40it/s, train_loss=0.0997]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:17:17 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 13.43it/s, train_loss=0.0851]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:17:17 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n",
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 12.93it/s, train_loss=0.0851]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/06/12 17:17:21 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 70.31it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/chapter22/lib/python3.9/site-packages/torch/nn/modules/transformer.py:382: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "2025/06/12 17:17:21 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID 'd33aa85b227d44e0afac61a1ffe22fcb', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current pytorch workflow\n",
      "\n",
      "  | Name                | Type                | Params | Mode \n",
      "--------------------------------------------------------------------\n",
      "0 | criterion           | MSELoss             | 0      | train\n",
      "1 | train_criterion     | MSELoss             | 0      | train\n",
      "2 | val_criterion       | MSELoss             | 0      | train\n",
      "3 | train_metrics       | MetricCollection    | 0      | train\n",
      "4 | val_metrics         | MetricCollection    | 0      | train\n",
      "5 | encoder             | Linear              | 192    | train\n",
      "6 | positional_encoding | _PositionalEncoding | 0      | train\n",
      "7 | transformer         | Transformer         | 465 K  | train\n",
      "8 | decoder             | Linear              | 780    | train\n",
      "--------------------------------------------------------------------\n",
      "466 K     Trainable params\n",
      "0         Non-trainable params\n",
      "466 K     Total params\n",
      "1.866     Total estimated model params size (MB)\n",
      "78        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "/opt/anaconda3/envs/chapter22/lib/python3.9/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 0: 100%|██████████| 1/1 [00:00<00:00, 13.54it/s, train_loss=0.392]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:17:21 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 1/1 [00:00<00:00, 18.51it/s, train_loss=0.328]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:17:21 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 1/1 [00:00<00:00, 17.47it/s, train_loss=0.156]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:17:21 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 1/1 [00:00<00:00, 19.46it/s, train_loss=0.101]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:17:21 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 18.90it/s, train_loss=0.0888]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:17:21 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n",
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 17.94it/s, train_loss=0.0888]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/06/12 17:17:25 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 90.90it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/chapter22/lib/python3.9/site-packages/torch/nn/modules/transformer.py:382: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "2025/06/12 17:17:25 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID 'f54d0242dfe74d3681ad605a733108b7', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current pytorch workflow\n",
      "\n",
      "  | Name                | Type                | Params | Mode \n",
      "--------------------------------------------------------------------\n",
      "0 | criterion           | MSELoss             | 0      | train\n",
      "1 | train_criterion     | MSELoss             | 0      | train\n",
      "2 | val_criterion       | MSELoss             | 0      | train\n",
      "3 | train_metrics       | MetricCollection    | 0      | train\n",
      "4 | val_metrics         | MetricCollection    | 0      | train\n",
      "5 | encoder             | Linear              | 192    | train\n",
      "6 | positional_encoding | _PositionalEncoding | 0      | train\n",
      "7 | transformer         | Transformer         | 565 K  | train\n",
      "8 | decoder             | Linear              | 780    | train\n",
      "--------------------------------------------------------------------\n",
      "566 K     Trainable params\n",
      "0         Non-trainable params\n",
      "566 K     Total params\n",
      "2.265     Total estimated model params size (MB)\n",
      "92        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "/opt/anaconda3/envs/chapter22/lib/python3.9/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 0: 100%|██████████| 1/1 [00:00<00:00, 14.39it/s, train_loss=0.745]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:17:25 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 1/1 [00:00<00:00, 15.48it/s, train_loss=0.515]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:17:25 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 1/1 [00:00<00:00, 15.55it/s, train_loss=0.218]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:17:25 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 1/1 [00:00<00:00, 15.40it/s, train_loss=0.0841]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:17:25 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 15.68it/s, train_loss=0.0788]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:17:25 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n",
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 15.01it/s, train_loss=0.0788]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/06/12 17:17:29 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 87.80it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/chapter22/lib/python3.9/site-packages/torch/nn/modules/transformer.py:382: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "2025/06/12 17:17:29 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID '321ce248343b48c792715bde8d047c26', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current pytorch workflow\n",
      "\n",
      "  | Name                | Type                | Params | Mode \n",
      "--------------------------------------------------------------------\n",
      "0 | criterion           | MSELoss             | 0      | train\n",
      "1 | train_criterion     | MSELoss             | 0      | train\n",
      "2 | val_criterion       | MSELoss             | 0      | train\n",
      "3 | train_metrics       | MetricCollection    | 0      | train\n",
      "4 | val_metrics         | MetricCollection    | 0      | train\n",
      "5 | encoder             | Linear              | 192    | train\n",
      "6 | positional_encoding | _PositionalEncoding | 0      | train\n",
      "7 | transformer         | Transformer         | 548 K  | train\n",
      "8 | decoder             | Linear              | 780    | train\n",
      "--------------------------------------------------------------------\n",
      "549 K     Trainable params\n",
      "0         Non-trainable params\n",
      "549 K     Total params\n",
      "2.198     Total estimated model params size (MB)\n",
      "88        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "/opt/anaconda3/envs/chapter22/lib/python3.9/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 0: 100%|██████████| 1/1 [00:00<00:00, 15.63it/s, train_loss=0.689]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:17:29 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 1/1 [00:00<00:00, 16.08it/s, train_loss=0.493]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:17:29 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 1/1 [00:00<00:00, 16.72it/s, train_loss=0.210]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:17:29 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 1/1 [00:00<00:00, 16.78it/s, train_loss=0.136]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:17:29 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 16.07it/s, train_loss=0.0828]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:17:30 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n",
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 15.41it/s, train_loss=0.0828]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/06/12 17:17:33 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 83.46it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/chapter22/lib/python3.9/site-packages/torch/nn/modules/transformer.py:382: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "2025/06/12 17:17:33 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID '9807cc83db544cb98035059c9b5683e8', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current pytorch workflow\n",
      "\n",
      "  | Name                | Type                | Params | Mode \n",
      "--------------------------------------------------------------------\n",
      "0 | criterion           | MSELoss             | 0      | train\n",
      "1 | train_criterion     | MSELoss             | 0      | train\n",
      "2 | val_criterion       | MSELoss             | 0      | train\n",
      "3 | train_metrics       | MetricCollection    | 0      | train\n",
      "4 | val_metrics         | MetricCollection    | 0      | train\n",
      "5 | encoder             | Linear              | 192    | train\n",
      "6 | positional_encoding | _PositionalEncoding | 0      | train\n",
      "7 | transformer         | Transformer         | 648 K  | train\n",
      "8 | decoder             | Linear              | 780    | train\n",
      "--------------------------------------------------------------------\n",
      "649 K     Trainable params\n",
      "0         Non-trainable params\n",
      "649 K     Total params\n",
      "2.597     Total estimated model params size (MB)\n",
      "102       Modules in train mode\n",
      "0         Modules in eval mode\n",
      "/opt/anaconda3/envs/chapter22/lib/python3.9/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 0: 100%|██████████| 1/1 [00:00<00:00, 12.47it/s, train_loss=0.637]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:17:33 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 1/1 [00:00<00:00, 13.90it/s, train_loss=0.236]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:17:33 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 1/1 [00:00<00:00, 14.62it/s, train_loss=0.135]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:17:34 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 1/1 [00:00<00:00, 14.60it/s, train_loss=0.0932]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:17:34 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 14.32it/s, train_loss=0.104] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:17:34 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n",
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 13.69it/s, train_loss=0.104]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/06/12 17:17:37 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 85.35it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/chapter22/lib/python3.9/site-packages/torch/nn/modules/transformer.py:382: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "2025/06/12 17:17:38 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID '507107247b094f2dbb11d4102f62fa46', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current pytorch workflow\n",
      "\n",
      "  | Name                | Type                | Params | Mode \n",
      "--------------------------------------------------------------------\n",
      "0 | criterion           | MSELoss             | 0      | train\n",
      "1 | train_criterion     | MSELoss             | 0      | train\n",
      "2 | val_criterion       | MSELoss             | 0      | train\n",
      "3 | train_metrics       | MetricCollection    | 0      | train\n",
      "4 | val_metrics         | MetricCollection    | 0      | train\n",
      "5 | encoder             | Linear              | 192    | train\n",
      "6 | positional_encoding | _PositionalEncoding | 0      | train\n",
      "7 | transformer         | Transformer         | 631 K  | train\n",
      "8 | decoder             | Linear              | 780    | train\n",
      "--------------------------------------------------------------------\n",
      "632 K     Trainable params\n",
      "0         Non-trainable params\n",
      "632 K     Total params\n",
      "2.530     Total estimated model params size (MB)\n",
      "98        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "/opt/anaconda3/envs/chapter22/lib/python3.9/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 0: 100%|██████████| 1/1 [00:00<00:00, 14.36it/s, train_loss=0.698]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:17:38 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 1/1 [00:00<00:00, 14.96it/s, train_loss=0.233]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:17:38 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 1/1 [00:00<00:00, 15.02it/s, train_loss=0.141]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:17:38 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 1/1 [00:00<00:00, 15.79it/s, train_loss=0.102]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:17:38 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 15.35it/s, train_loss=0.0933]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:17:38 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n",
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 14.61it/s, train_loss=0.0933]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/06/12 17:17:42 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 78.52it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/chapter22/lib/python3.9/site-packages/torch/nn/modules/transformer.py:382: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "2025/06/12 17:17:42 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID '951fdb3abbf245618d50c94597a8b771', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current pytorch workflow\n",
      "\n",
      "  | Name                | Type                | Params | Mode \n",
      "--------------------------------------------------------------------\n",
      "0 | criterion           | MSELoss             | 0      | train\n",
      "1 | train_criterion     | MSELoss             | 0      | train\n",
      "2 | val_criterion       | MSELoss             | 0      | train\n",
      "3 | train_metrics       | MetricCollection    | 0      | train\n",
      "4 | val_metrics         | MetricCollection    | 0      | train\n",
      "5 | encoder             | Linear              | 192    | train\n",
      "6 | positional_encoding | _PositionalEncoding | 0      | train\n",
      "7 | transformer         | Transformer         | 731 K  | train\n",
      "8 | decoder             | Linear              | 780    | train\n",
      "--------------------------------------------------------------------\n",
      "732 K     Trainable params\n",
      "0         Non-trainable params\n",
      "732 K     Total params\n",
      "2.929     Total estimated model params size (MB)\n",
      "112       Modules in train mode\n",
      "0         Modules in eval mode\n",
      "/opt/anaconda3/envs/chapter22/lib/python3.9/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 0: 100%|██████████| 1/1 [00:00<00:00, 11.91it/s, train_loss=0.801]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:17:42 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 1/1 [00:00<00:00, 13.63it/s, train_loss=0.379]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:17:42 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 1/1 [00:00<00:00, 13.26it/s, train_loss=0.164]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:17:42 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 1/1 [00:00<00:00, 13.22it/s, train_loss=0.121]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:17:42 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 13.43it/s, train_loss=0.0899]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:17:42 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n",
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 12.92it/s, train_loss=0.0899]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/06/12 17:17:46 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 80.14it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/chapter22/lib/python3.9/site-packages/torch/nn/modules/transformer.py:382: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "2025/06/12 17:17:46 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID 'b402b0e5630a4f459a6b5493719acb02', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current pytorch workflow\n",
      "\n",
      "  | Name                | Type                | Params | Mode \n",
      "--------------------------------------------------------------------\n",
      "0 | criterion           | MSELoss             | 0      | train\n",
      "1 | train_criterion     | MSELoss             | 0      | train\n",
      "2 | val_criterion       | MSELoss             | 0      | train\n",
      "3 | train_metrics       | MetricCollection    | 0      | train\n",
      "4 | val_metrics         | MetricCollection    | 0      | train\n",
      "5 | encoder             | Linear              | 192    | train\n",
      "6 | positional_encoding | _PositionalEncoding | 0      | train\n",
      "7 | transformer         | Transformer         | 465 K  | train\n",
      "8 | decoder             | Linear              | 780    | train\n",
      "--------------------------------------------------------------------\n",
      "466 K     Trainable params\n",
      "0         Non-trainable params\n",
      "466 K     Total params\n",
      "1.866     Total estimated model params size (MB)\n",
      "78        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "/opt/anaconda3/envs/chapter22/lib/python3.9/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 0: 100%|██████████| 1/1 [00:00<00:00, 13.68it/s, train_loss=0.395]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:17:46 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 1/1 [00:00<00:00, 19.30it/s, train_loss=0.313]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:17:46 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 1/1 [00:00<00:00, 18.97it/s, train_loss=0.154]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:17:46 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 1/1 [00:00<00:00, 18.30it/s, train_loss=0.0996]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:17:46 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 19.66it/s, train_loss=0.0808]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:17:46 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n",
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 18.58it/s, train_loss=0.0808]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/06/12 17:17:50 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 99.84it/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/chapter22/lib/python3.9/site-packages/torch/nn/modules/transformer.py:382: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "2025/06/12 17:17:50 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID 'd528f9add82a498691b3a4aadbe5fdb6', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current pytorch workflow\n",
      "\n",
      "  | Name                | Type                | Params | Mode \n",
      "--------------------------------------------------------------------\n",
      "0 | criterion           | MSELoss             | 0      | train\n",
      "1 | train_criterion     | MSELoss             | 0      | train\n",
      "2 | val_criterion       | MSELoss             | 0      | train\n",
      "3 | train_metrics       | MetricCollection    | 0      | train\n",
      "4 | val_metrics         | MetricCollection    | 0      | train\n",
      "5 | encoder             | Linear              | 192    | train\n",
      "6 | positional_encoding | _PositionalEncoding | 0      | train\n",
      "7 | transformer         | Transformer         | 565 K  | train\n",
      "8 | decoder             | Linear              | 780    | train\n",
      "--------------------------------------------------------------------\n",
      "566 K     Trainable params\n",
      "0         Non-trainable params\n",
      "566 K     Total params\n",
      "2.265     Total estimated model params size (MB)\n",
      "92        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "/opt/anaconda3/envs/chapter22/lib/python3.9/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 0: 100%|██████████| 1/1 [00:00<00:00, 14.02it/s, train_loss=0.768]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:17:50 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 1/1 [00:00<00:00, 16.48it/s, train_loss=0.513]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:17:50 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 1/1 [00:00<00:00, 15.93it/s, train_loss=0.210]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:17:50 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 1/1 [00:00<00:00, 15.59it/s, train_loss=0.087]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:17:50 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 15.84it/s, train_loss=0.082]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:17:50 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n",
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 15.13it/s, train_loss=0.082]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/06/12 17:17:54 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 79.26it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/chapter22/lib/python3.9/site-packages/torch/nn/modules/transformer.py:382: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "2025/06/12 17:17:54 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID '91a67ac76b5f4bf0a6d2f1c1d52cf9f4', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current pytorch workflow\n",
      "\n",
      "  | Name                | Type                | Params | Mode \n",
      "--------------------------------------------------------------------\n",
      "0 | criterion           | MSELoss             | 0      | train\n",
      "1 | train_criterion     | MSELoss             | 0      | train\n",
      "2 | val_criterion       | MSELoss             | 0      | train\n",
      "3 | train_metrics       | MetricCollection    | 0      | train\n",
      "4 | val_metrics         | MetricCollection    | 0      | train\n",
      "5 | encoder             | Linear              | 192    | train\n",
      "6 | positional_encoding | _PositionalEncoding | 0      | train\n",
      "7 | transformer         | Transformer         | 548 K  | train\n",
      "8 | decoder             | Linear              | 780    | train\n",
      "--------------------------------------------------------------------\n",
      "549 K     Trainable params\n",
      "0         Non-trainable params\n",
      "549 K     Total params\n",
      "2.198     Total estimated model params size (MB)\n",
      "88        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "/opt/anaconda3/envs/chapter22/lib/python3.9/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 0: 100%|██████████| 1/1 [00:00<00:00, 15.06it/s, train_loss=0.703]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:17:54 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 1/1 [00:00<00:00, 16.31it/s, train_loss=0.494]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:17:54 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 1/1 [00:00<00:00, 17.20it/s, train_loss=0.232]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:17:54 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 1/1 [00:00<00:00, 16.99it/s, train_loss=0.149]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:17:54 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 17.28it/s, train_loss=0.0905]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:17:54 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n",
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 16.49it/s, train_loss=0.0905]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/06/12 17:17:58 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 88.35it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/chapter22/lib/python3.9/site-packages/torch/nn/modules/transformer.py:382: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "2025/06/12 17:17:58 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID '183469e1df1c46fbaaba64e5f2373d6d', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current pytorch workflow\n",
      "\n",
      "  | Name                | Type                | Params | Mode \n",
      "--------------------------------------------------------------------\n",
      "0 | criterion           | MSELoss             | 0      | train\n",
      "1 | train_criterion     | MSELoss             | 0      | train\n",
      "2 | val_criterion       | MSELoss             | 0      | train\n",
      "3 | train_metrics       | MetricCollection    | 0      | train\n",
      "4 | val_metrics         | MetricCollection    | 0      | train\n",
      "5 | encoder             | Linear              | 192    | train\n",
      "6 | positional_encoding | _PositionalEncoding | 0      | train\n",
      "7 | transformer         | Transformer         | 648 K  | train\n",
      "8 | decoder             | Linear              | 780    | train\n",
      "--------------------------------------------------------------------\n",
      "649 K     Trainable params\n",
      "0         Non-trainable params\n",
      "649 K     Total params\n",
      "2.597     Total estimated model params size (MB)\n",
      "102       Modules in train mode\n",
      "0         Modules in eval mode\n",
      "/opt/anaconda3/envs/chapter22/lib/python3.9/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 0: 100%|██████████| 1/1 [00:00<00:00, 13.30it/s, train_loss=0.625]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:17:58 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 1/1 [00:00<00:00, 14.08it/s, train_loss=0.206]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:17:58 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 1/1 [00:00<00:00, 15.41it/s, train_loss=0.115]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:17:58 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 1/1 [00:00<00:00, 14.18it/s, train_loss=0.0924]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:17:59 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 14.92it/s, train_loss=0.100] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:17:59 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n",
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 14.28it/s, train_loss=0.100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/06/12 17:18:02 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 80.66it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/chapter22/lib/python3.9/site-packages/torch/nn/modules/transformer.py:382: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "2025/06/12 17:18:02 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID 'd4830103109c46b3855456f38e9c8131', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current pytorch workflow\n",
      "\n",
      "  | Name                | Type                | Params | Mode \n",
      "--------------------------------------------------------------------\n",
      "0 | criterion           | MSELoss             | 0      | train\n",
      "1 | train_criterion     | MSELoss             | 0      | train\n",
      "2 | val_criterion       | MSELoss             | 0      | train\n",
      "3 | train_metrics       | MetricCollection    | 0      | train\n",
      "4 | val_metrics         | MetricCollection    | 0      | train\n",
      "5 | encoder             | Linear              | 192    | train\n",
      "6 | positional_encoding | _PositionalEncoding | 0      | train\n",
      "7 | transformer         | Transformer         | 631 K  | train\n",
      "8 | decoder             | Linear              | 780    | train\n",
      "--------------------------------------------------------------------\n",
      "632 K     Trainable params\n",
      "0         Non-trainable params\n",
      "632 K     Total params\n",
      "2.530     Total estimated model params size (MB)\n",
      "98        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "/opt/anaconda3/envs/chapter22/lib/python3.9/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 0: 100%|██████████| 1/1 [00:00<00:00, 13.88it/s, train_loss=0.710]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:18:03 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 1/1 [00:00<00:00, 15.14it/s, train_loss=0.247]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:18:03 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 1/1 [00:00<00:00, 15.08it/s, train_loss=0.140]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:18:03 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 1/1 [00:00<00:00, 14.99it/s, train_loss=0.0988]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:18:03 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 15.29it/s, train_loss=0.0891]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:18:03 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n",
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 14.64it/s, train_loss=0.0891]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/06/12 17:18:07 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 78.39it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/chapter22/lib/python3.9/site-packages/torch/nn/modules/transformer.py:382: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "2025/06/12 17:18:07 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID 'd411e0907145463e8c6c3f1242822b68', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current pytorch workflow\n",
      "\n",
      "  | Name                | Type                | Params | Mode \n",
      "--------------------------------------------------------------------\n",
      "0 | criterion           | MSELoss             | 0      | train\n",
      "1 | train_criterion     | MSELoss             | 0      | train\n",
      "2 | val_criterion       | MSELoss             | 0      | train\n",
      "3 | train_metrics       | MetricCollection    | 0      | train\n",
      "4 | val_metrics         | MetricCollection    | 0      | train\n",
      "5 | encoder             | Linear              | 192    | train\n",
      "6 | positional_encoding | _PositionalEncoding | 0      | train\n",
      "7 | transformer         | Transformer         | 731 K  | train\n",
      "8 | decoder             | Linear              | 780    | train\n",
      "--------------------------------------------------------------------\n",
      "732 K     Trainable params\n",
      "0         Non-trainable params\n",
      "732 K     Total params\n",
      "2.929     Total estimated model params size (MB)\n",
      "112       Modules in train mode\n",
      "0         Modules in eval mode\n",
      "/opt/anaconda3/envs/chapter22/lib/python3.9/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 0: 100%|██████████| 1/1 [00:00<00:00, 12.57it/s, train_loss=0.809]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:18:07 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 1/1 [00:00<00:00, 12.69it/s, train_loss=0.384]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:18:07 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 1/1 [00:00<00:00, 13.45it/s, train_loss=0.143]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:18:07 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 1/1 [00:00<00:00, 12.95it/s, train_loss=0.123]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:18:07 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 13.63it/s, train_loss=0.0903]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:18:07 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n",
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 13.11it/s, train_loss=0.0903]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/06/12 17:18:11 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 72.90it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/chapter22/lib/python3.9/site-packages/torch/nn/modules/transformer.py:382: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "2025/06/12 17:18:11 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID '8022f0c2562d4789bcc1aafbc03004ef', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current pytorch workflow\n",
      "\n",
      "  | Name                | Type                | Params | Mode \n",
      "--------------------------------------------------------------------\n",
      "0 | criterion           | MSELoss             | 0      | train\n",
      "1 | train_criterion     | MSELoss             | 0      | train\n",
      "2 | val_criterion       | MSELoss             | 0      | train\n",
      "3 | train_metrics       | MetricCollection    | 0      | train\n",
      "4 | val_metrics         | MetricCollection    | 0      | train\n",
      "5 | encoder             | Linear              | 96     | train\n",
      "6 | positional_encoding | _PositionalEncoding | 0      | train\n",
      "7 | transformer         | Transformer         | 201 K  | train\n",
      "8 | decoder             | Linear              | 396    | train\n",
      "--------------------------------------------------------------------\n",
      "201 K     Trainable params\n",
      "0         Non-trainable params\n",
      "201 K     Total params\n",
      "0.807     Total estimated model params size (MB)\n",
      "78        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "/opt/anaconda3/envs/chapter22/lib/python3.9/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 0: 100%|██████████| 1/1 [00:00<00:00, 13.47it/s, train_loss=0.560]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:18:11 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 1/1 [00:00<00:00, 19.21it/s, train_loss=0.270]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:18:11 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 1/1 [00:00<00:00, 18.31it/s, train_loss=0.183]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:18:11 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 1/1 [00:00<00:00, 19.08it/s, train_loss=0.134]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:18:11 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 19.65it/s, train_loss=0.118]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:18:11 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 1/1 [00:00<00:00, 17.98it/s, train_loss=0.0966]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:18:11 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 1/1 [00:00<00:00, 19.03it/s, train_loss=0.080] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:18:11 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 1/1 [00:00<00:00, 19.12it/s, train_loss=0.077]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:18:11 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 1/1 [00:00<00:00, 19.27it/s, train_loss=0.082]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:18:12 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 19.55it/s, train_loss=0.0894]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:18:12 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n",
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 18.34it/s, train_loss=0.0894]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/06/12 17:18:15 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 96.82it/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/chapter22/lib/python3.9/site-packages/torch/nn/modules/transformer.py:382: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "2025/06/12 17:18:16 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID '4ebbc34d4c084d2e8553511544586cad', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current pytorch workflow\n",
      "\n",
      "  | Name                | Type                | Params | Mode \n",
      "--------------------------------------------------------------------\n",
      "0 | criterion           | MSELoss             | 0      | train\n",
      "1 | train_criterion     | MSELoss             | 0      | train\n",
      "2 | val_criterion       | MSELoss             | 0      | train\n",
      "3 | train_metrics       | MetricCollection    | 0      | train\n",
      "4 | val_metrics         | MetricCollection    | 0      | train\n",
      "5 | encoder             | Linear              | 96     | train\n",
      "6 | positional_encoding | _PositionalEncoding | 0      | train\n",
      "7 | transformer         | Transformer         | 243 K  | train\n",
      "8 | decoder             | Linear              | 396    | train\n",
      "--------------------------------------------------------------------\n",
      "243 K     Trainable params\n",
      "0         Non-trainable params\n",
      "243 K     Total params\n",
      "0.975     Total estimated model params size (MB)\n",
      "92        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "/opt/anaconda3/envs/chapter22/lib/python3.9/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 0: 100%|██████████| 1/1 [00:00<00:00, 14.61it/s, train_loss=0.945]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:18:16 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 1/1 [00:00<00:00, 16.30it/s, train_loss=0.344]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:18:16 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 1/1 [00:00<00:00, 15.40it/s, train_loss=0.215]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:18:16 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 1/1 [00:00<00:00, 16.01it/s, train_loss=0.113]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:18:16 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 15.85it/s, train_loss=0.0676]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:18:16 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 1/1 [00:00<00:00, 16.39it/s, train_loss=0.0777]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:18:16 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 1/1 [00:00<00:00, 16.06it/s, train_loss=0.0819]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:18:16 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 1/1 [00:00<00:00, 15.71it/s, train_loss=0.0772]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:18:16 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 1/1 [00:00<00:00, 15.68it/s, train_loss=0.0909]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:18:16 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 16.53it/s, train_loss=0.0757]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:18:16 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n",
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 15.78it/s, train_loss=0.0757]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/06/12 17:18:20 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 86.34it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/chapter22/lib/python3.9/site-packages/torch/nn/modules/transformer.py:382: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "2025/06/12 17:18:20 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID '5021d31a8c4e409f9fd5b904be351a09', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current pytorch workflow\n",
      "\n",
      "  | Name                | Type                | Params | Mode \n",
      "--------------------------------------------------------------------\n",
      "0 | criterion           | MSELoss             | 0      | train\n",
      "1 | train_criterion     | MSELoss             | 0      | train\n",
      "2 | val_criterion       | MSELoss             | 0      | train\n",
      "3 | train_metrics       | MetricCollection    | 0      | train\n",
      "4 | val_metrics         | MetricCollection    | 0      | train\n",
      "5 | encoder             | Linear              | 96     | train\n",
      "6 | positional_encoding | _PositionalEncoding | 0      | train\n",
      "7 | transformer         | Transformer         | 238 K  | train\n",
      "8 | decoder             | Linear              | 396    | train\n",
      "--------------------------------------------------------------------\n",
      "239 K     Trainable params\n",
      "0         Non-trainable params\n",
      "239 K     Total params\n",
      "0.958     Total estimated model params size (MB)\n",
      "88        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "/opt/anaconda3/envs/chapter22/lib/python3.9/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 0: 100%|██████████| 1/1 [00:00<00:00, 14.98it/s, train_loss=0.841]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:18:20 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 1/1 [00:00<00:00, 17.20it/s, train_loss=0.338]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:18:20 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 1/1 [00:00<00:00, 16.81it/s, train_loss=0.155]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:18:20 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 1/1 [00:00<00:00, 17.03it/s, train_loss=0.0972]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:18:20 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 16.69it/s, train_loss=0.0737]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:18:20 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 1/1 [00:00<00:00, 16.30it/s, train_loss=0.0846]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:18:20 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 1/1 [00:00<00:00, 16.59it/s, train_loss=0.0974]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:18:21 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 1/1 [00:00<00:00, 16.97it/s, train_loss=0.085] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:18:21 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 1/1 [00:00<00:00, 16.58it/s, train_loss=0.0843]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:18:21 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 16.41it/s, train_loss=0.0694]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:18:21 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n",
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 15.68it/s, train_loss=0.0694]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/06/12 17:18:24 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 75.23it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/chapter22/lib/python3.9/site-packages/torch/nn/modules/transformer.py:382: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "2025/06/12 17:18:25 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID '8296bf32a9444bde99d33b759c992fb0', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current pytorch workflow\n",
      "\n",
      "  | Name                | Type                | Params | Mode \n",
      "--------------------------------------------------------------------\n",
      "0 | criterion           | MSELoss             | 0      | train\n",
      "1 | train_criterion     | MSELoss             | 0      | train\n",
      "2 | val_criterion       | MSELoss             | 0      | train\n",
      "3 | train_metrics       | MetricCollection    | 0      | train\n",
      "4 | val_metrics         | MetricCollection    | 0      | train\n",
      "5 | encoder             | Linear              | 96     | train\n",
      "6 | positional_encoding | _PositionalEncoding | 0      | train\n",
      "7 | transformer         | Transformer         | 280 K  | train\n",
      "8 | decoder             | Linear              | 396    | train\n",
      "--------------------------------------------------------------------\n",
      "281 K     Trainable params\n",
      "0         Non-trainable params\n",
      "281 K     Total params\n",
      "1.126     Total estimated model params size (MB)\n",
      "102       Modules in train mode\n",
      "0         Modules in eval mode\n",
      "/opt/anaconda3/envs/chapter22/lib/python3.9/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 0: 100%|██████████| 1/1 [00:00<00:00, 13.46it/s, train_loss=0.745]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:18:25 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 1/1 [00:00<00:00, 14.08it/s, train_loss=0.258]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:18:25 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 1/1 [00:00<00:00, 14.75it/s, train_loss=0.209]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:18:25 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 1/1 [00:00<00:00, 14.67it/s, train_loss=0.149]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:18:25 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 14.84it/s, train_loss=0.102]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:18:25 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 1/1 [00:00<00:00, 14.20it/s, train_loss=0.0795]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:18:25 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 1/1 [00:00<00:00, 13.85it/s, train_loss=0.0758]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:18:25 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 1/1 [00:00<00:00, 14.33it/s, train_loss=0.088] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:18:25 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 1/1 [00:00<00:00, 14.91it/s, train_loss=0.0753]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:18:25 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 14.55it/s, train_loss=0.0669]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:18:25 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n",
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 13.95it/s, train_loss=0.0669]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/06/12 17:18:29 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 75.70it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/chapter22/lib/python3.9/site-packages/torch/nn/modules/transformer.py:382: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "2025/06/12 17:18:29 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID '1150358235de4d6681a7b43188a64cdb', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current pytorch workflow\n",
      "\n",
      "  | Name                | Type                | Params | Mode \n",
      "--------------------------------------------------------------------\n",
      "0 | criterion           | MSELoss             | 0      | train\n",
      "1 | train_criterion     | MSELoss             | 0      | train\n",
      "2 | val_criterion       | MSELoss             | 0      | train\n",
      "3 | train_metrics       | MetricCollection    | 0      | train\n",
      "4 | val_metrics         | MetricCollection    | 0      | train\n",
      "5 | encoder             | Linear              | 96     | train\n",
      "6 | positional_encoding | _PositionalEncoding | 0      | train\n",
      "7 | transformer         | Transformer         | 276 K  | train\n",
      "8 | decoder             | Linear              | 396    | train\n",
      "--------------------------------------------------------------------\n",
      "277 K     Trainable params\n",
      "0         Non-trainable params\n",
      "277 K     Total params\n",
      "1.109     Total estimated model params size (MB)\n",
      "98        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "/opt/anaconda3/envs/chapter22/lib/python3.9/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 0: 100%|██████████| 1/1 [00:00<00:00, 13.55it/s, train_loss=0.383]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:18:29 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 1/1 [00:00<00:00, 15.40it/s, train_loss=0.208]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:18:29 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 1/1 [00:00<00:00, 15.18it/s, train_loss=0.147]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:18:29 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 1/1 [00:00<00:00, 15.85it/s, train_loss=0.0958]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:18:29 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 14.69it/s, train_loss=0.0855]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:18:29 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 1/1 [00:00<00:00, 14.90it/s, train_loss=0.0787]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:18:30 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 1/1 [00:00<00:00, 15.57it/s, train_loss=0.0866]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:18:30 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 1/1 [00:00<00:00, 15.19it/s, train_loss=0.0737]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:18:30 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 1/1 [00:00<00:00, 15.39it/s, train_loss=0.0721]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:18:30 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 15.44it/s, train_loss=0.0631]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:18:30 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n",
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 14.78it/s, train_loss=0.0631]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/06/12 17:18:33 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 76.83it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/chapter22/lib/python3.9/site-packages/torch/nn/modules/transformer.py:382: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "2025/06/12 17:18:34 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID '386f0940e6d54ccf9f2d6c335aa9c30f', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current pytorch workflow\n",
      "\n",
      "  | Name                | Type                | Params | Mode \n",
      "--------------------------------------------------------------------\n",
      "0 | criterion           | MSELoss             | 0      | train\n",
      "1 | train_criterion     | MSELoss             | 0      | train\n",
      "2 | val_criterion       | MSELoss             | 0      | train\n",
      "3 | train_metrics       | MetricCollection    | 0      | train\n",
      "4 | val_metrics         | MetricCollection    | 0      | train\n",
      "5 | encoder             | Linear              | 96     | train\n",
      "6 | positional_encoding | _PositionalEncoding | 0      | train\n",
      "7 | transformer         | Transformer         | 318 K  | train\n",
      "8 | decoder             | Linear              | 396    | train\n",
      "--------------------------------------------------------------------\n",
      "319 K     Trainable params\n",
      "0         Non-trainable params\n",
      "319 K     Total params\n",
      "1.276     Total estimated model params size (MB)\n",
      "112       Modules in train mode\n",
      "0         Modules in eval mode\n",
      "/opt/anaconda3/envs/chapter22/lib/python3.9/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 0: 100%|██████████| 1/1 [00:00<00:00, 12.09it/s, train_loss=0.426]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:18:34 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 1/1 [00:00<00:00, 13.26it/s, train_loss=0.227]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:18:34 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 1/1 [00:00<00:00, 12.82it/s, train_loss=0.101]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:18:34 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 1/1 [00:00<00:00, 13.39it/s, train_loss=0.101]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:18:34 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 13.36it/s, train_loss=0.0894]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:18:34 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 1/1 [00:00<00:00, 13.11it/s, train_loss=0.0903]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:18:34 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 1/1 [00:00<00:00, 13.46it/s, train_loss=0.079] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:18:34 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 1/1 [00:00<00:00, 13.43it/s, train_loss=0.0777]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:18:34 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 1/1 [00:00<00:00, 13.98it/s, train_loss=0.0803]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:18:34 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 13.87it/s, train_loss=0.0761]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:18:34 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n",
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 13.39it/s, train_loss=0.0761]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/06/12 17:18:38 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 75.45it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/chapter22/lib/python3.9/site-packages/torch/nn/modules/transformer.py:382: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "2025/06/12 17:18:38 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID 'b81d9bb1b4334164bb76e605c8a0d596', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current pytorch workflow\n",
      "\n",
      "  | Name                | Type                | Params | Mode \n",
      "--------------------------------------------------------------------\n",
      "0 | criterion           | MSELoss             | 0      | train\n",
      "1 | train_criterion     | MSELoss             | 0      | train\n",
      "2 | val_criterion       | MSELoss             | 0      | train\n",
      "3 | train_metrics       | MetricCollection    | 0      | train\n",
      "4 | val_metrics         | MetricCollection    | 0      | train\n",
      "5 | encoder             | Linear              | 96     | train\n",
      "6 | positional_encoding | _PositionalEncoding | 0      | train\n",
      "7 | transformer         | Transformer         | 201 K  | train\n",
      "8 | decoder             | Linear              | 396    | train\n",
      "--------------------------------------------------------------------\n",
      "201 K     Trainable params\n",
      "0         Non-trainable params\n",
      "201 K     Total params\n",
      "0.807     Total estimated model params size (MB)\n",
      "78        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "/opt/anaconda3/envs/chapter22/lib/python3.9/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 0: 100%|██████████| 1/1 [00:00<00:00, 13.35it/s, train_loss=0.577]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:18:38 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 1/1 [00:00<00:00, 19.55it/s, train_loss=0.311]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:18:38 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 1/1 [00:00<00:00, 18.56it/s, train_loss=0.169]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:18:38 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 1/1 [00:00<00:00, 19.20it/s, train_loss=0.128]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:18:38 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 18.95it/s, train_loss=0.124]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:18:39 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 1/1 [00:00<00:00, 19.59it/s, train_loss=0.115]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:18:39 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 1/1 [00:00<00:00, 20.30it/s, train_loss=0.093]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:18:39 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 1/1 [00:00<00:00, 18.18it/s, train_loss=0.0761]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:18:39 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 1/1 [00:00<00:00, 19.34it/s, train_loss=0.0748]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:18:39 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 18.58it/s, train_loss=0.0885]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:18:39 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n",
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 17.58it/s, train_loss=0.0885]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/06/12 17:18:43 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 100.86it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/chapter22/lib/python3.9/site-packages/torch/nn/modules/transformer.py:382: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "2025/06/12 17:18:43 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID 'f257aeb7839b43c4ab854591f3176a79', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current pytorch workflow\n",
      "\n",
      "  | Name                | Type                | Params | Mode \n",
      "--------------------------------------------------------------------\n",
      "0 | criterion           | MSELoss             | 0      | train\n",
      "1 | train_criterion     | MSELoss             | 0      | train\n",
      "2 | val_criterion       | MSELoss             | 0      | train\n",
      "3 | train_metrics       | MetricCollection    | 0      | train\n",
      "4 | val_metrics         | MetricCollection    | 0      | train\n",
      "5 | encoder             | Linear              | 96     | train\n",
      "6 | positional_encoding | _PositionalEncoding | 0      | train\n",
      "7 | transformer         | Transformer         | 243 K  | train\n",
      "8 | decoder             | Linear              | 396    | train\n",
      "--------------------------------------------------------------------\n",
      "243 K     Trainable params\n",
      "0         Non-trainable params\n",
      "243 K     Total params\n",
      "0.975     Total estimated model params size (MB)\n",
      "92        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "/opt/anaconda3/envs/chapter22/lib/python3.9/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 0: 100%|██████████| 1/1 [00:00<00:00, 14.29it/s, train_loss=0.972]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:18:43 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 1/1 [00:00<00:00, 15.88it/s, train_loss=0.392]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:18:43 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 1/1 [00:00<00:00, 16.40it/s, train_loss=0.231]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:18:43 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 1/1 [00:00<00:00, 15.67it/s, train_loss=0.134]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:18:43 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 16.16it/s, train_loss=0.0693]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:18:43 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 1/1 [00:00<00:00, 16.75it/s, train_loss=0.0752]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:18:43 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 1/1 [00:00<00:00, 16.57it/s, train_loss=0.0799]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:18:43 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 1/1 [00:00<00:00, 15.85it/s, train_loss=0.075] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:18:43 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 1/1 [00:00<00:00, 16.91it/s, train_loss=0.0911]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:18:43 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 15.89it/s, train_loss=0.0752]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:18:43 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n",
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 15.19it/s, train_loss=0.0752]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/06/12 17:18:47 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 82.85it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/chapter22/lib/python3.9/site-packages/torch/nn/modules/transformer.py:382: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "2025/06/12 17:18:47 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID 'e181eaaa89794c05ac247625bbaafa45', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current pytorch workflow\n",
      "\n",
      "  | Name                | Type                | Params | Mode \n",
      "--------------------------------------------------------------------\n",
      "0 | criterion           | MSELoss             | 0      | train\n",
      "1 | train_criterion     | MSELoss             | 0      | train\n",
      "2 | val_criterion       | MSELoss             | 0      | train\n",
      "3 | train_metrics       | MetricCollection    | 0      | train\n",
      "4 | val_metrics         | MetricCollection    | 0      | train\n",
      "5 | encoder             | Linear              | 96     | train\n",
      "6 | positional_encoding | _PositionalEncoding | 0      | train\n",
      "7 | transformer         | Transformer         | 238 K  | train\n",
      "8 | decoder             | Linear              | 396    | train\n",
      "--------------------------------------------------------------------\n",
      "239 K     Trainable params\n",
      "0         Non-trainable params\n",
      "239 K     Total params\n",
      "0.958     Total estimated model params size (MB)\n",
      "88        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "/opt/anaconda3/envs/chapter22/lib/python3.9/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 0: 100%|██████████| 1/1 [00:00<00:00, 15.93it/s, train_loss=0.836]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:18:47 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 1/1 [00:00<00:00, 17.09it/s, train_loss=0.349]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:18:47 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 1/1 [00:00<00:00, 17.26it/s, train_loss=0.149]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:18:47 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 1/1 [00:00<00:00, 17.53it/s, train_loss=0.0851]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:18:47 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 16.88it/s, train_loss=0.0772]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:18:47 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 1/1 [00:00<00:00, 17.36it/s, train_loss=0.0873]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:18:48 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 1/1 [00:00<00:00, 17.34it/s, train_loss=0.0941]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:18:48 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 1/1 [00:00<00:00, 16.56it/s, train_loss=0.0869]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:18:48 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 1/1 [00:00<00:00, 17.26it/s, train_loss=0.0788]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:18:48 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 17.59it/s, train_loss=0.0696]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:18:48 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n",
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 16.67it/s, train_loss=0.0696]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/06/12 17:18:51 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 90.57it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/chapter22/lib/python3.9/site-packages/torch/nn/modules/transformer.py:382: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "2025/06/12 17:18:52 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID '2342bf86c5bd45659cd16a8e184a1cbe', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current pytorch workflow\n",
      "\n",
      "  | Name                | Type                | Params | Mode \n",
      "--------------------------------------------------------------------\n",
      "0 | criterion           | MSELoss             | 0      | train\n",
      "1 | train_criterion     | MSELoss             | 0      | train\n",
      "2 | val_criterion       | MSELoss             | 0      | train\n",
      "3 | train_metrics       | MetricCollection    | 0      | train\n",
      "4 | val_metrics         | MetricCollection    | 0      | train\n",
      "5 | encoder             | Linear              | 96     | train\n",
      "6 | positional_encoding | _PositionalEncoding | 0      | train\n",
      "7 | transformer         | Transformer         | 280 K  | train\n",
      "8 | decoder             | Linear              | 396    | train\n",
      "--------------------------------------------------------------------\n",
      "281 K     Trainable params\n",
      "0         Non-trainable params\n",
      "281 K     Total params\n",
      "1.126     Total estimated model params size (MB)\n",
      "102       Modules in train mode\n",
      "0         Modules in eval mode\n",
      "/opt/anaconda3/envs/chapter22/lib/python3.9/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 0: 100%|██████████| 1/1 [00:00<00:00, 13.22it/s, train_loss=0.799]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:18:52 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 1/1 [00:00<00:00, 14.43it/s, train_loss=0.247]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:18:52 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 1/1 [00:00<00:00, 14.89it/s, train_loss=0.186]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:18:52 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 1/1 [00:00<00:00, 14.80it/s, train_loss=0.137]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:18:52 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 14.16it/s, train_loss=0.0957]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:18:52 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 1/1 [00:00<00:00, 14.27it/s, train_loss=0.0685]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:18:52 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 1/1 [00:00<00:00, 14.74it/s, train_loss=0.0795]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:18:52 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 1/1 [00:00<00:00, 14.73it/s, train_loss=0.0836]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:18:52 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 1/1 [00:00<00:00, 14.75it/s, train_loss=0.0721]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:18:52 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 15.06it/s, train_loss=0.0658]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:18:52 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n",
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 14.47it/s, train_loss=0.0658]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/06/12 17:18:56 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 77.90it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/chapter22/lib/python3.9/site-packages/torch/nn/modules/transformer.py:382: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "2025/06/12 17:18:56 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID '0a684b19296e4419ae0059414e1fde44', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current pytorch workflow\n",
      "\n",
      "  | Name                | Type                | Params | Mode \n",
      "--------------------------------------------------------------------\n",
      "0 | criterion           | MSELoss             | 0      | train\n",
      "1 | train_criterion     | MSELoss             | 0      | train\n",
      "2 | val_criterion       | MSELoss             | 0      | train\n",
      "3 | train_metrics       | MetricCollection    | 0      | train\n",
      "4 | val_metrics         | MetricCollection    | 0      | train\n",
      "5 | encoder             | Linear              | 96     | train\n",
      "6 | positional_encoding | _PositionalEncoding | 0      | train\n",
      "7 | transformer         | Transformer         | 276 K  | train\n",
      "8 | decoder             | Linear              | 396    | train\n",
      "--------------------------------------------------------------------\n",
      "277 K     Trainable params\n",
      "0         Non-trainable params\n",
      "277 K     Total params\n",
      "1.109     Total estimated model params size (MB)\n",
      "98        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "/opt/anaconda3/envs/chapter22/lib/python3.9/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 0: 100%|██████████| 1/1 [00:00<00:00, 14.42it/s, train_loss=0.395]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:18:56 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 1/1 [00:00<00:00, 14.89it/s, train_loss=0.234]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:18:56 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 1/1 [00:00<00:00, 14.49it/s, train_loss=0.137]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:18:56 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 1/1 [00:00<00:00, 15.55it/s, train_loss=0.107]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:18:56 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 15.91it/s, train_loss=0.105]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:18:57 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 1/1 [00:00<00:00, 15.90it/s, train_loss=0.0753]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:18:57 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 1/1 [00:00<00:00, 15.57it/s, train_loss=0.0961]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:18:57 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 1/1 [00:00<00:00, 15.66it/s, train_loss=0.071] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:18:57 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 1/1 [00:00<00:00, 15.44it/s, train_loss=0.078]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:18:57 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 14.78it/s, train_loss=0.0632]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:18:57 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n",
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 14.12it/s, train_loss=0.0632]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/06/12 17:19:01 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 81.33it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/chapter22/lib/python3.9/site-packages/torch/nn/modules/transformer.py:382: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "2025/06/12 17:19:01 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID '0a1a0820135f45d79fcee19d7aaa617c', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current pytorch workflow\n",
      "\n",
      "  | Name                | Type                | Params | Mode \n",
      "--------------------------------------------------------------------\n",
      "0 | criterion           | MSELoss             | 0      | train\n",
      "1 | train_criterion     | MSELoss             | 0      | train\n",
      "2 | val_criterion       | MSELoss             | 0      | train\n",
      "3 | train_metrics       | MetricCollection    | 0      | train\n",
      "4 | val_metrics         | MetricCollection    | 0      | train\n",
      "5 | encoder             | Linear              | 96     | train\n",
      "6 | positional_encoding | _PositionalEncoding | 0      | train\n",
      "7 | transformer         | Transformer         | 318 K  | train\n",
      "8 | decoder             | Linear              | 396    | train\n",
      "--------------------------------------------------------------------\n",
      "319 K     Trainable params\n",
      "0         Non-trainable params\n",
      "319 K     Total params\n",
      "1.276     Total estimated model params size (MB)\n",
      "112       Modules in train mode\n",
      "0         Modules in eval mode\n",
      "/opt/anaconda3/envs/chapter22/lib/python3.9/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 0: 100%|██████████| 1/1 [00:00<00:00, 12.64it/s, train_loss=0.477]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:19:01 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 1/1 [00:00<00:00, 13.42it/s, train_loss=0.238]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:19:01 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 1/1 [00:00<00:00, 13.18it/s, train_loss=0.112]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:19:01 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 1/1 [00:00<00:00, 13.89it/s, train_loss=0.0997]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:19:01 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 13.39it/s, train_loss=0.0851]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:19:01 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 1/1 [00:00<00:00, 13.32it/s, train_loss=0.0821]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:19:01 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 1/1 [00:00<00:00, 13.21it/s, train_loss=0.0749]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:19:01 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 1/1 [00:00<00:00, 13.14it/s, train_loss=0.074] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:19:01 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 1/1 [00:00<00:00, 13.72it/s, train_loss=0.0752]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:19:01 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 13.40it/s, train_loss=0.079] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:19:01 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n",
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 12.89it/s, train_loss=0.079]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/06/12 17:19:05 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 78.74it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/chapter22/lib/python3.9/site-packages/torch/nn/modules/transformer.py:382: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "2025/06/12 17:19:05 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID '27676bbcc54d4146998069930f95f1f7', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current pytorch workflow\n",
      "\n",
      "  | Name                | Type                | Params | Mode \n",
      "--------------------------------------------------------------------\n",
      "0 | criterion           | MSELoss             | 0      | train\n",
      "1 | train_criterion     | MSELoss             | 0      | train\n",
      "2 | val_criterion       | MSELoss             | 0      | train\n",
      "3 | train_metrics       | MetricCollection    | 0      | train\n",
      "4 | val_metrics         | MetricCollection    | 0      | train\n",
      "5 | encoder             | Linear              | 192    | train\n",
      "6 | positional_encoding | _PositionalEncoding | 0      | train\n",
      "7 | transformer         | Transformer         | 465 K  | train\n",
      "8 | decoder             | Linear              | 780    | train\n",
      "--------------------------------------------------------------------\n",
      "466 K     Trainable params\n",
      "0         Non-trainable params\n",
      "466 K     Total params\n",
      "1.866     Total estimated model params size (MB)\n",
      "78        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "/opt/anaconda3/envs/chapter22/lib/python3.9/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 0: 100%|██████████| 1/1 [00:00<00:00, 12.95it/s, train_loss=0.392]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:19:05 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 1/1 [00:00<00:00, 18.86it/s, train_loss=0.328]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:19:05 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 1/1 [00:00<00:00, 18.57it/s, train_loss=0.156]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:19:05 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 1/1 [00:00<00:00, 18.85it/s, train_loss=0.101]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:19:06 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 19.63it/s, train_loss=0.0888]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:19:06 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 1/1 [00:00<00:00, 19.54it/s, train_loss=0.103] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:19:06 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 1/1 [00:00<00:00, 18.69it/s, train_loss=0.099]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:19:06 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 1/1 [00:00<00:00, 18.30it/s, train_loss=0.0801]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:19:06 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 1/1 [00:00<00:00, 18.64it/s, train_loss=0.0858]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:19:06 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 18.41it/s, train_loss=0.0703]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:19:06 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n",
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 17.45it/s, train_loss=0.0703]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/06/12 17:19:10 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 101.03it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/chapter22/lib/python3.9/site-packages/torch/nn/modules/transformer.py:382: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "2025/06/12 17:19:10 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID 'b04b15da261340a2a4d021a4e2da27b4', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current pytorch workflow\n",
      "\n",
      "  | Name                | Type                | Params | Mode \n",
      "--------------------------------------------------------------------\n",
      "0 | criterion           | MSELoss             | 0      | train\n",
      "1 | train_criterion     | MSELoss             | 0      | train\n",
      "2 | val_criterion       | MSELoss             | 0      | train\n",
      "3 | train_metrics       | MetricCollection    | 0      | train\n",
      "4 | val_metrics         | MetricCollection    | 0      | train\n",
      "5 | encoder             | Linear              | 192    | train\n",
      "6 | positional_encoding | _PositionalEncoding | 0      | train\n",
      "7 | transformer         | Transformer         | 565 K  | train\n",
      "8 | decoder             | Linear              | 780    | train\n",
      "--------------------------------------------------------------------\n",
      "566 K     Trainable params\n",
      "0         Non-trainable params\n",
      "566 K     Total params\n",
      "2.265     Total estimated model params size (MB)\n",
      "92        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "/opt/anaconda3/envs/chapter22/lib/python3.9/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 0: 100%|██████████| 1/1 [00:00<00:00, 14.70it/s, train_loss=0.745]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:19:10 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 1/1 [00:00<00:00, 16.21it/s, train_loss=0.515]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:19:10 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 1/1 [00:00<00:00, 16.09it/s, train_loss=0.218]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:19:10 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 1/1 [00:00<00:00, 16.69it/s, train_loss=0.0841]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:19:10 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 15.71it/s, train_loss=0.0788]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:19:10 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 1/1 [00:00<00:00, 15.99it/s, train_loss=0.116] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:19:10 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 1/1 [00:00<00:00, 15.88it/s, train_loss=0.103]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:19:10 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 1/1 [00:00<00:00, 16.29it/s, train_loss=0.0871]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:19:10 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 1/1 [00:00<00:00, 15.81it/s, train_loss=0.0838]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:19:10 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 15.92it/s, train_loss=0.0752]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:19:10 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n",
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 15.28it/s, train_loss=0.0752]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/06/12 17:19:14 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 86.71it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/chapter22/lib/python3.9/site-packages/torch/nn/modules/transformer.py:382: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "2025/06/12 17:19:14 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID '8f84a00b3918414a9fad3d26f6f615dd', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current pytorch workflow\n",
      "\n",
      "  | Name                | Type                | Params | Mode \n",
      "--------------------------------------------------------------------\n",
      "0 | criterion           | MSELoss             | 0      | train\n",
      "1 | train_criterion     | MSELoss             | 0      | train\n",
      "2 | val_criterion       | MSELoss             | 0      | train\n",
      "3 | train_metrics       | MetricCollection    | 0      | train\n",
      "4 | val_metrics         | MetricCollection    | 0      | train\n",
      "5 | encoder             | Linear              | 192    | train\n",
      "6 | positional_encoding | _PositionalEncoding | 0      | train\n",
      "7 | transformer         | Transformer         | 548 K  | train\n",
      "8 | decoder             | Linear              | 780    | train\n",
      "--------------------------------------------------------------------\n",
      "549 K     Trainable params\n",
      "0         Non-trainable params\n",
      "549 K     Total params\n",
      "2.198     Total estimated model params size (MB)\n",
      "88        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "/opt/anaconda3/envs/chapter22/lib/python3.9/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 0: 100%|██████████| 1/1 [00:00<00:00, 15.38it/s, train_loss=0.689]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:19:14 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 1/1 [00:00<00:00, 16.83it/s, train_loss=0.493]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:19:14 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 1/1 [00:00<00:00, 16.69it/s, train_loss=0.210]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:19:14 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 1/1 [00:00<00:00, 15.74it/s, train_loss=0.136]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:19:14 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 16.54it/s, train_loss=0.0828]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:19:15 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 1/1 [00:00<00:00, 16.17it/s, train_loss=0.0801]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:19:15 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 1/1 [00:00<00:00, 17.14it/s, train_loss=0.0878]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:19:15 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 1/1 [00:00<00:00, 16.27it/s, train_loss=0.0903]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:19:15 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 1/1 [00:00<00:00, 17.33it/s, train_loss=0.0887]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:19:15 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 17.11it/s, train_loss=0.100] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:19:15 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n",
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 16.34it/s, train_loss=0.100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/06/12 17:19:18 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 80.48it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/chapter22/lib/python3.9/site-packages/torch/nn/modules/transformer.py:382: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "2025/06/12 17:19:19 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID '843f723aeaec40ab885ee484012f68df', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current pytorch workflow\n",
      "\n",
      "  | Name                | Type                | Params | Mode \n",
      "--------------------------------------------------------------------\n",
      "0 | criterion           | MSELoss             | 0      | train\n",
      "1 | train_criterion     | MSELoss             | 0      | train\n",
      "2 | val_criterion       | MSELoss             | 0      | train\n",
      "3 | train_metrics       | MetricCollection    | 0      | train\n",
      "4 | val_metrics         | MetricCollection    | 0      | train\n",
      "5 | encoder             | Linear              | 192    | train\n",
      "6 | positional_encoding | _PositionalEncoding | 0      | train\n",
      "7 | transformer         | Transformer         | 648 K  | train\n",
      "8 | decoder             | Linear              | 780    | train\n",
      "--------------------------------------------------------------------\n",
      "649 K     Trainable params\n",
      "0         Non-trainable params\n",
      "649 K     Total params\n",
      "2.597     Total estimated model params size (MB)\n",
      "102       Modules in train mode\n",
      "0         Modules in eval mode\n",
      "/opt/anaconda3/envs/chapter22/lib/python3.9/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 0: 100%|██████████| 1/1 [00:00<00:00, 13.16it/s, train_loss=0.637]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:19:19 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 1/1 [00:00<00:00, 14.28it/s, train_loss=0.236]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:19:19 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 1/1 [00:00<00:00, 14.19it/s, train_loss=0.135]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:19:19 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 1/1 [00:00<00:00, 14.63it/s, train_loss=0.0932]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:19:19 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 14.56it/s, train_loss=0.104] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:19:19 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 1/1 [00:00<00:00, 13.85it/s, train_loss=0.0931]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:19:19 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 1/1 [00:00<00:00, 14.33it/s, train_loss=0.0798]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:19:19 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 1/1 [00:00<00:00, 14.32it/s, train_loss=0.076] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:19:19 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 1/1 [00:00<00:00, 14.46it/s, train_loss=0.0827]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:19:19 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 14.70it/s, train_loss=0.066] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:19:19 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n",
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 14.04it/s, train_loss=0.066]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/06/12 17:19:23 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 83.14it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/chapter22/lib/python3.9/site-packages/torch/nn/modules/transformer.py:382: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "2025/06/12 17:19:23 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID '2b41b0fdcc894659b29ddeb74e57f0d1', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current pytorch workflow\n",
      "\n",
      "  | Name                | Type                | Params | Mode \n",
      "--------------------------------------------------------------------\n",
      "0 | criterion           | MSELoss             | 0      | train\n",
      "1 | train_criterion     | MSELoss             | 0      | train\n",
      "2 | val_criterion       | MSELoss             | 0      | train\n",
      "3 | train_metrics       | MetricCollection    | 0      | train\n",
      "4 | val_metrics         | MetricCollection    | 0      | train\n",
      "5 | encoder             | Linear              | 192    | train\n",
      "6 | positional_encoding | _PositionalEncoding | 0      | train\n",
      "7 | transformer         | Transformer         | 631 K  | train\n",
      "8 | decoder             | Linear              | 780    | train\n",
      "--------------------------------------------------------------------\n",
      "632 K     Trainable params\n",
      "0         Non-trainable params\n",
      "632 K     Total params\n",
      "2.530     Total estimated model params size (MB)\n",
      "98        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "/opt/anaconda3/envs/chapter22/lib/python3.9/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 0: 100%|██████████| 1/1 [00:00<00:00, 13.71it/s, train_loss=0.698]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:19:23 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 1/1 [00:00<00:00, 15.21it/s, train_loss=0.233]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:19:23 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 1/1 [00:00<00:00, 15.10it/s, train_loss=0.141]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:19:23 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 1/1 [00:00<00:00, 15.03it/s, train_loss=0.102]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:19:23 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 14.97it/s, train_loss=0.0933]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:19:24 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 1/1 [00:00<00:00, 14.76it/s, train_loss=0.0802]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:19:24 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 1/1 [00:00<00:00, 15.86it/s, train_loss=0.0733]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:19:24 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 1/1 [00:00<00:00, 14.30it/s, train_loss=0.0749]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:19:24 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 1/1 [00:00<00:00, 15.50it/s, train_loss=0.0725]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:19:24 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 15.52it/s, train_loss=0.0781]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:19:24 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n",
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 14.86it/s, train_loss=0.0781]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/06/12 17:19:28 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 76.91it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/chapter22/lib/python3.9/site-packages/torch/nn/modules/transformer.py:382: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "2025/06/12 17:19:28 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID 'ba38be4785ec43a3a7a85aa24110a16d', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current pytorch workflow\n",
      "\n",
      "  | Name                | Type                | Params | Mode \n",
      "--------------------------------------------------------------------\n",
      "0 | criterion           | MSELoss             | 0      | train\n",
      "1 | train_criterion     | MSELoss             | 0      | train\n",
      "2 | val_criterion       | MSELoss             | 0      | train\n",
      "3 | train_metrics       | MetricCollection    | 0      | train\n",
      "4 | val_metrics         | MetricCollection    | 0      | train\n",
      "5 | encoder             | Linear              | 192    | train\n",
      "6 | positional_encoding | _PositionalEncoding | 0      | train\n",
      "7 | transformer         | Transformer         | 731 K  | train\n",
      "8 | decoder             | Linear              | 780    | train\n",
      "--------------------------------------------------------------------\n",
      "732 K     Trainable params\n",
      "0         Non-trainable params\n",
      "732 K     Total params\n",
      "2.929     Total estimated model params size (MB)\n",
      "112       Modules in train mode\n",
      "0         Modules in eval mode\n",
      "/opt/anaconda3/envs/chapter22/lib/python3.9/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 0: 100%|██████████| 1/1 [00:00<00:00, 12.30it/s, train_loss=0.801]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:19:28 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 1/1 [00:00<00:00, 12.42it/s, train_loss=0.379]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:19:28 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 1/1 [00:00<00:00, 12.40it/s, train_loss=0.164]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:19:28 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 1/1 [00:00<00:00, 12.59it/s, train_loss=0.121]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:19:28 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 12.94it/s, train_loss=0.0899]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:19:28 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 1/1 [00:00<00:00, 13.83it/s, train_loss=0.106] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:19:28 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 1/1 [00:00<00:00, 13.54it/s, train_loss=0.087]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:19:28 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 1/1 [00:00<00:00, 12.99it/s, train_loss=0.0646]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:19:28 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 1/1 [00:00<00:00, 12.89it/s, train_loss=0.0635]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:19:29 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 13.17it/s, train_loss=0.0909]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:19:29 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n",
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 12.67it/s, train_loss=0.0909]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/06/12 17:19:32 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 75.06it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/chapter22/lib/python3.9/site-packages/torch/nn/modules/transformer.py:382: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "2025/06/12 17:19:32 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID '67a2a3d5303f4d5393385e142da81bbd', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current pytorch workflow\n",
      "\n",
      "  | Name                | Type                | Params | Mode \n",
      "--------------------------------------------------------------------\n",
      "0 | criterion           | MSELoss             | 0      | train\n",
      "1 | train_criterion     | MSELoss             | 0      | train\n",
      "2 | val_criterion       | MSELoss             | 0      | train\n",
      "3 | train_metrics       | MetricCollection    | 0      | train\n",
      "4 | val_metrics         | MetricCollection    | 0      | train\n",
      "5 | encoder             | Linear              | 192    | train\n",
      "6 | positional_encoding | _PositionalEncoding | 0      | train\n",
      "7 | transformer         | Transformer         | 465 K  | train\n",
      "8 | decoder             | Linear              | 780    | train\n",
      "--------------------------------------------------------------------\n",
      "466 K     Trainable params\n",
      "0         Non-trainable params\n",
      "466 K     Total params\n",
      "1.866     Total estimated model params size (MB)\n",
      "78        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "/opt/anaconda3/envs/chapter22/lib/python3.9/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 0: 100%|██████████| 1/1 [00:00<00:00, 12.64it/s, train_loss=0.395]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:19:33 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 1/1 [00:00<00:00, 18.05it/s, train_loss=0.313]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:19:33 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 1/1 [00:00<00:00, 17.54it/s, train_loss=0.154]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:19:33 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 1/1 [00:00<00:00, 17.44it/s, train_loss=0.0996]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:19:33 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 17.87it/s, train_loss=0.0808]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:19:33 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 1/1 [00:00<00:00, 17.84it/s, train_loss=0.103] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:19:33 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 1/1 [00:00<00:00, 18.00it/s, train_loss=0.0954]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:19:33 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 1/1 [00:00<00:00, 18.04it/s, train_loss=0.0798]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:19:33 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 1/1 [00:00<00:00, 17.79it/s, train_loss=0.0885]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:19:33 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 18.85it/s, train_loss=0.0712]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:19:33 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n",
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 17.76it/s, train_loss=0.0712]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/06/12 17:19:37 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 81.52it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/chapter22/lib/python3.9/site-packages/torch/nn/modules/transformer.py:382: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "2025/06/12 17:19:37 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID 'fe26661de28946d2834908366e9ea90d', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current pytorch workflow\n",
      "\n",
      "  | Name                | Type                | Params | Mode \n",
      "--------------------------------------------------------------------\n",
      "0 | criterion           | MSELoss             | 0      | train\n",
      "1 | train_criterion     | MSELoss             | 0      | train\n",
      "2 | val_criterion       | MSELoss             | 0      | train\n",
      "3 | train_metrics       | MetricCollection    | 0      | train\n",
      "4 | val_metrics         | MetricCollection    | 0      | train\n",
      "5 | encoder             | Linear              | 192    | train\n",
      "6 | positional_encoding | _PositionalEncoding | 0      | train\n",
      "7 | transformer         | Transformer         | 565 K  | train\n",
      "8 | decoder             | Linear              | 780    | train\n",
      "--------------------------------------------------------------------\n",
      "566 K     Trainable params\n",
      "0         Non-trainable params\n",
      "566 K     Total params\n",
      "2.265     Total estimated model params size (MB)\n",
      "92        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "/opt/anaconda3/envs/chapter22/lib/python3.9/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 0: 100%|██████████| 1/1 [00:00<00:00, 13.77it/s, train_loss=0.768]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:19:37 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 1/1 [00:00<00:00, 14.02it/s, train_loss=0.513]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:19:37 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 1/1 [00:00<00:00, 14.91it/s, train_loss=0.210]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:19:37 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 1/1 [00:00<00:00, 14.88it/s, train_loss=0.087]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:19:37 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 15.71it/s, train_loss=0.082]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:19:37 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 1/1 [00:00<00:00, 15.96it/s, train_loss=0.111]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:19:37 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 1/1 [00:00<00:00, 15.06it/s, train_loss=0.106]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:19:37 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 1/1 [00:00<00:00, 16.43it/s, train_loss=0.0885]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:19:37 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 1/1 [00:00<00:00, 15.99it/s, train_loss=0.0923]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:19:37 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 15.30it/s, train_loss=0.0782]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:19:38 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n",
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 14.63it/s, train_loss=0.0782]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/06/12 17:19:41 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 87.74it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/chapter22/lib/python3.9/site-packages/torch/nn/modules/transformer.py:382: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "2025/06/12 17:19:41 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID 'b961aeec0ba54ab69bf28fa51555691a', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current pytorch workflow\n",
      "\n",
      "  | Name                | Type                | Params | Mode \n",
      "--------------------------------------------------------------------\n",
      "0 | criterion           | MSELoss             | 0      | train\n",
      "1 | train_criterion     | MSELoss             | 0      | train\n",
      "2 | val_criterion       | MSELoss             | 0      | train\n",
      "3 | train_metrics       | MetricCollection    | 0      | train\n",
      "4 | val_metrics         | MetricCollection    | 0      | train\n",
      "5 | encoder             | Linear              | 192    | train\n",
      "6 | positional_encoding | _PositionalEncoding | 0      | train\n",
      "7 | transformer         | Transformer         | 548 K  | train\n",
      "8 | decoder             | Linear              | 780    | train\n",
      "--------------------------------------------------------------------\n",
      "549 K     Trainable params\n",
      "0         Non-trainable params\n",
      "549 K     Total params\n",
      "2.198     Total estimated model params size (MB)\n",
      "88        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "/opt/anaconda3/envs/chapter22/lib/python3.9/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 0: 100%|██████████| 1/1 [00:00<00:00, 15.80it/s, train_loss=0.703]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:19:41 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 1/1 [00:00<00:00, 16.32it/s, train_loss=0.494]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:19:42 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 1/1 [00:00<00:00, 15.68it/s, train_loss=0.232]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:19:42 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 1/1 [00:00<00:00, 16.03it/s, train_loss=0.149]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:19:42 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 15.76it/s, train_loss=0.0905]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:19:42 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 1/1 [00:00<00:00, 17.42it/s, train_loss=0.0831]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:19:42 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 1/1 [00:00<00:00, 16.08it/s, train_loss=0.092] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:19:42 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 1/1 [00:00<00:00, 16.78it/s, train_loss=0.0976]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:19:42 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 1/1 [00:00<00:00, 17.12it/s, train_loss=0.0901]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:19:42 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 16.06it/s, train_loss=0.098] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:19:42 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n",
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 15.35it/s, train_loss=0.098]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/06/12 17:19:46 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 81.51it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/chapter22/lib/python3.9/site-packages/torch/nn/modules/transformer.py:382: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "2025/06/12 17:19:46 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID '08a77d12c71c4d1186f3032b303ceedc', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current pytorch workflow\n",
      "\n",
      "  | Name                | Type                | Params | Mode \n",
      "--------------------------------------------------------------------\n",
      "0 | criterion           | MSELoss             | 0      | train\n",
      "1 | train_criterion     | MSELoss             | 0      | train\n",
      "2 | val_criterion       | MSELoss             | 0      | train\n",
      "3 | train_metrics       | MetricCollection    | 0      | train\n",
      "4 | val_metrics         | MetricCollection    | 0      | train\n",
      "5 | encoder             | Linear              | 192    | train\n",
      "6 | positional_encoding | _PositionalEncoding | 0      | train\n",
      "7 | transformer         | Transformer         | 648 K  | train\n",
      "8 | decoder             | Linear              | 780    | train\n",
      "--------------------------------------------------------------------\n",
      "649 K     Trainable params\n",
      "0         Non-trainable params\n",
      "649 K     Total params\n",
      "2.597     Total estimated model params size (MB)\n",
      "102       Modules in train mode\n",
      "0         Modules in eval mode\n",
      "/opt/anaconda3/envs/chapter22/lib/python3.9/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 0: 100%|██████████| 1/1 [00:00<00:00, 12.83it/s, train_loss=0.625]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:19:46 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 1/1 [00:00<00:00, 14.33it/s, train_loss=0.206]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:19:46 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 1/1 [00:00<00:00, 14.21it/s, train_loss=0.115]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:19:46 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 1/1 [00:00<00:00, 13.72it/s, train_loss=0.0924]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:19:46 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 14.72it/s, train_loss=0.100] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:19:46 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 1/1 [00:00<00:00, 14.21it/s, train_loss=0.0892]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:19:46 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 1/1 [00:00<00:00, 14.71it/s, train_loss=0.0743]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:19:46 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 1/1 [00:00<00:00, 13.63it/s, train_loss=0.0699]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:19:46 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 1/1 [00:00<00:00, 13.84it/s, train_loss=0.074] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:19:47 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 14.32it/s, train_loss=0.0685]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:19:47 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n",
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 13.76it/s, train_loss=0.0685]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/06/12 17:19:50 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 85.49it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/chapter22/lib/python3.9/site-packages/torch/nn/modules/transformer.py:382: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "2025/06/12 17:19:50 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID 'ebc6bdf99d9241c49fae43a69464ed24', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current pytorch workflow\n",
      "\n",
      "  | Name                | Type                | Params | Mode \n",
      "--------------------------------------------------------------------\n",
      "0 | criterion           | MSELoss             | 0      | train\n",
      "1 | train_criterion     | MSELoss             | 0      | train\n",
      "2 | val_criterion       | MSELoss             | 0      | train\n",
      "3 | train_metrics       | MetricCollection    | 0      | train\n",
      "4 | val_metrics         | MetricCollection    | 0      | train\n",
      "5 | encoder             | Linear              | 192    | train\n",
      "6 | positional_encoding | _PositionalEncoding | 0      | train\n",
      "7 | transformer         | Transformer         | 631 K  | train\n",
      "8 | decoder             | Linear              | 780    | train\n",
      "--------------------------------------------------------------------\n",
      "632 K     Trainable params\n",
      "0         Non-trainable params\n",
      "632 K     Total params\n",
      "2.530     Total estimated model params size (MB)\n",
      "98        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "/opt/anaconda3/envs/chapter22/lib/python3.9/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 0: 100%|██████████| 1/1 [00:00<00:00, 14.21it/s, train_loss=0.710]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:19:50 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 1/1 [00:00<00:00, 14.44it/s, train_loss=0.247]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:19:51 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 1/1 [00:00<00:00, 15.21it/s, train_loss=0.140]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:19:51 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 1/1 [00:00<00:00, 15.61it/s, train_loss=0.0988]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:19:51 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 14.66it/s, train_loss=0.0891]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:19:51 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 1/1 [00:00<00:00, 15.39it/s, train_loss=0.0765]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:19:51 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 1/1 [00:00<00:00, 14.69it/s, train_loss=0.0685]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:19:51 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 1/1 [00:00<00:00, 15.38it/s, train_loss=0.0756]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:19:51 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 1/1 [00:00<00:00, 14.56it/s, train_loss=0.0759]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:19:51 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 15.02it/s, train_loss=0.0819]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:19:51 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n",
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 14.40it/s, train_loss=0.0819]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/06/12 17:19:55 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 78.61it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/chapter22/lib/python3.9/site-packages/torch/nn/modules/transformer.py:382: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "2025/06/12 17:19:55 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID 'f7ee1c2a13534758af5d117a04f1371e', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current pytorch workflow\n",
      "\n",
      "  | Name                | Type                | Params | Mode \n",
      "--------------------------------------------------------------------\n",
      "0 | criterion           | MSELoss             | 0      | train\n",
      "1 | train_criterion     | MSELoss             | 0      | train\n",
      "2 | val_criterion       | MSELoss             | 0      | train\n",
      "3 | train_metrics       | MetricCollection    | 0      | train\n",
      "4 | val_metrics         | MetricCollection    | 0      | train\n",
      "5 | encoder             | Linear              | 192    | train\n",
      "6 | positional_encoding | _PositionalEncoding | 0      | train\n",
      "7 | transformer         | Transformer         | 731 K  | train\n",
      "8 | decoder             | Linear              | 780    | train\n",
      "--------------------------------------------------------------------\n",
      "732 K     Trainable params\n",
      "0         Non-trainable params\n",
      "732 K     Total params\n",
      "2.929     Total estimated model params size (MB)\n",
      "112       Modules in train mode\n",
      "0         Modules in eval mode\n",
      "/opt/anaconda3/envs/chapter22/lib/python3.9/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 0: 100%|██████████| 1/1 [00:00<00:00, 11.68it/s, train_loss=0.809]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:19:55 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 1/1 [00:00<00:00, 13.29it/s, train_loss=0.384]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:19:55 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 1/1 [00:00<00:00, 12.82it/s, train_loss=0.143]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:19:55 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 1/1 [00:00<00:00, 12.48it/s, train_loss=0.123]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:19:55 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 12.34it/s, train_loss=0.0903]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:19:55 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 1/1 [00:00<00:00, 13.43it/s, train_loss=0.102] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:19:55 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 1/1 [00:00<00:00, 12.85it/s, train_loss=0.0881]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:19:55 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 1/1 [00:00<00:00, 13.36it/s, train_loss=0.0649]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:19:56 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 1/1 [00:00<00:00, 13.34it/s, train_loss=0.0657]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:19:56 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 13.57it/s, train_loss=0.0904]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:19:56 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n",
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 13.03it/s, train_loss=0.0904]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/06/12 17:19:59 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 69.76it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_chunck_length</th>\n",
       "      <th>n_epochs</th>\n",
       "      <th>d_model</th>\n",
       "      <th>nhead</th>\n",
       "      <th>num_encoder_layers</th>\n",
       "      <th>num_decoder_layers</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>24</td>\n",
       "      <td>10</td>\n",
       "      <td>64</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0.839653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>24</td>\n",
       "      <td>10</td>\n",
       "      <td>64</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.839218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>24</td>\n",
       "      <td>10</td>\n",
       "      <td>64</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.836948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>24</td>\n",
       "      <td>5</td>\n",
       "      <td>64</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.836611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>24</td>\n",
       "      <td>10</td>\n",
       "      <td>64</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0.836331</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    input_chunck_length  n_epochs  d_model  nhead  num_encoder_layers  \\\n",
       "88                   24        10       64      4                   4   \n",
       "89                   24        10       64      4                   4   \n",
       "95                   24        10       64      8                   4   \n",
       "60                   24         5       64      4                   2   \n",
       "94                   24        10       64      8                   4   \n",
       "\n",
       "    num_decoder_layers     score  \n",
       "88                   3  0.839653  \n",
       "89                   4  0.839218  \n",
       "95                   4  0.836948  \n",
       "60                   3  0.836611  \n",
       "94                   3  0.836331  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def score_nbeats(input_chunck_length, n_epochs, d_model, nhead, num_encoder_layers, num_decoder_layers):\n",
    "    \n",
    "    # Specifying a model using the gridsearch parameters\n",
    "    model = TransformerModel(\n",
    "        input_chunk_length=input_chunck_length,\n",
    "        output_chunk_length=12,\n",
    "        n_epochs=n_epochs,\n",
    "        d_model=d_model, \n",
    "        nhead=nhead,\n",
    "        num_encoder_layers=num_encoder_layers,\n",
    "        num_decoder_layers=num_decoder_layers,\n",
    "        random_state=123\n",
    "    )\n",
    "    \n",
    "    # Train the model\n",
    "    model.fit(\n",
    "        train_scaled,\n",
    "        \n",
    "        # add the promotions as past covariates\n",
    "        past_covariates=promos_train\n",
    "    )\n",
    "    \n",
    "    \n",
    "    # Forecast 12 steps using this model\n",
    "    fcst = model.predict(\n",
    "        n=12,\n",
    "    \n",
    "        # add past covariates (promos train)\n",
    "        past_covariates=promos_train,\n",
    "        \n",
    "    )\n",
    "\n",
    "    # Rescale the predictions to the original scale\n",
    "    fcst = my_scaler.inverse_transform(fcst).values()\n",
    "    \n",
    "    # Compute metric\n",
    "    metric = 1 - mean_absolute_percentage_error(list(test['SALES']), fcst)\n",
    "\n",
    "    return metric\n",
    "\n",
    "\n",
    "\n",
    "#d_model=64, nhead=4, num_encoder_layers=3, num_decoder_layers=3\n",
    "\n",
    "# Run a Grid Search\n",
    "grid_result = []\n",
    "for input_chunck_length in [12, 24]:\n",
    "    for n_epochs in [5, 10]:\n",
    "        for d_model in [32, 64]:\n",
    "            for nhead in [4, 8]:\n",
    "                for num_encoder_layers in [2, 3, 4]:\n",
    "                    for num_decoder_layers in [3, 4]:\n",
    "                        score = score_nbeats(input_chunck_length, n_epochs, d_model, nhead, num_encoder_layers, num_decoder_layers)\n",
    "                        result = [input_chunck_length, n_epochs, d_model, nhead, num_encoder_layers, num_decoder_layers, score]\n",
    "                        grid_result.append(result)\n",
    "\n",
    "\n",
    "# Inspect the results in a DataFrame\n",
    "grid_output = pd.DataFrame(grid_result, columns=[\n",
    "    'input_chunck_length',\n",
    "    'n_epochs', \n",
    "    'd_model', \n",
    "    'nhead', \n",
    "    'num_encoder_layers', \n",
    "    'num_decoder_layers', \n",
    "    'score'\n",
    "])\n",
    "\n",
    "grid_output.sort_values('score', ascending=False).head()\n",
    "                                 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb17e09e-522d-47a2-ad0b-ea419e77b0c3",
   "metadata": {},
   "source": [
    "## Listing 22-9. Recreate the model with the best 1-mape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "50974b0e-d57b-4027-b57e-bde5126e4590",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/chapter22/lib/python3.9/site-packages/torch/nn/modules/transformer.py:382: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "2025/06/12 17:35:55 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID '437bbae45ba0442e8dd3ef8b805065d3', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current pytorch workflow\n",
      "\n",
      "  | Name                | Type                | Params | Mode \n",
      "--------------------------------------------------------------------\n",
      "0 | criterion           | MSELoss             | 0      | train\n",
      "1 | train_criterion     | MSELoss             | 0      | train\n",
      "2 | val_criterion       | MSELoss             | 0      | train\n",
      "3 | train_metrics       | MetricCollection    | 0      | train\n",
      "4 | val_metrics         | MetricCollection    | 0      | train\n",
      "5 | encoder             | Linear              | 192    | train\n",
      "6 | positional_encoding | _PositionalEncoding | 0      | train\n",
      "7 | transformer         | Transformer         | 631 K  | train\n",
      "8 | decoder             | Linear              | 780    | train\n",
      "--------------------------------------------------------------------\n",
      "632 K     Trainable params\n",
      "0         Non-trainable params\n",
      "632 K     Total params\n",
      "2.530     Total estimated model params size (MB)\n",
      "98        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "/opt/anaconda3/envs/chapter22/lib/python3.9/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 1/1 [00:00<00:00, 12.95it/s, train_loss=0.698]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:35:55 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 1/1 [00:00<00:00, 14.01it/s, train_loss=0.233]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:35:55 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 1/1 [00:00<00:00, 14.86it/s, train_loss=0.141]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:35:55 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 1/1 [00:00<00:00, 15.11it/s, train_loss=0.102]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:35:55 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 15.75it/s, train_loss=0.0933]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:35:55 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 1/1 [00:00<00:00, 15.80it/s, train_loss=0.0802]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:35:55 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 1/1 [00:00<00:00, 15.37it/s, train_loss=0.0733]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:35:55 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 1/1 [00:00<00:00, 15.20it/s, train_loss=0.0749]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:35:55 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 1/1 [00:00<00:00, 15.34it/s, train_loss=0.0725]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:35:56 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 14.86it/s, train_loss=0.0781]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/12 17:35:56 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n",
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00, 14.27it/s, train_loss=0.0781]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/06/12 17:36:00 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 65.31it/s]\n",
      "0.8396534472703934\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x341bc0070>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "input_chunck_length=24\n",
    "n_epochs=10\n",
    "d_model=64\n",
    "nhead=4\n",
    "num_encoder_layers=4\n",
    "num_decoder_layers=3\n",
    "\n",
    "# Specifying a model using the gridsearch parameters\n",
    "model = TransformerModel(\n",
    "    input_chunk_length=input_chunck_length,\n",
    "    output_chunk_length=12,\n",
    "    n_epochs=n_epochs,\n",
    "    d_model=d_model,\n",
    "    nhead=nhead,\n",
    "    num_encoder_layers=num_encoder_layers,\n",
    "    num_decoder_layers=num_decoder_layers,\n",
    "    random_state=123\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "model.fit(\n",
    "    train_scaled,\n",
    "    \n",
    "    # add the promotions as past covariates\n",
    "    past_covariates=promos_train\n",
    ")\n",
    "\n",
    "\n",
    "# Forecast 12 steps using this model\n",
    "fcst = model.predict(\n",
    "    n=12,\n",
    "\n",
    "    # add past covariates (promos train)\n",
    "    past_covariates=promos_train,\n",
    "    \n",
    ")\n",
    "\n",
    "# Rescale the predictions to the original scale\n",
    "fcst = my_scaler.inverse_transform(fcst).values()\n",
    "\n",
    "# Compute metric\n",
    "metric = 1 - mean_absolute_percentage_error(list(test['SALES']), fcst)\n",
    "print(metric)\n",
    "\n",
    "# Plot the best forecast\n",
    "plt.plot(fcst)\n",
    "plt.plot(list(test['SALES']))\n",
    "plt.legend(['fcst', 'test'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe17f008-8d10-427c-bda6-e6e35c0bb939",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
