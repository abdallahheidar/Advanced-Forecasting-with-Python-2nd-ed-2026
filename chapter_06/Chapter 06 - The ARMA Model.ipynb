{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "lined-resort",
   "metadata": {},
   "source": [
    "# Chapter 6 - The ARMA Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "common-spain",
   "metadata": {},
   "source": [
    "## Listing 6-1. Getting the Births data into Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "utility-strength",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the csv file\n",
    "data = pd.read_csv('births_data.csv', sep=';')\n",
    "\n",
    "# Keep useful columns\n",
    "data = data[['Date', 'Births']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "solid-lindsay",
   "metadata": {},
   "source": [
    "## Listing 6-2. Aggregating the Births data to yearly data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "controlled-athens",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['year'] = data.Date.apply(lambda x: x[-4:])\n",
    "data = data[['Births', 'year']].groupby('year').sum()\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "renewable-ground",
   "metadata": {},
   "source": [
    "## Listing 6-3. Plotting the yearly Births data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "printable-planning",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "ax = data.plot()\n",
    "ax.set_ylabel('Births')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "higher-fairy",
   "metadata": {},
   "source": [
    "## Listing 6-4. Applying the ADF test to the Births yearly totals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "197896b6-deaf-4be8-babc-d85dd0fca5df",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dietary-fetish",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "result = adfuller(data['Births'])\n",
    "print(result)\n",
    "\n",
    "pvalue = result[1]\n",
    "\n",
    "if pvalue < 0.05:\n",
    "    print('stationary')\n",
    "else:\n",
    "    print('not stationary')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "circular-theory",
   "metadata": {},
   "source": [
    "## Listing 6-7. Creating the ACF and PACF plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "other-illinois",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plot_acf(data['Births'], lags=40)\n",
    "\n",
    "plot_pacf(data['Births'], lags=40)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "processed-dairy",
   "metadata": {},
   "source": [
    "## Listing 6-8. Fitting the ARMA(1,1) model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee648ffe-eb1e-42da-a399-052f7f315903",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conscious-religion",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "\n",
    "# Forecast the first ARMA(1,1) model\n",
    "mod = ARIMA(list(data['Births']), order=(1,0,1))\n",
    "res = mod.fit()\n",
    "pred = res.predict()\n",
    "\n",
    "# Print the r2 score of the prediction\n",
    "print(r2_score(data, pred))\n",
    "\n",
    "# Create the plot\n",
    "plt.plot(list(data['Births']))\n",
    "plt.plot(pred)\n",
    "plt.legend(['Actual Births', 'Predicted Births'])\n",
    "plt.xlabel('Timesteps')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thrown-armor",
   "metadata": {},
   "source": [
    "## Listing 6-9. Plotting a histrogram of the residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unique-launch",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = pd.Series(res.resid).hist()\n",
    "ax.set_ylabel('Number of occurences')\n",
    "ax.set_xlabel('Residual')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "disabled-peoples",
   "metadata": {},
   "source": [
    "## Listing 6-10. Obtaining the summary table of your modelâ€™s fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dangerous-singer",
   "metadata": {},
   "outputs": [],
   "source": [
    "res.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chief-pavilion",
   "metadata": {},
   "source": [
    "## Listing 6-11. Grid search with cross-validation for optimal p and q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "matched-costume",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "\n",
    "def train_model(p, q):\n",
    "\n",
    "    errors = []\n",
    "    \n",
    "    tscv = TimeSeriesSplit(test_size=10)\n",
    "    \n",
    "    for train_index, test_index in tscv.split(data_array):\n",
    "        \n",
    "        X_train, X_test = data_array[train_index], data_array[test_index]\n",
    "        X_test_orig = X_test\n",
    "        \n",
    "        fcst = []\n",
    "        for step in range(10):\n",
    "            mod = ARIMA(X_train, order=(p,0,q))\n",
    "            res = mod.fit()\n",
    "\n",
    "            fcst.append(res.forecast(steps=1))\n",
    "\n",
    "            X_train = np.concatenate((X_train, X_test[0:1,:]))\n",
    "            X_test = X_test[1:]\n",
    "            \n",
    "        errors.append(r2_score(X_test_orig, fcst))\n",
    "        \n",
    "    pq_result = [p, q, np.mean(errors)]\n",
    "\n",
    "    \n",
    "    return pq_result\n",
    "\n",
    "\n",
    "\n",
    "data_array = data.values\n",
    "\n",
    "avg_errors = []\n",
    "\n",
    "for p in range(13):\n",
    "    for q in range(13):\n",
    "\n",
    "        try:\n",
    "            pq_result = train_model(p, q)\n",
    "            print(pq_result)\n",
    "            avg_errors.append(pq_result)\n",
    "\n",
    "        except:\n",
    "            print(p,q,'failure')\n",
    "\n",
    "avg_errors = pd.DataFrame(avg_errors)\n",
    "avg_errors.columns = ['p', 'q', 'error']\n",
    "result = avg_errors.pivot(index='p', columns='q')['error']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b62275-1ae2-43c3-a4b7-e13b74cb69fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f424d5cc-4963-4e44-8dc0-ab75b9e26d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find max\n",
    "maxi = 0\n",
    "for p in range(12):\n",
    "    for q in range(12):\n",
    "        if result.iloc[p,q] > maxi:\n",
    "            maxi = result.iloc[p,q]\n",
    "            maxidx = (p,q)\n",
    "print(maxi,maxidx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "processed-edwards",
   "metadata": {},
   "source": [
    "## Listing 6-12. Showing the test prediction of the final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "designing-scheduling",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_array = data.values\n",
    "X_train, X_test = data_array[:-10], data_array[-10:]\n",
    "X_test_orig = X_test\n",
    "\n",
    "fcst = []\n",
    "for step in range(10):\n",
    "    mod = ARIMA(X_train, order=(2,0,9))\n",
    "    res = mod.fit()\n",
    "    fcst.append(res.forecast(steps=1))\n",
    "    X_train = np.concatenate((X_train, X_test[0:1,:]))\n",
    "    X_test = X_test[1:]\n",
    "\n",
    "plt.plot(X_test_orig)\n",
    "plt.plot(fcst)\n",
    "plt.legend(['Actual Births', 'Predicted Births'])\n",
    "plt.xlabel('Time steps of test data')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fa378d9-19c0-4147-8c17-708820eb8970",
   "metadata": {},
   "source": [
    "## Listing 6-13. Adding MLFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b118ad-5879-4617-8d96-84491608c856",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "mlflow.autolog()\n",
    "\n",
    "def train_model(p, q):\n",
    "    \n",
    "    errors = []\n",
    "    tscv = TimeSeriesSplit(test_size=10)\n",
    "    for train_index, test_index in tscv.split(data_array):\n",
    "        X_train, X_test = data_array[train_index], data_array[test_index]\n",
    "        X_test_orig = X_test\n",
    "        fcst = []\n",
    "        for step in range(10):\n",
    "            mod = ARIMA(X_train, order=(p,0,q))\n",
    "            res = mod.fit()\n",
    "            fcst.append(res.forecast(steps=1))\n",
    "            X_train = np.concatenate((X_train, X_test[0:1,:]))\n",
    "            X_test = X_test[1:]\n",
    "        errors.append(r2_score(X_test_orig, fcst))\n",
    "    pq_result = [p, q, np.mean(errors)]\n",
    "    return pq_result\n",
    "    \n",
    "with mlflow.start_run():\n",
    "    \n",
    "    data_array = data.values\n",
    "    \n",
    "    avg_errors = []\n",
    "    \n",
    "    for p in [2]:\n",
    "        for q in [9]:\n",
    "    \n",
    "            try:\n",
    "                pq_result = train_model(p, q)\n",
    "\n",
    "                # Log this metric to mlflow\n",
    "                mlflow.log_metric('cross-validation-r2-score', pq_result[2])\n",
    "                avg_errors.append(pq_result)\n",
    "    \n",
    "            except:\n",
    "                print(p,q,'failure')\n",
    "    \n",
    "    avg_errors = pd.DataFrame(avg_errors)\n",
    "    avg_errors.columns = ['p', 'q', 'error']\n",
    "    result = avg_errors.pivot(index='p', columns='q')['error']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6fc499b-4134-4063-869b-e2bb4da3fa83",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
